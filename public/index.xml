<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Welcome to CFSS! on CFSS: Computing for the Social Sciences</title><link>https://cfssmacss.netlify.app/</link><description>Recent content in Welcome to CFSS! on CFSS: Computing for the Social Sciences</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 06 Oct 2025 13:30:00 -0600</lastBuildDate><atom:link href="https://cfssmacss.netlify.app/index.xml" rel="self" type="application/rss+xml"/><item><title>A1: Practice editing .Rmd and generating .md</title><link>https://cfssmacss.netlify.app/assignments/edit-readme/</link><pubDate>Thu, 29 Sep 2022 13:30:00 -0600</pubDate><guid>https://cfssmacss.netlify.app/assignments/edit-readme/</guid><description>&lt;h1 id="overview">Overview&lt;/h1>
&lt;p>The goal is to test your software installation, your GitHub setup, and
the homework submission process, as well as demonstrate basic competency
in Markdown and R Markdown.&lt;/p>
&lt;h2 id="accessing-your-a1-repository">Accessing your &lt;code>A1&lt;/code> repository&lt;/h2>
&lt;ul>
&lt;li>Go &lt;a href="https://classroom.github.com/a/B8DreZI2">to this link&lt;/a> to accept
and create your private &lt;code>a1&lt;/code> repository on GitHub. Once you do so,
your repository will be built in a few seconds. It follows the naming
convention &lt;code>a1-&amp;lt;USERNAME&amp;gt;&lt;/code>&lt;/li>
&lt;li>Once the your repository has been created, click on the link you see,
which will take you to your repository.&lt;/li>
&lt;li>Finally, clone the repository to your computer following the process
below.&lt;/li>
&lt;/ul>
&lt;h2 id="cloning-your-a1-repository">Cloning your &lt;code>a1&lt;/code> repository&lt;/h2>
&lt;p>After you have accessed the &lt;code>a1&lt;/code> repository (see above), follow these
steps to clone it. Whenever possible, this will be the preferred route
for setting up your R projects:&lt;/p></description></item><item><title>A2: Exploring and visualizing data</title><link>https://cfssmacss.netlify.app/assignments/explore-data/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/assignments/explore-data/</guid><description>Transform and explore a cleaned dataset on gun deaths in the United States.</description></item><item><title>A3: Wrangling and visualizing data</title><link>https://cfssmacss.netlify.app/assignments/wrangle-data/</link><pubDate>Tue, 27 Jun 2023 13:30:00 -0600</pubDate><guid>https://cfssmacss.netlify.app/assignments/wrangle-data/</guid><description>Wrangle and explore messy datasets in practical research environments.</description></item><item><title>A4: Programming in R</title><link>https://cfssmacss.netlify.app/assignments/programming/</link><pubDate>Fri, 21 Oct 2022 13:30:00 -0600</pubDate><guid>https://cfssmacss.netlify.app/assignments/programming/</guid><description>Practice programming techniques in R.</description></item><item><title>A5: Debugging and practice working with functions</title><link>https://cfssmacss.netlify.app/assignments/debugging-rmarkdown/</link><pubDate>Fri, 01 Mar 2019 12:25:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/assignments/debugging-rmarkdown/</guid><description>Resolve code errors and practice writing and using functions with social science data.</description></item><item><title>A6: Collecting and analyzing data from the web</title><link>https://cfssmacss.netlify.app/assignments/webdata/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/assignments/webdata/</guid><description>Collect data from the web and analyze it.</description></item><item><title>Final: Generating reproducible social science research</title><link>https://cfssmacss.netlify.app/assignments/reproducible-research/</link><pubDate>Mon, 10 Jul 2023 13:30:00 -0600</pubDate><guid>https://cfssmacss.netlify.app/assignments/reproducible-research/</guid><description>Synthesize everything we have learned thus far.</description></item><item><title>A7: Analyzing textual data</title><link>https://cfssmacss.netlify.app/assignments/text-analysis/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/assignments/text-analysis/</guid><description>Collect text data and analyze it.</description></item><item><title>General Questions &amp; Info</title><link>https://cfssmacss.netlify.app/faq/about-the-course/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/faq/about-the-course/</guid><description>&lt;h2 id="general-description">General description&lt;/h2>
&lt;p>This course is open to any graduate (or advanced undergraduate) at the
University of Chicago. We draw from a wide range of departments such as
Information Science, Sociology, Psychology, Political Science, etc.
Typically these students are looking to learn basic computational and
analytic skills they can apply to master’s projects or dissertation
research.&lt;/p>
&lt;p>If you have never programmed before or don’t know what the
&lt;a href="https://cfssmacss.netlify.app/setup/shell/">shell&lt;/a> is, &lt;strong>prepare for a different way of approaching
problems&lt;/strong>. This class will prove to be very beneficial if you stick
with it, but that will require you to commit for the full quarter. I do
not presume any prior programming experience, so everyone starts from
the same knowledge level. I guarantee that the first few weeks and
assignments will be rough - but the good news is that they will be rough
for everyone! Your classmates are struggling with you and you can lean
on one another to get through the worst part of the learning curve.&lt;/p></description></item><item><title>What is Git?</title><link>https://cfssmacss.netlify.app/setup/git/what-is-git/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/git/what-is-git/</guid><description>&lt;h2 id="why-git">Why Git?&lt;/h2>
&lt;p>In this course (and in your own work), you will be writing lots of programs. Generally the first draft is not the final draft, be it a research paper or a computer script. We want a way to track our changes over time.&lt;/p>
&lt;p>Perhaps this is to make sure we have a record of what we&amp;rsquo;ve already done that doesn&amp;rsquo;t work, so we can avoid doing it again. Or maybe we want to share our code with collaborators who are working on a project with us. How can we do this?&lt;/p></description></item><item><title>Homework Rubric</title><link>https://cfssmacss.netlify.app/faq/homework-evaluations/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/faq/homework-evaluations/</guid><description>&lt;h2 id="evaluation-philosophy">Evaluation philosophy&lt;/h2>
&lt;p>The university requires that I assign each student a letter grade at the end of the quarter. However I find that numeric scores on assignments tend to cause students grading anxiety if they do not achieve a perfect 100%. Nor does the numeric score convey specific feedback as to what the student has done well on an assignment, combined with feedback on areas for improvement.&lt;/p>
&lt;p>As such, I do not assign numeric scores in this class. All homework assignments are evaluated using the grading rubric below. Final grades are calculated as the cumulative performance across all homework assignments.&lt;/p></description></item><item><title>Install Git</title><link>https://cfssmacss.netlify.app/setup/git/git/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/git/git/</guid><description>&lt;p>This page provides instructions to install Git for Windows, Mac OX, and Linux.&lt;/p>
&lt;h1 id="git-installation-windows">Git Installation: Windows&lt;/h1>
&lt;p>Install &lt;a href="https://git-for-windows.github.io/">Git for Windows&lt;/a>, also known as &lt;code>msysgit&lt;/code> or &amp;ldquo;Git Bash&amp;rdquo;, to get Git in addition to some other useful tools, such as the Bash shell. Yes, all those names are totally confusing, but you might encounter them elsewhere and I want you to be well-informed.&lt;/p>
&lt;p>This method of installing Git for Windows leaves the Git executable in a conventional location, which will help you and other programs, e.g. RStudio, find it and use it. This also supports a transition to more expert use, because the &amp;ldquo;Git Bash&amp;rdquo; shell will be useful as you venture outside of R/RStudio.&lt;/p></description></item><item><title>Why R?</title><link>https://cfssmacss.netlify.app/setup/r/what-is-r/</link><pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/r/what-is-r/</guid><description>&lt;h2 id="open-source">Open-source&lt;/h2>
&lt;p>R is open-source software, which means using it is &lt;strong>completely free&lt;/strong>. Second, open-source software is developed &lt;strong>collaboratively&lt;/strong>, meaning the source code is open to public inspection, modification, and improvement.&lt;/p>
&lt;h2 id="popular">Popular&lt;/h2>
&lt;p>R is widely used in the physical and social sciences, &lt;a href="http://spectrum.ieee.org/static/interactive-the-top-programming-languages-2016">as well as in government, non-profits, and the private sector&lt;/a>.&lt;/p>
&lt;p>Many developers and social scientists write programs in R. As a result, there is also a large support community available to help troubleshoot problematic code. As seen in the Redmonk programming language rankings (which compare languages&amp;rsquo; appearances on Github [usage] and StackOverflow [support]), R appears near the top of both rankings.&lt;/p></description></item><item><title>Git clients</title><link>https://cfssmacss.netlify.app/setup/git/git-clients/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/git/git-clients/</guid><description>&lt;p>You can use Git for version control through the command line or through a Git client. For the first option, see &lt;a href="https://cfssmacss.netlify.app/setup/shell/">What is the Shell?&lt;/a>. Here we are going to focus on Git clients.&lt;/p>
&lt;p>Learning how and why to use Git can be rough. Therefore, using a client, rather than the command line, is usually helpful when getting started. Most clients help you interface with Git and GitHub through a user-friendly Graphical User Interface (GUI), but they still perform the same underlying Git commands that you would perform through the command line.&lt;/p></description></item><item><title>Setup R</title><link>https://cfssmacss.netlify.app/setup/r/r/</link><pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/r/r/</guid><description>&lt;h2 id="r">R&lt;/h2>
&lt;p>&lt;a href="https://www.r-project.org/">R&lt;/a> is an open-source programming language based on the &lt;a href="https://en.wikipedia.org/wiki/S_%28programming_language%29">S&lt;/a> from the 1970s. It is very popular in the physical and social sciences due to it&amp;rsquo;s cost (free) and versatility. Thousands of expansion libraries have been published which extend the tasks R can perform, and users can write their own custom functions and/or libraries to perform specific operations.&lt;/p>
&lt;h2 id="installing-r">Installing R&lt;/h2>
&lt;ol>
&lt;li>Download the latest binary distribution for your operating system (e.g. Windows, Mac OS X, or Linux) from &lt;a href="https://cran.rstudio.com/">CRAN&lt;/a>, a network of servers around the world which store identical copies of the R binaries, source code, and thousands of additional libraries. The binary version has been pre-compiled and is the easiest to install. Windows users should make sure to select the binary for the &lt;em>base distribution&lt;/em>.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/li>
&lt;li>Run the installation from the file you just downloaded (&lt;code>.exe&lt;/code> or &lt;code>.pkg&lt;/code>).&lt;/li>
&lt;li>Open R. You should see a screen similar to this:&lt;/li>
&lt;/ol>

&lt;figure>
 &lt;img src="r_console.png"/> 
&lt;/figure>

&lt;p>This is the default R console. You can use this as your development environment where you write and execute code. However the default R console is very minimalistic and not much more useful than a text editor. This is why we will use RStudio for programming in R. However to demonstrate that your R installation works, type &lt;code>5 + 2&lt;/code> in the console and press enter. You should see the following:&lt;/p></description></item><item><title>Configure Git</title><link>https://cfssmacss.netlify.app/setup/git/git-configure/</link><pubDate>Tue, 27 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/git/git-configure/</guid><description>&lt;div class="alert alert-info" role="alert">
&lt;pre>&lt;code>note
&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>To ensure minimal challenges using Git during the class, we want to configure Git now with some default settings. &lt;strong>You only have to do this once per machine.&lt;/strong>&lt;/p>
&lt;h1 id="identify-yourself">Identify yourself&lt;/h1>
&lt;p>In order to track changes and attribute them to the correct user, we need to tell Git your name and email address. Run the following commands from the R console:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-r" data-lang="r">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">usethis&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">::&lt;/span>&lt;span style="color:#000">use_git_config&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">user.name&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;Jean Clipperton&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">user.email&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;email@gmail.com&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace &lt;code>Jean Clipperton&lt;/code> and &lt;code>email@gmail.com&lt;/code> with your name and email address. Your name could be your GitHub username, or your actual first and last name. &lt;strong>Your email address must be the email address associated with your GitHub account.&lt;/strong>&lt;/p></description></item><item><title>Accessing RStudio Workbench</title><link>https://cfssmacss.netlify.app/setup/r/r-server/</link><pubDate>Mon, 26 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/r/r-server/</guid><description>&lt;p>Let&amp;rsquo;s begin with a few definitions:&lt;/p>
&lt;h2 id="r">R&lt;/h2>
&lt;p>&lt;a href="https://www.r-project.org/">R&lt;/a> is an open-source programming language based on the &lt;a href="https://en.wikipedia.org/wiki/S_%28programming_language%29">S&lt;/a> from the 1970s. It is very popular in the physical and social sciences due to it&amp;rsquo;s cost (free) and versatility. Thousands of expansion libraries have been published which extend the tasks R can perform, and users can write their own custom functions and/or libraries to perform specific operations.&lt;/p>
&lt;h2 id="rstudio">RStudio&lt;/h2>
&lt;p>The base R distribution is not the best for developing and writing programs. Instead, we want an integrated development environment (IDE) which will allow us to write and execute code, debug programs, and automate certain tasks. In this course we will use &lt;a href="https://www.rstudio.com/products/RStudio/">RStudio&lt;/a>, perhaps the most popular IDE available for R. Like R, it is open-source, expandable, and provides many useful tools and enhancements over the base R environment.&lt;/p></description></item><item><title>How to ask for help</title><link>https://cfssmacss.netlify.app/faq/asking-questions/</link><pubDate>Sun, 25 Sep 2022 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/faq/asking-questions/</guid><description>&lt;p>Asking questions is an important part of this class. Remember the &lt;strong>15
minute rule&lt;/strong>: Once you’ve spent 15 minutes attempting to troubleshoot a
problem, ask for help.&lt;/p>
&lt;p>Questions should be posted to &lt;a href="https://edstem.org/us/courses/79778/discussion">Ed
Discussion&lt;/a> in the
appropriate category (general v discussion). Here are some &lt;strong>tips&lt;/strong> you
should always follow when posting questions.&lt;/p>
&lt;h2 id="introduce-the-problem-with-an-informative-title">Introduce the problem with an informative title&lt;/h2>
&lt;ul>
&lt;li>Bad title: “I need help!”&lt;/li>
&lt;li>Good title: “Getting a ‘file not found error’ when importing
scotus.csv”&lt;/li>
&lt;/ul>
&lt;p>Be specific with your title. It should be brief, but also informative so
that when others are looking at it (and they have a similar error and/or
solution), they can easily find it.&lt;/p></description></item><item><title>Using Git within RStudio</title><link>https://cfssmacss.netlify.app/setup/git/git-with-rstudio/</link><pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/setup/git/git-with-rstudio/</guid><description>&lt;p>Complete these steps after you have Installed Git (only if you are working with R Studio locally) and Configured Git (for both local and R Workbench option) to verify that everything works as expected. If you are not sure, begin by reading &lt;a href="https://cfssmacss.netlify.app/setup/">Start here: Software Options&lt;/a>.&lt;/p>
&lt;h1 id="step-0-make-sure-rstudio-can-find-git">Step 0: Make sure RStudio can find Git&lt;/h1>
&lt;h2 id="if-everything-is-installed-correctly">If everything is installed correctly&amp;hellip;&lt;/h2>
&lt;ul>
&lt;li>&lt;em>File &amp;gt; New Project&lt;/em>. If you see a Version Control options, that&amp;rsquo;s good. Do not select it. Instead, select &lt;em>New Directory &amp;gt; New Project&lt;/em>. Do you see a check box &amp;ldquo;Create a git repository&amp;rdquo;? If yes, that&amp;rsquo;s good. Check it.&lt;/li>
&lt;li>Give this test project a name and click &amp;ldquo;Create Project&amp;rdquo;. Do you see a &amp;ldquo;Git&amp;rdquo; tab in the upper right pane, the same one that has &amp;ldquo;Environment&amp;rdquo; and &amp;ldquo;History&amp;rdquo;? If yes, good.&lt;/li>
&lt;/ul>
&lt;p>If this worked, you can delete the project. You&amp;rsquo;ve set everything up correctly (if you are working on R Workbench this should automatically work). To delete the project, go to the &amp;ldquo;Files&amp;rdquo; tab (bottom right corner), select the project folder and click &amp;ldquo;Delete&amp;rdquo;&lt;/p></description></item><item><title>Juneteenth (observed)</title><link>https://cfssmacss.netlify.app/schedule/juneteenth/</link><pubDate>Fri, 01 Mar 2019 12:25:00 -0500</pubDate><guid>https://cfssmacss.netlify.app/schedule/juneteenth/</guid><description>No class.</description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/application-program-interface/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/application-program-interface/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Identify multiple methods for obtaining data from the internet&lt;/li>
&lt;li>Define web-scraping&lt;/li>
&lt;li>Define Application Program Interface (API)&lt;/li>
&lt;li>Explain APIs authentication keys and demonstrate secure methods for
storing these keys&lt;/li>
&lt;li>Interact with APIs&lt;/li>
&lt;li>Define JSON data structure and how to convert them to data frames&lt;/li>
&lt;/ul>
&lt;!--
* Practice tidying messy JSON data objects using `tidyr`
* Demonstrate how to use canned packages in R to access APIs
* Practice gathering data from Twitter API using the `rtweet` package in R
-->
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Chapter 1 and 4 in &lt;a href="https://steviep42.github.io/webscraping/book/">Web Scraping with
R&lt;/a>&lt;/li>
&lt;li>Setup:
&lt;ol>
&lt;li>Go to &lt;a href="http://www.geonames.org/login/">the geonames site&lt;/a> and
register an account&lt;/li>
&lt;li>Click &lt;a href="http://www.geonames.org/enablefreewebservice">here&lt;/a> to
enable the free web service&lt;/li>
&lt;li>Go to the &lt;a href="https://www.omdbapi.com/">OMDb website and click on the “API Key” tab to generate
your API key&lt;/a>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>Several packages are needed for this week’s lectures (all installed on R
workbench). If you are using R from your laptop (VS. R Workbench), I’d
suggest following the lectures using R Workbench and installing the
packages after class.&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/build-better-workflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/build-better-workflow/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Identify the importance of preprocessing data sets&lt;/li>
&lt;li>Introduce the &lt;code>recipes&lt;/code> package for preprocessing data&lt;/li>
&lt;li>Utilize &lt;code>usemodels&lt;/code> to automatically construct code templates for
common model types&lt;/li>
&lt;li>Construct workflows for machine learning&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/preprocess/">Preprocess your data&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/tune-models/">Tune model parameters&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This is not a math/stats class. In class we will &lt;strong>briefly&lt;/strong> summarize
how these methods work and spend the bulk of our time on estimating and
interpreting these models. That said, you should have some understanding
of the mathematical underpinnings of statistical learning methods prior
to implementing them yourselves. See below for some recommended
readings:&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/classification-topic-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/classification-topic-models/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduce supervised and unsupervised text classification&lt;/li>
&lt;li>Define sentiment analysis and demonstrate its use (Chapter 2)&lt;/li>
&lt;li>Define topic modeling with Latent Dirichlet allocation and demonstrate
its use (Chapter 6)&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 2 and Chapter 6 in &lt;a href="http://tidytextmining.com/">Tidy Text Mining with
R&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf">Probabilistic Topic
Models&lt;/a> by Blei,
David (2012)&lt;/li>
&lt;/ul>
&lt;!--
*[Topic modeling](/notes/topic-modeling/) from the lecture notes demonstrates how to implement this in a (semi)-tidy workflow
-->
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s in-class
materials:
&lt;code>usethis::use_course(&amp;quot;CFSS-MACSS/text-analysis-fundamentals-and-sentiment-analysis-and-tm&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;!--
* [Predicting song artist from lyrics](/notes/predicting-song-artist/)
* [Text analysis: topic modeling](/notes/topic-modeling/)
-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>See additional resources for the previous lecture on text analysis and
regular expressions&lt;/li>
&lt;li>Original &lt;a href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com">Topic Modeling (LDA)
article&lt;/a>
by Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. “Latent
Dirichlet Allocation.”&lt;/li>
&lt;li>For an introduction to supervised classification with text data, read
&lt;a href="https://smltar.com/mlclassification.html">Classification&lt;/a> in
Supervised Machine Learning for Text Analysis in R&lt;/li>
&lt;li>Two blog posts by David Robinson (co-author of &lt;code>tidytext&lt;/code>) analyzing
Donald J. Trump’s twitter account. Regardless of your political
affiliations, these are excellent examples demonstrating of the key
principles of reproducible research that we’ve learned in this course
(e.g., R Markdown documents and knitting code with output; Retrieving
data from APIs; Textual analysis with &lt;code>tidytext&lt;/code>; Visualizations with
`ggplot2)
&lt;ul>
&lt;li>&lt;a href="http://varianceexplained.org/r/trump-tweets/">Text analysis of Trump’s tweets confirms he writes only the
(angrier) Android
half&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://varianceexplained.org/r/trump-followup/">Trump’s Android and iPhone tweets, one year
later&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/data-communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/data-communication/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/data-structures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/data-structures/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Recognize and manipulate R Data Structures (especially vectors and
lists)&lt;/li>
&lt;li>Review control structures and functions&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 20 “Vectors” in &lt;a href="https://r4ds.had.co.nz/vectors.html">R for Data
Science&lt;/a>&lt;/li>
&lt;li>Optional: Chapter 14 “Strings” in &lt;a href="https://r4ds.had.co.nz/strings.html">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s in-class
exercises: &lt;code>usethis::use_course(&amp;quot;CFSS-MACSS/data-structures&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Work on &lt;a href="https://cfssmacss.netlify.app/homework/debugging-rmarkdown/">Homework 5&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/data-transformation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/data-transformation/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Identify programming as a form of problem solving&lt;/li>
&lt;li>Practice decomposing a goal into a set of discrete, computational
tasks&lt;/li>
&lt;li>Identify the basic verbs for a language of data manipulation&lt;/li>
&lt;li>Familiarize with Pipes&lt;/li>
&lt;li>Practice transforming data&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Required: read Chapter 5 “Data Transformation” and Chapter 18 “Pipes”
from &lt;a href="http://r4ds.had.co.nz/">R for Data Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/problem-solving/">Computer programming as a form of problem
solving&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/dplyr/">&lt;code>dplyr&lt;/code> in brief&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/transform-college/">Practice transforming college education
data&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
* see also: [Pipes in R](/notes/pipes/) taken from "Functions" lecture of Oct 25
-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>Cheat sheet &lt;a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf">Data Wrangling with &lt;code>dplyr&lt;/code> and
&lt;code>tidyr&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Start Homework 2&lt;/li>
&lt;li>Review this week’s readings and notes&lt;/li>
&lt;/ul>
&lt;!--
* Complete your peer evaluations for homework 01. Review the following:
 * [General Homework Rubric](/faq/homework-evaluations/)
 * [Performing peer review](/faq/peer-evaluations/)
 * To find which peers you will evaluate:
 * Navigate to the [course organization page on GitHub](https://github.coecis.cornell.edu/cis-fa22)
 * Find the `hw01` repos you can see that are not your own repo
 * Open the repos and find the pull request. You can then initiate a [code review](https://github.com/features/code-review) to leave detailed feedback.
--></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/debugging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/debugging/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Define a bug&lt;/li>
&lt;li>Review best practices for reading, writing, and styling code&lt;/li>
&lt;li>Distinguish between errors, warnings, and messages&lt;/li>
&lt;li>Identify and practice methods for error handling and recovery&lt;/li>
&lt;/ul>
&lt;!--
* Interpret function documentation
* Introduce `traceback()` and explain how to read it
-->
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read “Debugging R code” in &lt;a href="https://rstats.wtf/debugging-r-code.html">What They Forgot to Teach You About
R&lt;/a>&lt;/li>
&lt;li>Skim &lt;a href="http://style.tidyverse.org/">The &lt;code>tidyverse&lt;/code> style guide&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="http://socviz.co/appendix.html#how-to-read-an-r-help-page">How to read an R help
page&lt;/a>&lt;/li>
&lt;li>Review &lt;a href="http://r4ds.had.co.nz/iteration.html#dealing-with-failure">21.6 Dealing with failure in &lt;em>R for Data
Science&lt;/em>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>No in-class materials (today we complete in-class materials for “Data
Structures” lecture)&lt;/li>
&lt;li>Review the assigned readings for further insights and practice&lt;/li>
&lt;/ul>
&lt;h3 id="additional-resources">Additional Resources&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/style-guide/">Bugs and styling code&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/condition-handling/">Debugging and condition handling&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/naming-slides/naming-slides.pdf">&lt;em>Naming
things&lt;/em>&lt;/a> -
by Jenny Bryan. A concise guide to naming files.&lt;/li>
&lt;/ul>
&lt;h2 id="after-class">After class&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/homework/programming/">Complete Homework 4&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/distributed-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/distributed-learning/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Discuss the need for distributed computing&lt;/li>
&lt;li>Illustrate the split-apply-combine analytical pattern&lt;/li>
&lt;li>Define parallel processing&lt;/li>
&lt;li>Define SQL&lt;/li>
&lt;li>Demonstrate how to access local and remote SQL databases&lt;/li>
&lt;li>Introduce Hadoop and Spark as distributed computing platforms&lt;/li>
&lt;li>Introduce the &lt;code>sparklyr&lt;/code> package&lt;/li>
&lt;li>Demonstrate how to use &lt;code>sparklyr&lt;/code> for machine learning using the
Titanic data set&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Install &lt;code>sparklyr&lt;/code> and H2O on your local computer. Run the code below
to install all necessary packages and set the correct options.&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/exploratory-data-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/exploratory-data-analysis/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Define Exploratory Data Analysis (EDA) and types of pattern
exploration&lt;/li>
&lt;li>Demonstrate types of graphs useful for EDA and precautions when
interpreting them&lt;/li>
&lt;li>Define factors&lt;/li>
&lt;li>Practice exploring data&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 7 “Exploratory Data Analysis” and Chapter 15 “Factors”
from &lt;a href="http://r4ds.had.co.nz/">R for Data Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/exploratory-data-analysis/">Exploratory data analysis&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/exploratory-data-analysis-practice/">Practice exploring college education
data&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
* Copied from the lecture on data wrangling, notes on factors: [Practice transforming and visualizing factors](/notes/factors-exercise/)
-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>Antony Unwin &lt;a href="https://catalog.lib.uchicago.edu/vufind/Record/11609643">Graphical Data Analysis with
R&lt;/a>. It
covers a range of graphical methods for data exploration and analysis;
draws on packages beyond &lt;code>ggplot2&lt;/code> for statistical graphics.&lt;/li>
&lt;li>Cheat Sheet &lt;a href="https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-visualization.pdf">Data visualization with
ggplot2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Work on homework 2&lt;/li>
&lt;li>Review today’s lecture materials, and prepare for next class&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/extended-git-workflows/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/extended-git-workflows/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Complete the homework assignment&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/fall-break/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/fall-break/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/git-and-github/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/git-and-github/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Familiarize with R syntax, data types, and data structures&lt;/li>
&lt;li>Distinguish between R scripts (&lt;code>.R&lt;/code>), Markdown documents (&lt;code>.md&lt;/code>), and
R Markdown documents (&lt;code>.Rmd&lt;/code>)&lt;/li>
&lt;li>Identify the major components of R Markdown&lt;/li>
&lt;li>Create repositories&lt;/li>
&lt;li>Make commits and synchronize repositories from RStudio&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read chapter 4 “Workflow Basics” in &lt;a href="https://r4ds.had.co.nz/workflow-basics.html">R for Data
Science&lt;/a>&lt;/li>
&lt;li>Read Data Carpentry &lt;a href="https://datacarpentry.org/R-ecology-lesson/01-intro-to-r.html">Introduction to
R&lt;/a>&lt;/li>
&lt;li>Read chapter 27 “R Markdown” in &lt;a href="https://r4ds.had.co.nz/r-markdown.html">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s lecture and
exercises: &lt;code>usethis::use_course(&amp;quot;CFSS-MACSS/intro-r&amp;quot;)&lt;/code>[1]&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/setup/git/git-with-rstudio/">Using Git within R Studio&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://pjbartlein.github.io/REarthSysSci/markdown.html">Markdown and R
Markdown&lt;/a> by
Pat Bartlein&lt;/li>
&lt;li>&lt;a href="https://rmarkdown.rstudio.com/lesson-1.html">R Markdown from R
Studio&lt;/a> official
documentation&lt;/li>
&lt;li>Practice your R skills with &lt;a href="https://www.datacamp.com/courses/free-introduction-to-r">DataCamp free Introduction to R
course&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>If you haven’t yet:
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/setup/">Install and setup software&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Start &lt;a href="https://cfssmacss.netlify.app/homework/edit-readme/">Homework 1&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- [^bryan]: Meeting title courtesy of Jenny Bryan's ["Excuse Me, Do You Have a Moment to Talk About Version Control?"](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1399928)
 * Fill out [this survey](https://forms.gle/J8axkKpKZGxYyxYZA) -->
&lt;p>[1] If you are using R from your local machine: first install the
library by typing in your console &lt;code>install.packages(&amp;quot;usethis&amp;quot;)&lt;/code>; then
load it with &lt;code>library(usethis)&lt;/code>; finally run the code&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/grammar-of-graphics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/grammar-of-graphics/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Identify the importance of graphics in communicating information&lt;/li>
&lt;li>Define the layered grammar of graphics&lt;/li>
&lt;li>Demonstrate how to use layered grammar of graphics&lt;/li>
&lt;li>Practice generating layered graphics using
&lt;a href="https://github.com/hadley/ggplot2">&lt;code>ggplot2&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Required: read chapter 3 from &lt;a href="https://r4ds.had.co.nz/data-visualisation.html">R for Data
Science&lt;/a>. You need to
read this chapter and complete some of the exercises before coming to
class. Exercise solutions can be found
&lt;a href="https://jrnold.github.io/r4ds-exercise-solutions/">here&lt;/a>.&lt;/li>
&lt;li>Optional: read Hadley Wickham &lt;a href="https://vita.had.co.nz/papers/layered-grammar.html">A Layered Grammar of
Graphics&lt;/a> – the
“pre-print” version of the article can be downloaded for free. This
article is optional, but I strongly encourage you to skim through it
to familiarize with the theory and language of the grammar of
graphics; read especially section 3 “Components of the Layered
Grammar” and section 4 “A Hierarchy of Defaults.”&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/why-visualize-data/">Why visualize data?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/grammar-of-graphics/">The Grammar of Graphics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/gapminder/">Practice generating graphics with ggplot2&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
Optional:
* [How to build a complicated, layered graphic](/notes/minard/)
* [Exploring Minard's 1812 plot with `ggplot2`](https://github.com/andrewheiss/fancy-minard) - a much fancier (and more complex) version
-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;p>Graphical design * &lt;a href="https://www.edwardtufte.com/tufte/books_vdqi">Tufte, Edward R. &lt;em>The Visual Display of
Quantitative
Information&lt;/em>.&lt;/a> Classic
book on statistical graphics and visualization design. * &lt;a href="https://socviz.co/">Healey,
Kieran. &lt;em>Data Visualization: A Practical Guide&lt;/em>.&lt;/a> An
applied introduction to graphical design with lots of applications in
&lt;code>ggplot2&lt;/code> and many code examples.&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/hyperparameter-tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/hyperparameter-tuning/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;div class="alert alert-info" role="alert">
&lt;pre>&lt;code>note
&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class="alert alert-info" role="alert">
&lt;pre>&lt;code>note
&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="additional-readings">Additional readings&lt;/h3>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/homework/machine-learning/">Complete the machine learning homework&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/independence-day/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/independence-day/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/intro/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduction to the course&lt;/li>
&lt;li>Identify major course objectives&lt;/li>
&lt;li>Identify course logistics and expectations&lt;/li>
&lt;li>Familiarize with basic principles of programming and reproducible
workflow&lt;/li>
&lt;li>Software setup instructions&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read the “Welcome” page and chapter 1 “Introduction” in &lt;a href="http://r4ds.had.co.nz/">R for Data
Science&lt;/a>. (&lt;em>Note that there is a new draft
we’ll be moving to soon: &lt;a href="https://r4ds.hadley.nz/">Second Edition of R for Data
Science&lt;/a>&lt;/em>)&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/intro-to-course/">Introduction to computing for the social
sciences&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510">Good Enough Practices in Scientific
Computing&lt;/a>.
Additional resource and good summary of best computing practices&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Read the &lt;a href="https://cfssmacss.netlify.app/setup/">Setup&lt;/a> section and install the required software&lt;/li>
&lt;li>Fill out &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSfV_g4z7rpNWz_ONmH1oLrItXprHjo8-KBpnd19FbEJDCrEDA/viewform?usp=sf_link">this
survey&lt;/a>&lt;/li>
&lt;li>Explore this website&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/labor-day/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/labor-day/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/memorial-day/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/memorial-day/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/mlk-day/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/mlk-day/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/no-class-misc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/no-class-misc/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/pipes-functions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/pipes-functions/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review control structures&lt;/li>
&lt;li>Define functions and their purpose&lt;/li>
&lt;li>Analyze a user-written function and explain how it works&lt;/li>
&lt;li>Practice writing functions&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 17 “Introduction” and chapter 19 “Functions” in &lt;a href="http://r4ds.had.co.nz/">R for
Data Science&lt;/a>&lt;/li>
&lt;li>Review Chapter 21 “Iteration” in &lt;a href="https://r4ds.had.co.nz/iteration.html">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
See "Data transformation" lecture for further references
-->
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s in-class
exercises: &lt;code>usethis::use_course(&amp;quot;css-materials/functions&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;!--
* [Pipes in R](/notes/pipes/)
* [Functions in R](/notes/functions/)
-->
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Homework assignments&lt;/li>
&lt;li>Review today’s lecture materials, and prepare for next class&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/r-markdown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/r-markdown/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review the importance of reproducibility in scientific research&lt;/li>
&lt;li>Identify the major components of &lt;code>.Rmd&lt;/code>&lt;/li>
&lt;li>Define &lt;code>knitr&lt;/code> chunks&lt;/li>
&lt;li>Implement chunk options to customize output&lt;/li>
&lt;li>Practice different R Markdown formats&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read chapters 27 “R Markdown”, 28 “Graphics for communication”, and 29
“R Markdown formats” in &lt;a href="http://r4ds.had.co.nz">R for Data Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;p>Consult these resources for further information about R Markdown, it is
likely they will provide the answer to what you need: * &lt;a href="https://bookdown.org/yihui/rmarkdown/">R Markdown the
definitive Guide&lt;/a> * &lt;a href="https://posit.co/resources/cheatsheets/?_page=2/">R Markdown
cheat sheet&lt;/a> *
&lt;a href="https://pjbartlein.github.io/REarthSysSci/markdown.html">Markdown and R
Markdown&lt;/a> by
Pat Bartlein * &lt;a href="https://rmarkdown.rstudio.com/lesson-1.html">R Markdown from R
Studio&lt;/a> official
documentation * Info on the &lt;code>lubridate&lt;/code> package: &lt;a href="https://r4ds.had.co.nz/dates-and-times.html">Chapter 16 of R for
Data Science&lt;/a>&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/relational-data-factors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/relational-data-factors/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduce relational data&lt;/li>
&lt;li>Demonstrate how tables can be linked to one another&lt;/li>
&lt;li>Demonstrate methods in &lt;code>dplyr&lt;/code> for linking and merging related tables&lt;/li>
&lt;li>Practice joining tables&lt;/li>
&lt;li>Review factors&lt;/li>
&lt;/ul>
&lt;!-- 
*Demonstrate how to transform and reorder factors for visualizations
-->
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 13 “Relational Data” in &lt;a href="http://r4ds.had.co.nz/">R for Data
Science&lt;/a>. Do not complete exercises 13.4.6.2-3
– we will be completing these as in-class exercises&lt;/li>
&lt;li>Review Chapter 15 “Factors” in &lt;a href="http://r4ds.had.co.nz/">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/relational-data-exercise/">Practice using relational data&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
* [Relational data: a quick review](/notes/relational-data/)
* [Practice using relational data](/notes/relational-data-exercise/)
* [Practice transforming and visualizing factors](/notes/factors-exercise/)
-->
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Keep working on homework 3&lt;/li>
&lt;li>Review lectures and readings&lt;/li>
&lt;/ul>
&lt;!--
* [Complete the wrangling and visualizing data homework](/homework/wrangle-data/)
--></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/reprex-git/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/reprex-git/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review Git/GitHub basic workflow using the R GUI&lt;/li>
&lt;li>Learn how to use basic Git/GitHub workflow through the command line&lt;/li>
&lt;li>Good practices&lt;/li>
&lt;li>Common problems and how to solve them&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://happygitwithr.com/big-picture.html">Chapter 1 Why Git? Why
GitHub?&lt;/a> in &lt;em>“Happy Git
and GitHub for the useR”&lt;/em>&lt;/li>
&lt;li>Read &lt;a href="https://peerj.com/preprints/3159v2/">“Excuse me, do you have a moment to talk about version
control?”&lt;/a>&lt;/li>
&lt;li>Skim chapters 15, 16, and 17 included in the section &lt;a href="https://happygitwithr.com/usage-intro.html">Early GitHub
Wins&lt;/a> in &lt;em>“Happy Git and
GitHub for the useR”&lt;/em>&lt;/li>
&lt;li>Skim chapters 20 to 23 in the section &lt;a href="https://happygitwithr.com/git-intro.html">Git
fundamentals&lt;/a> in &lt;em>“Happy Git
and GitHub for the useR”&lt;/em>&lt;/li>
&lt;/ul>
&lt;p>We will be using R Workbench for the lecture and the in-class exercises.
If you are using R from your laptop (VS. R Workbench), make sure your
system is correctly configured, see the &lt;a href="https://cfssmacss.netlify.app/setup/git/">Git page under
Setup&lt;/a>.&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/reproducible-documents/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/reproducible-documents/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/reproducible-workflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/reproducible-workflow/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review the importance of reproducibility in scientific research&lt;/li>
&lt;li>Define a project-oriented workflow&lt;/li>
&lt;li>Practice implementing it in R&lt;/li>
&lt;li>Identify R startup procedures&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read chapters 1, 2, 3, 7 in &lt;a href="https://rstats.wtf/">What They Forgot to Teach You About
R&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>In-class practice instructions are included in the slides for today&lt;/li>
&lt;/ul>
&lt;!--
&lt;div class="alert alert-info" role="alert">
 
 note
 
&lt;/div>

-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>Book &lt;a href="https://rstats.wtf/">What They Forgot to Teach You About R&lt;/a>&lt;/li>
&lt;li>Article on &lt;a href="https://www.tidyverse.org/articles/2017/12/workflow-vs-script/">Project-oriented
workflow&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="after-class">After class&lt;/h2>
&lt;ul>
&lt;li>Complete &lt;a href="homework/homework/programming/">Hw04&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/shiny-server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/shiny-server/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review Shiny apps&lt;/li>
&lt;li>Define reactivity&lt;/li>
&lt;li>Build the server component of a Shiny app&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://cfssmacss.netlify.app/notes/shiny/">Tutorial from class&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/bensoltoff/age-rule">Git repo for dating age rule
app&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://bensoltoff.shinyapps.io/chicago-employees/">Chicago wage employees sample
app&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Finish &lt;a href="https://cfssmacss.netlify.app/homework/shiny/">Shiny homework assignment&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/shiny-ui/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/shiny-ui/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduce Shiny apps&lt;/li>
&lt;li>Demonstrate each element of a Shiny app&lt;/li>
&lt;li>Distinguish &lt;strong>UI&lt;/strong> from &lt;strong>server&lt;/strong> components&lt;/li>
&lt;li>Build the UI component of a Shiny app&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://cfssmacss.netlify.app/notes/shiny/">Tutorial from class&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/cis-ds/shiny-demo">&lt;code>shiny-demo&lt;/code>&lt;/a> - fork and clone
this repo to follow along with the in-class exercise&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/bensoltoff/age-rule">Git repo for dating age rule
app&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://bensoltoff.shinyapps.io/chicago-employees/">Chicago wage employees sample
app&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/spatial-viz-i/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/spatial-viz-i/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduce the major components of a geospatial visualization&lt;/li>
&lt;li>Identify how to draw raster maps using &lt;code>ggmaps&lt;/code> and &lt;code>get_map()&lt;/code>&lt;/li>
&lt;li>Practice generating raster maps&lt;/li>
&lt;li>Demonstrate &lt;code>geofacet&lt;/code> and &lt;code>facet_geo()&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/intro-geospatial-viz/">Introduction to geospatial
visualization&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/raster-maps-with-ggmap/">Drawing raster maps with
&lt;code>ggmap&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://cfssmacss.netlify.app/notes/raster-maps-practice/">Practice drawing raster maps&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://uchicago.ares.atlas-sys.com/ares/ares.dll?SessionID=A103809140M&amp;amp;Action=10&amp;amp;Type=10&amp;amp;Value=696335">Mapping data in &lt;em>The Truthful Art&lt;/em> by Alberto
Cairo&lt;/a> -
excellent chapter on designing data maps with lots of examples. Though
really the entire book is useful if you do a lot of work with data
visualizations of any type. &lt;strong>UChicago authentication required.&lt;/strong>&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/spatial-viz-ii/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/spatial-viz-ii/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Define shapefiles and import spatial data using the &lt;code>sf&lt;/code> package&lt;/li>
&lt;li>Draw maps using &lt;code>ggplot2&lt;/code> and &lt;code>geom_sf()&lt;/code>&lt;/li>
&lt;li>Change coordinate systems&lt;/li>
&lt;li>Generate appropriate color palettes to visualize additional dimensions
of data&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/simple-features/">Importing shapefiles using &lt;code>sf&lt;/code>&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/vector-maps/">Drawing vector maps with &lt;code>ggplot2&lt;/code> and
&lt;code>sf&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://cfssmacss.netlify.app/notes/optimal-color-palettes/">Selecting optimal color palettes&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://cfssmacss.netlify.app/notes/vector-maps-practice/">Practice drawing vector maps&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://newcatalog.library.cornell.edu/catalog/15104586">Mapping data in &lt;em>The Truthful Art&lt;/em> by Alberto
Cairo&lt;/a> -
excellent chapter on designing data maps with lots of examples. Though
really the entire book is useful if you do a lot of work with data
visualizations of any type.&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/stat-learn-classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/stat-learn-classification/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Define a decision tree&lt;/li>
&lt;li>Demonstrate how to estimate a decision tree&lt;/li>
&lt;li>Define and estimate a random forest&lt;/li>
&lt;li>Introduce the &lt;code>caret&lt;/code> package for statistical learning in R&lt;/li>
&lt;li>Define resampling method&lt;/li>
&lt;li>Compare and contrast the validation set approach with leave-one-out
and &lt;em>k&lt;/em>-fold cross-validation&lt;/li>
&lt;li>Demonstrate how to conduct cross-validation using &lt;code>rsample&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;p>This is not a math/stats class. In class we will &lt;strong>briefly&lt;/strong> summarize
how these methods work and spend the bulk of our time on estimating and
interpreting these models. That said, you should have some understanding
of the mathematical underpinnings of statistical learning methods prior
to implementing them yourselves. See below for some recommended
readings:&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/stat-learn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/stat-learn/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Review the major goals of machine learning&lt;/li>
&lt;li>Introduce the &lt;code>tidymodels&lt;/code> and &lt;code>parsnip&lt;/code> packages for estimating
regression models&lt;/li>
&lt;li>Define resampling methods for evaluating model performance&lt;/li>
&lt;li>Demonstrate how to conduct cross-validation using &lt;code>rsample&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/statistical-learning/">Statistical learning: the basics&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/start-with-models/">Build a model&lt;/a>&lt;/li>
&lt;li>Read &lt;a href="https://cfssmacss.netlify.app/notes/resampling/">Evaluate your model with resampling&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This is not a math/stats class. In class we will &lt;strong>briefly&lt;/strong> summarize
how these methods work and spend the bulk of our time on estimating and
interpreting these models. That said, you should have some understanding
of the mathematical underpinnings of statistical learning methods prior
to implementing them yourselves. See below for some recommended
readings:&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/text-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/text-data/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Introduce regular expressions&lt;/li>
&lt;li>Identify the basic workflow for conducting text analysis&lt;/li>
&lt;li>Define the tidy text formats (Chapter 1)&lt;/li>
&lt;li>Word frequencies and tf-idf (Chapter 1 and 3)&lt;/li>
&lt;/ul>
&lt;!-- 
* Demonstrate how to conduct sentiment analysis using twitter
* Explain how to generate and interpret a wordcloud -->
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;p>For this and the following lecture we use the book &lt;a href="http://tidytextmining.com/">&lt;em>Tidy Text Mining
with R&lt;/em>&lt;/a>. Before this class: read Chapter 1,
3, and 4. Before next class: read chapters 2 and 6&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/thanksgiving/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/thanksgiving/</guid><description>&lt;!--
## Overview


## Before class


## Class materials


## What you need to do after class
--></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/tidy-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/tidy-data/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Import data in R&lt;/li>
&lt;li>Define tidy data and its characteristics&lt;/li>
&lt;li>Practice tidying data&lt;/li>
&lt;/ul>
&lt;!--
* Demonstrate how vectors can be read and parsed
* Define various data file formats and functions for importation
-->
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Required: read Chapter 11 “Data Import” and Chapter 12 “Tidy data”
from &lt;a href="http://r4ds.had.co.nz/">R for Data Science&lt;/a>&lt;/li>
&lt;li>Optional: read Chapter 10 “Tibbles” from &lt;a href="http://r4ds.had.co.nz/">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/tidy-data/">Tidy data&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/tidy-exercise/">Practice tidying data&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
* [Importing data into R](/notes/importing-data/)
* [Tidy data](/notes/tidy-data/)
* [Practice tidying data](/notes/tidy-exercise/)
-->
&lt;h2 id="additional-resources">Additional resources&lt;/h2>
&lt;ul>
&lt;li>Lohr. 2014. &lt;a href="http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html?_r=0">For Big-Data Scientists, “Janitor Work” Is Key Hurdle to
Insights.&lt;/a>
&lt;em>New York Times&lt;/em>&lt;/li>
&lt;li>&lt;a href="http://www.mimno.org/articles/carpentry/">Data Carpentry&lt;/a> a response
to the NYTimes article&lt;/li>
&lt;li>&lt;a href="https://tidyr.tidyverse.org/articles/pivot.html">Pivoting in &lt;code>tidyr&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Complete &lt;a href="https://cfssmacss.netlify.app/homework/explore-data/">Homework 2&lt;/a>&lt;/li>
&lt;li>Review today’s lecture materials, and prepare for next class&lt;/li>
&lt;li>Start &lt;a href="https://cfssmacss.netlify.app/homework/wrangle-data/">Homework 3&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/tidyeval/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/tidyeval/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/homework/programming/">Complete the programming homework&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/vectors-iteration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/vectors-iteration/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;!--
* Review the major types of vectors
* Demonstrate how to subset vectors
* Demonstrate vector recycling
* Define lists
-->
&lt;ul>
&lt;li>Introduce if-else statements&lt;/li>
&lt;li>Introduce iterative operations&lt;/li>
&lt;li>Practice writing iterative operations using loops, &lt;code>map()&lt;/code> functions,
and &lt;code>dplyr::across()&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Read Chapter 13 “Control Structures” in &lt;a href="https://bookdown.org/rdpeng/rprogdatascience/control-structures.html">R programming for Data
Science&lt;/a>&lt;/li>
&lt;li>Read Chapter 21 “Iteration” in &lt;a href="https://r4ds.had.co.nz/iteration.html">R for Data
Science&lt;/a>&lt;/li>
&lt;/ul>
&lt;!--
* Read chapters 14.1-2, 20-21 from [R for Data Science](http://r4ds.had.co.nz/)
-->
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s in-class
exercises: &lt;code>usethis::use_course(&amp;quot;css-materials/control-structures&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;!--
* [Data storage types](/notes/vectors/)
* [Iteration](/notes/iteration/)
* [Column-wise operations](https://dplyr.tidyverse.org/dev/articles/colwise.html)
-->
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>Complete/Start Homework assignments&lt;/li>
&lt;li>Review today’s lecture materials, and prepare for next class&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/web-scraping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/web-scraping/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Define HTML and CSS selectors&lt;/li>
&lt;li>Introduce the &lt;code>rvest&lt;/code> package&lt;/li>
&lt;li>Demonstrate how to extract information from HTML pages&lt;/li>
&lt;li>Practice scraping data&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>Chapter 1 and 4 in &lt;a href="https://steviep42.github.io/webscraping/book/">Web Scraping with
R&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Several packages are needed for this week’s lectures (all installed on R
workbench). If you are using R from your laptop (VS. R Workbench), I’d
suggest following the lectures using R Workbench and installing the
packages after class.&lt;/p>
&lt;h2 id="additional-resources">Additional Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://rvest.tidyverse.org/articles/harvesting-the-web.html">&lt;code>rvest&lt;/code>
documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://cran.r-project.org/web/packages/httr/">&lt;code>httr&lt;/code> documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/yusuzech/r-web-scraping-cheat-sheet/blob/master/README.md">Web Scraping using R Cheat
Sheet&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ropensci/webservices">More install-and-play API packages for
R&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>Run the code below in your console to download today’s in-class
exercises: &lt;code>usethis::use_course(&amp;quot;CFSS-MACSS/web-scraping&amp;quot;)&lt;/code>&lt;/li>
&lt;/ul>
&lt;!--
* [Web scraping](/notes/web-scraping/)
* `rvest`
 * Load the library (`library(rvest)`)
 * `demo("tripadvisor")` - scraping a Trip Advisor page
 * `demo("united")` - how to scrape a web page which requires a login
 * [Scraping IMDB](https://blog.rstudio.org/2014/11/24/rvest-easy-web-scraping-with-r/)
--></description></item><item><title/><link>https://cfssmacss.netlify.app/schedule/work-with-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/schedule/work-with-models/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;ul>
&lt;li>Combine multiple &lt;code>ggplot()&lt;/code> objects using &lt;code>patchwork&lt;/code>&lt;/li>
&lt;li>Fit multiple regression lines as separate layers in &lt;code>ggplot()&lt;/code>&lt;/li>
&lt;li>Generate legends using single-value variables&lt;/li>
&lt;li>Identify principles for visualizing statistical model estimates&lt;/li>
&lt;li>Generate predicted values from models for graphing&lt;/li>
&lt;li>Plot marginal effects using &lt;code>margins&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="before-class">Before class&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Read &lt;a href="https://socviz.co/modeling.html">Work with Models in &lt;em>Data Visualization: A Practical
Introduction&lt;/em>&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Install the following packages:&lt;/p>
&lt;pre>&lt;code>install.packages(c(&amp;quot;socviz&amp;quot;, &amp;quot;margins&amp;quot;))
remotes::install_github(&amp;quot;thomasp85/patchwork&amp;quot;)
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h2 id="class-materials">Class materials&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/notes/work-with-models-exercise/">Working with statistical models&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-you-need-to-do-after-class">What you need to do after class&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cfssmacss.netlify.app/homework/statistical-learning/">Complete the statistical learning
homework&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/a-deep-dive-into-r-markdown/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/a-deep-dive-into-r-markdown/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>A deep dive into R Markdown&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# A deep dive into R Markdown
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






## R Markdown: resources 

Assigned readings:
* Chapters 27 "R Markdown", 28 "Graphics for communication", and 29 "R Markdown formats" in [R for Data Science](http://r4ds.had.co.nz)

Additional resources:

* [R Markdown the definitive Guide](https://bookdown.org/yihui/rmarkdown/)
* [R Markdown cheat sheet](https://posit.co/resources/cheatsheets/?_page=2/)
* [Markdown and R Markdown](https://pjbartlein.github.io/REarthSysSci/markdown.html) by Pat Bartlein
* [R Markdown from R Studio](https://rmarkdown.rstudio.com/lesson-1.html) official documentation
* `Rmarkdown.Rmd` from lecture two: `usethis::use_course("CFSS-MACSS/intro-r")`
---

## R Markdown and Markdown

**R Markdown**: text file that uses the extension `.Rmd`.

**Markdown**: text file that use the extension `.md`

* Similarities: 
 * they use the same syntax, R Markdown is just an extension of the markdown syntax
* Differences: 
 * R code cannot be executed in a `.md` VS we can embed and execute R code in a `.Rmd `
 * An `.md` can be generated from a `.Rmd` but not the other way around

---

## R Markdown: Knitting process

R Markdown files allow to generate well-formatted documents (md, pdf, word, html, etc.) that include text, code, and output.

To create such documents, you “Knit” or “render” them in three ways: 

1. by clicking the “Knit” button in the script editor panel of your R Markdown file and select the desired output

1. by adding the desired output in the YAML header such as: `github_document`, `pdf_document`, `word_document`, `html_document`, etc. (notice: without `\(\LaTeX\)` installed, the pdf won't work)

1. by using `render()`, as explained [here](https://pkgs.rstudio.com/rmarkdown/reference/render.html). For example, run in your console: `rmarkdown::render("my-document.Rmd", output_format: html_document`)

---

## R Markdown: Knitting process for presentations

* [ioslides](http://rmarkdown.rstudio.com/ioslides_presentation_format.html)
* [reveal.js](http://rmarkdown.rstudio.com/revealjs_presentation_format.html)
* [Slidy](http://rmarkdown.rstudio.com/slidy_presentation_format.html)
* [Beamer](http://rmarkdown.rstudio.com/beamer_presentation_format.html)
* [`xaringan`](https://bookdown.org/yihui/rmarkdown/xaringan.html)

---

## R Markdown: Knitting process

&amp;lt;img src="rmarkdownflow.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

When you knit the document:

1. R Markdown sends the .Rmd file to knitr: http://yihui.name/knitr/

1. Knitr executes all of the code chunks and creates a new plain markdown (.md) file which includes the code and its output

1. This plain markdown file is then converted by pandoc into any number of output types including html, PDF, Word document, etc.: http://pandoc.org/

---

## R Markdown: Three main components

1. A **YAML header** surrounded by `---` at the top of the file

1. Text mixed with simple text formatting using the [Markdown syntax](../hw01-edit-README.html)

1. **Chunks** of R code surrounded by ` ``` `
To insert them:
 * keyboard shortcut Cmd/Ctrl + Alt + I
 * “Insert” button icon in the editor toolbar
 * manually type the chunk delimiters ` ```{r} and ``` `

---

## R Markdown: Basic Syntax

```` 
_Italics_ and *Italics*
````
*Italics* and _Italics_

--

````
__Bold__ and **Bold**
````
**Bold** and __Bold__

--

````
~~Strikethrough~~ 
````
~~Strikethrough~~ 

--

````
`inline code`
````
`inline code`

---

## R Markdown: Basic Syntax

Use a backslash `\` to make special characters visible, e.g., to interpret them literally:

--

````
I want to use \* for emphasis, not for italics: \*great\*
````
I want to use \* for emphasis, not for italics: \*great\*

--

````
I do not want a list here, I want the literal number followed by a dot: 1\.
````
I do not want a list here, I want the literal number followed by a dot: 1\.




---

## R Markdown: Unordered lists

Use either `*`, `-`, or `+`, then a space, then the text:

.pull-left[

````
+ item 1
 + sub
 + sub
- item 2
 - sub
 - sub
+ item 3
 - sub
 * sub
- item 4
 * sub
 * sub
````

]
.pull-right[

+ item 1
 + sub
 + sub
- item 2
 - sub
 - sub
+ item 3
 - sub
 * sub
- item 4
 * sub
 * sub
]

---

## R Markdown: Ordered lists

Write the number 1, followed by a period or a round bracket, then a space, then the text. 
For nested lists, indent once and use `+`, `*`, or `-` followed by a space: 

.pull-left[

````
1. item 1
 + sub
 + sub sub
 + sub
1. item 2
 * sub
 * sub
1) item 3
 - sub
 + sub
````

]
.pull-right[

1. item 1
 + sub
 + sub sub
 + sub
1) item 2
 * sub
 * sub sub
 * sub
1. item 3
 - sub
 + sub sub
 
]

---

## R Markdown: Headers

Use `#` to add headers. The more `#`, the smallest the header:

.pull-left[

````
# Main title, 1st level

## Section title, 2nd level

### Subsection title, 3rd level

#### Subsection title, 4th level

Write regular-sized sentences without `#`

````

]
.pull-right[

# Main title, 1st level

## Section title, 2nd level

### Subsection title, 3rd level

#### Subsection title, 4th level

Write regular-sized sentences without `#`

]

--

NB: in R scripts or in `.Rmd` code chunks, `#` are used for comments, the number of `#` does not matter for comments

---

## R Markdown: links, tables, pictures

**Link**: write the linked text in brackets `[]`, followed immediately by the URL in parentheses `()`. 

````
[R Studio](https://www.rstudio.com/)
````

**Picture**: make sure the picture is in your folder, then type `![text](picture link, "title")`. The title is optional.

**Table**: use `-----` for rows and `|` for columns. See https://www.markdownguide.org/extended-syntax/

---


## R Markdown: tables



--

&amp;lt;table&amp;gt;
&amp;lt;caption&amp;gt;Table 1. etc.&amp;lt;/caption&amp;gt;
 &amp;lt;thead&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Id &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Year &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Month &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Intent &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Police &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Sex &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:center;"&amp;gt; Age &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:left;"&amp;gt; Race &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:right;"&amp;gt; Place &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:left;"&amp;gt; Education &amp;lt;/th&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/thead&amp;gt;
&amp;lt;tbody&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 1 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Jan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 34 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Asian/Pacific Islander &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; BA+ &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Jan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; F &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 21 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Street &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Some college &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 3 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Jan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 60 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Other specified &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; BA+ &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 4 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 64 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; BA+ &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 5 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 31 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Other specified &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 6 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 17 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Less than HS &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 7 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Undetermined &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 48 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 8 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Mar &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 41 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 9 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Accidental &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 50 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Other specified &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Some college &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 11 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Feb &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 30 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Some college &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 12 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Jan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 21 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 13 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Mar &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 43 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Less than HS &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 14 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Mar &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 34 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 15 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Mar &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Homicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 27 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 16 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 2012 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Mar &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 0 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; M &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:center;"&amp;gt; 27 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; Home &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
&amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;



---

## R Markdown: Inline code

.small[

````default
---
title: "Gun deaths"
output: html_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rcis)
```

## Gun deaths by age

Data for this plot come from the `gun_deaths` dataset.We have data about `r nrow(gun_deaths)` individuals killed by guns.
Only `r nrow(gun_deaths) - nrow(youth)` are older than 65. The distribution of the remainder is shown in the figure below.

```{r youth-dist, fig.cap = "Gun Death Victims Over 65", echo = FALSE}
youth &amp;lt;- gun_deaths %&amp;gt;% filter(age &amp;lt;= 65)
youth %&amp;gt;% 
 ggplot(aes(age)) + 
 geom_freqpoly(binwidth = 1)
```
````

]

---

## R Markdown: Inline code




```markdown
Data for this plot come from the `gun_deaths` dataset.
We have data about `r nrow(gun_deaths)` individuals killed by guns.

Only `r nrow(gun_deaths) - nrow(youth)` are older than 65.
The distribution of the remainder is shown in the previous figure.
```

--

Data for this plot come from the `gun_deaths` dataset.
We have data about 100798 individuals killed by guns.

Only 15687 are older than 65.
The distribution of the remainder is shown in the previous figure.


---

class: inverse, middle

# Practice 1 (~10 min)

Complete this tutorial: &amp;lt;https://commonmark.org/help/tutorial/&amp;gt;


---

## R Markdown: Naming code chunks 

A named code chunk:

````markdown
```{r youth-dist2}
# code goes here
```
````

Advantages:

1. More easily navigate to specific chunks (using the drop-down code navigator in the bottom-left of the script editor). Notice: Two code chunks should not have the same name.

1. Graphics produced by the chunks will have useful names

1. Used with `cache = TRUE`, allows to set up cached chunks to avoid re-performing expensive computations on every run 

--

`cache = TRUE` save the output of the chunk to a file on memory. On subsequent runs, R will check if the code chunk has changed; if not, R reuses it rather than re-running (Ch. 27 R for Data Science)

---

## R Markdown: Code chunks options

**`eval = FALSE`** code is not evaluated; code appears in the report, results do not appear in the report (useful to show an example code in your report, or when code has an error you want to show). Default is `eval = TRUE` 

**`include = FALSE`** code is evaluated; code does not appear in the report, nor do results (useful when you do not want to clutter your report with too much code). Default is `include = TRUE`

**`echo = FALSE`** code is evaluated; code does not appear in the report, results appear in the report (useful to show your output to people that are not interested in the code that produced it, or for demos of hw2 and hw3 which had the graphs but not code). Default is `echo = TRUE`

**`error = TRUE`** code is evaluated and appear in the report even if there is an error (e.g. to knit with errors). Default is `error = FALSE`

**`message = FALSE`** or **`warning = FALSE`** prevents messages or warnings from appearing in the report. Defaults is `message = TRUE` or `warning = TRUE`

---

## R Markdown: Code chunks options

&amp;lt;img src="chunk_options.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

Source: https://r4ds.had.co.nz/r-markdown.html#chunk-options

Full list: full list at http://yihui.name/knitr/options/

---

## Global options

Use global options if you want to change the default chunk options for all chunks in your file. 

In a code chunk (usually at the top of the document) type `knitr::opts_chunk$set()` with your options. For example, if we want to hide the code by default:

```r
knitr::opts_chunk$set(
 echo = FALSE
)
```

---

class: inverse, middle

# Practice 2 (~10 min)

Open **`gun-deaths.Rmd`** 
&amp;gt; `usethis::use_course("CFSS-MACSS/a-deep-dive-into-r-markdown")`

1. Observe how the file is structured, then knit it, and observe the output

2. Modify the code chunks options of the two code chunks that generate the graphs. For example: set one chunk to `eval = FALSE` and the other to `include = FALSE` and knit it; or create a bug in one of the code chunk and try to knit it

3. Add to the global options `echo = FALSE` and observe the output

---

## YAML header specifications


```default
---
title: "Gun deaths"
author: "Jean Clipperton"
output: html_document
---
```

* **Y**et **A**nother **M**arkup **L**anguage
* Standardized format for storing hierarchical data in a human-readable syntax
* Defines how your `.Rmd` file is rendered

See Chapter 27 of R for Data Science for more on YAML header (e.g., parameters, bibliogrpahies and citations). Here we review some topics not mentioned in that Chapter.

---

## YAML header specifications


```default
---
title: "Gun deaths"
author: "Jean Clipperton"
output: html_document
---
```

---

## YAML header specifications: Table of contents


```default
---
title: "Gun deaths"
author: "Jean Clipperton"
output: 
 html_document
 toc: true
 toc_depth: 2
---
```

---

## YAML header specifications: Apparence and Style


```default
---
title: "Gun deaths"
author: "Jean Clipperton"
output: 
 html_document
 theme: readable
 fig_width: 8
 fig_height: 6
---
```


---

## YAML header specifications: Date as string

We can add a date and modify it every time we modify our file. We can add a date as a simple string:


```default
---
title: "Gun deaths"
output: html_document
date: "July 3, 2023"
---
```

--

But adding the date manually is not scalable. We can add it automatically instead. 

---

## YAML header specifications: `lubridate` 

Add the date automatically using `lubridate`:


```default
---
title: "Gun deaths"
output: html_document
date: "`r lubridate::today()`"
---
```

For more on the `lubridate` package: [Chapter 16 of R for Data Science](https://r4ds.had.co.nz/dates-and-times.html)

---

## YAML header specifications: `Sys.Date`

Add the date automatically using `Sys.Date`:


```default
---
title: "Gun deaths"
output: html_document
date: "`r Sys.Date()`"
---
```

`Sys.Date` returns the current day in the current time zone. The default uses the format year/month/day.

---

## YAML header specifications: `Sys.time`

Add the date automatically using `Sys.time`:


```default
---
title: "Gun deaths"
output: html_document
date: "`r format (Sys.time(), '%d, %B, %Y')`"
---
```

`Sys.time` returns an absolute date-time value which can be converted to various time zones, and it more easily is customizable.

This format says we want the date as: numeric day, full name of the month, and full (4-digit) year, but it can be changed

---

## YAML header specifications: Date formats


Symbol |	Meaning	| Example |
-------|----------|---------|
%d |	day as a number | 	01-31 |
%a | abbreviated weekday | Mon |
%A |	unabbreviated weekday	| Monday |
%m |	month | 00-12 |
%b | abbreviated month | Jan |
%B |	unabbreviated month	|January |
%y | 2-digit year | 07 |
%Y |	4-digit year	| 2007 |

Source: https://www.statmethods.net/input/dates.html 
Documentation: https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/strptime 

---

class: inverse, middle

# Practice 3 (~10 min)

Open **`gun-deaths.Rmd`** (get the repo from the website). Modify the YAML header as follows:

1. Add a table of contents (toc), a theme (https://www.datadreaming.org/post/r-markdown-theme-gallery/), and set the default fig_width to 6 and fig_height to 4 

2. Instead of using `lubridate`, modify the date using `Sys.time()`. Render the following two dates exaclty as they appear here (using a comma (,) in the first and a slash (/) in the second):
 * July 3, 2023
 * 2023/07/03
 
3. Make a table with at least three rows and at least three columns

---

class: tiny

## R scripts


```r
# gun-deaths.R
# 2017-02-01
# Examine the distribution of age of victims in gun_deaths

# load packages
library(tidyverse)
library(rcis)

# filter data for under 65
youth &amp;lt;- gun_deaths %&amp;gt;%
 filter(age &amp;lt;= 65)

# number of individuals under 65 killed
nrow(gun_deaths) - nrow(youth)

# graph the distribution of youth
youth %&amp;gt;% 
 ggplot(aes(age)) + 
 geom_freqpoly(binwidth = 1)

# graph the distribution of youth, by race
youth %&amp;gt;%
 ggplot(aes(fct_infreq(race) %&amp;gt;% fct_rev())) +
 geom_bar() +
 coord_flip() +
 labs(x = "Victim race")
```

---

### When to use a script

* For troubleshooting
* Initial stages of project
* Building a reproducible pipeline
* It depends

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/build-a-better-workflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/build-a-better-workflow/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Build a better workflow&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="INFO 5940 Cornell University" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Build a better workflow
]
.author[
### INFO 5940 &lt;br /> Cornell University
]

---






class: inverse, middle

# Build a better training set with `recipes`

---
class: middle, frame

## Recipes

&amp;lt;iframe src="https://recipes.tidymodels.org" width="100%" height="400px" data-external="1"&amp;gt;&amp;lt;/iframe&amp;gt;

---

## Preprocessing options

- Encode categorical predictors
- Center and scale variables
- Handle class imbalance
- Impute missing data
- Perform dimensionality reduction 
- *A lot more!*

---

&amp;lt;img src="images/workflows/workflows.013.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---


## To build a recipe

1. Start the `recipe()`
1. Define the .display[variables] involved
1. Describe **prep**rocessing .display[step-by-step]

---

## `recipe()`

Creates a recipe for a set of variables


```r
recipe(test ~ ., data = bechdel)
```

---

## `recipe()`

Creates a recipe for a set of variables


```r
rec &amp;lt;- recipe(test ~ ., data = bechdel)
```

---

## `step_*()`

Adds a single transformation to a recipe. Transformations are replayed in order when the recipe is run on data.


```r
rec &amp;lt;- recipe(test ~ ., data = bechdel) %&amp;gt;%
 step_other(genre, threshold = .05)
```

---

&amp;lt;img src="index_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

.pull-left[

## Before recipe


```
## # A tibble: 14 × 2
## genre n
## &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1 Action 334
## 2 Comedy 286
## 3 Drama 236
## 4 Adventure 86
## 5 Animation 82
## 6 Crime 77
## 7 Horror 67
## 8 Biography 58
## 9 Mystery 10
## 10 Fantasy 6
## # … with 4 more rows
## # ℹ Use `print(n = ...)` to see more rows
```

]


.pull-right[

## After recipe


```
## # A tibble: 8 × 2
## genre n
## &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Action 334
## 2 Comedy 286
## 3 Drama 236
## 4 Adventure 86
## 5 other 85
## 6 Animation 82
## 7 Crime 77
## 8 Horror 67
```

]

---

## `step_*()`

Complete list at:
&amp;lt;https://recipes.tidymodels.org/reference/index.html&amp;gt;

&amp;lt;iframe src="https://recipes.tidymodels.org/reference/index.html" width="100%" height="400px" data-external="1"&amp;gt;&amp;lt;/iframe&amp;gt;

---

## K Nearest Neighbors (KNN)

To predict the outcome of a new data point:

- Find the K most similar old data points
- Take the average/mode/etc. outcome

---

## To specify a model with `parsnip`


1. Pick a .display[model]
1. Set the .display[engine]
1. Set the .display[mode] (if needed)

---

## To specify a KNN model with `parsnip`


```r
knn_mod &amp;lt;- nearest_neighbor() %&amp;gt;% 
 set_engine("kknn") %&amp;gt;% 
 set_mode("classification") 
```

---

## Fact

KNN requires all numeric predictors, and all need to be **centered** and **scaled**. 

What does that mean?

---

## Quiz

Why do you need to "train" a recipe?

--

Imagine "scaling" a new data point. What do you subtract from it? 
What do you divide it by?

---

&amp;lt;img src="images/pca.002.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="images/pca.003.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="images/pca.004.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Guess

.left-column[


```
# A tibble: 5 × 1
 rated
 &amp;lt;chr&amp;gt;
1 R 
2 PG-13
3 PG 
4 G 
5 NC-17
```

]

.right-column[


```
# A tibble: 1,394 × 5
 R `PG-13` PG G `NC-17`
 &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1 1 0 0 0 0
 2 1 0 0 0 0
 3 0 1 0 0 0
 4 0 1 0 0 0
 5 1 0 0 0 0
 6 1 0 0 0 0
 7 0 1 0 0 0
 8 0 1 0 0 0
 9 1 0 0 0 0
10 1 0 0 0 0
# … with 1,384 more rows
# ℹ Use `print(n = ...)` to see more rows
```

]

---

## Dummy Variables


```r
glm(test ~ rated, family = "binomial", data = bechdel)
```


```
## # A tibble: 5 × 5
## term estimate std.error statistic p.value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) -0.470 0.403 -1.17 0.244
## 2 ratedNC-17 -1.14 1.17 -0.976 0.329
## 3 ratedPG 0.225 0.427 0.527 0.598
## 4 ratedPG-13 0.354 0.412 0.859 0.391
## 5 ratedR 0.198 0.411 0.482 0.630
```

---

## `step_dummy()`

Converts nominal data into numeric dummy variables, needed as predictors for models like KNN.


```r
rec &amp;lt;- recipe(test ~ ., data = bechdel) %&amp;gt;%
 step_other(genre, threshold = .05) %&amp;gt;% 
* step_dummy(all_nominal_predictors())
```

.footnote[You *don't* need this for decision trees or ensembles of trees]

---

## Quiz

How does `recipes` know which variables are **numeric** and what is **nominal**?

--


```r
rec &amp;lt;- recipe(
 test ~ ., 
* data = bechdel
 )
```

---

## Quiz

How does `recipes` know what is a **predictor** and what is an **outcome**?

--


```r
rec &amp;lt;- recipe(
* test ~ .,
 data = bechdel
 )
```

--

.center[The .display[formula] &amp;amp;rarr; *indicates outcomes vs predictors*]


--

.center[The .display[data] &amp;amp;rarr; *is only used to catalog the names and types of each variable*]

---

## Selectors

Helper functions for selecting sets of variables


```r
rec %&amp;gt;% 
 step_novel(all_nominal()) %&amp;gt;%
 step_zv(all_predictors())
```

---

class: middle



&lt;div id="oyseelehiv" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
&lt;style>html {
 font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#oyseelehiv .gt_table {
 display: table;
 border-collapse: collapse;
 margin-left: auto;
 margin-right: auto;
 color: #333333;
 font-size: 18px;
 font-weight: normal;
 font-style: normal;
 background-color: #FFFFFF;
 width: 90%;
 border-top-style: solid;
 border-top-width: 2px;
 border-top-color: #A8A8A8;
 border-right-style: none;
 border-right-width: 2px;
 border-right-color: #D3D3D3;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #A8A8A8;
 border-left-style: none;
 border-left-width: 2px;
 border-left-color: #D3D3D3;
}

#oyseelehiv .gt_heading {
 background-color: #FFFFFF;
 text-align: center;
 border-bottom-color: #FFFFFF;
 border-left-style: none;
 border-left-width: 1px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 1px;
 border-right-color: #D3D3D3;
}

#oyseelehiv .gt_title {
 color: #333333;
 font-size: 125%;
 font-weight: initial;
 padding-top: 4px;
 padding-bottom: 4px;
 padding-left: 5px;
 padding-right: 5px;
 border-bottom-color: #FFFFFF;
 border-bottom-width: 0;
}

#oyseelehiv .gt_subtitle {
 color: #333333;
 font-size: 85%;
 font-weight: initial;
 padding-top: 0;
 padding-bottom: 6px;
 padding-left: 5px;
 padding-right: 5px;
 border-top-color: #FFFFFF;
 border-top-width: 0;
}

#oyseelehiv .gt_bottom_border {
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
}

#oyseelehiv .gt_col_headings {
 border-top-style: solid;
 border-top-width: 2px;
 border-top-color: #D3D3D3;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 border-left-style: none;
 border-left-width: 1px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 1px;
 border-right-color: #D3D3D3;
}

#oyseelehiv .gt_col_heading {
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: normal;
 text-transform: inherit;
 border-left-style: none;
 border-left-width: 1px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 1px;
 border-right-color: #D3D3D3;
 vertical-align: bottom;
 padding-top: 5px;
 padding-bottom: 6px;
 padding-left: 5px;
 padding-right: 5px;
 overflow-x: hidden;
}

#oyseelehiv .gt_column_spanner_outer {
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: normal;
 text-transform: inherit;
 padding-top: 0;
 padding-bottom: 0;
 padding-left: 4px;
 padding-right: 4px;
}

#oyseelehiv .gt_column_spanner_outer:first-child {
 padding-left: 0;
}

#oyseelehiv .gt_column_spanner_outer:last-child {
 padding-right: 0;
}

#oyseelehiv .gt_column_spanner {
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 vertical-align: bottom;
 padding-top: 5px;
 padding-bottom: 5px;
 overflow-x: hidden;
 display: inline-block;
 width: 100%;
}

#oyseelehiv .gt_group_heading {
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: initial;
 text-transform: inherit;
 border-top-style: solid;
 border-top-width: 2px;
 border-top-color: #D3D3D3;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 border-left-style: none;
 border-left-width: 1px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 1px;
 border-right-color: #D3D3D3;
 vertical-align: middle;
}

#oyseelehiv .gt_empty_group_heading {
 padding: 0.5px;
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: initial;
 border-top-style: solid;
 border-top-width: 2px;
 border-top-color: #D3D3D3;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 vertical-align: middle;
}

#oyseelehiv .gt_from_md > :first-child {
 margin-top: 0;
}

#oyseelehiv .gt_from_md > :last-child {
 margin-bottom: 0;
}

#oyseelehiv .gt_row {
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
 margin: 10px;
 border-top-style: solid;
 border-top-width: 1px;
 border-top-color: #D3D3D3;
 border-left-style: none;
 border-left-width: 1px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 1px;
 border-right-color: #D3D3D3;
 vertical-align: middle;
 overflow-x: hidden;
}

#oyseelehiv .gt_stub {
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: initial;
 text-transform: inherit;
 border-right-style: solid;
 border-right-width: 2px;
 border-right-color: #D3D3D3;
 padding-left: 5px;
 padding-right: 5px;
}

#oyseelehiv .gt_stub_row_group {
 color: #333333;
 background-color: #FFFFFF;
 font-size: 100%;
 font-weight: initial;
 text-transform: inherit;
 border-right-style: solid;
 border-right-width: 2px;
 border-right-color: #D3D3D3;
 padding-left: 5px;
 padding-right: 5px;
 vertical-align: top;
}

#oyseelehiv .gt_row_group_first td {
 border-top-width: 2px;
}

#oyseelehiv .gt_summary_row {
 color: #333333;
 background-color: #FFFFFF;
 text-transform: inherit;
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
}

#oyseelehiv .gt_first_summary_row {
 border-top-style: solid;
 border-top-color: #D3D3D3;
}

#oyseelehiv .gt_first_summary_row.thick {
 border-top-width: 2px;
}

#oyseelehiv .gt_last_summary_row {
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
}

#oyseelehiv .gt_grand_summary_row {
 color: #333333;
 background-color: #FFFFFF;
 text-transform: inherit;
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
}

#oyseelehiv .gt_first_grand_summary_row {
 padding-top: 8px;
 padding-bottom: 8px;
 padding-left: 5px;
 padding-right: 5px;
 border-top-style: double;
 border-top-width: 6px;
 border-top-color: #D3D3D3;
}

#oyseelehiv .gt_striped {
 background-color: rgba(128, 128, 128, 0.05);
}

#oyseelehiv .gt_table_body {
 border-top-style: solid;
 border-top-width: 2px;
 border-top-color: #D3D3D3;
 border-bottom-style: solid;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
}

#oyseelehiv .gt_footnotes {
 color: #333333;
 background-color: #FFFFFF;
 border-bottom-style: none;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 border-left-style: none;
 border-left-width: 2px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 2px;
 border-right-color: #D3D3D3;
}

#oyseelehiv .gt_footnote {
 margin: 0px;
 font-size: 90%;
 padding-left: 4px;
 padding-right: 4px;
 padding-left: 5px;
 padding-right: 5px;
}

#oyseelehiv .gt_sourcenotes {
 color: #333333;
 background-color: #FFFFFF;
 border-bottom-style: none;
 border-bottom-width: 2px;
 border-bottom-color: #D3D3D3;
 border-left-style: none;
 border-left-width: 2px;
 border-left-color: #D3D3D3;
 border-right-style: none;
 border-right-width: 2px;
 border-right-color: #D3D3D3;
}

#oyseelehiv .gt_sourcenote {
 font-size: 90%;
 padding-top: 4px;
 padding-bottom: 4px;
 padding-left: 5px;
 padding-right: 5px;
}

#oyseelehiv .gt_left {
 text-align: left;
}

#oyseelehiv .gt_center {
 text-align: center;
}

#oyseelehiv .gt_right {
 text-align: right;
 font-variant-numeric: tabular-nums;
}

#oyseelehiv .gt_font_normal {
 font-weight: normal;
}

#oyseelehiv .gt_font_bold {
 font-weight: bold;
}

#oyseelehiv .gt_font_italic {
 font-style: italic;
}

#oyseelehiv .gt_super {
 font-size: 65%;
}

#oyseelehiv .gt_two_val_uncert {
 display: inline-block;
 line-height: 1em;
 text-align: right;
 font-size: 60%;
 vertical-align: -0.25em;
 margin-left: 0.1em;
}

#oyseelehiv .gt_footnote_marks {
 font-style: italic;
 font-weight: normal;
 font-size: 75%;
 vertical-align: 0.4em;
}

#oyseelehiv .gt_asterisk {
 font-size: 100%;
 vertical-align: 0;
}

#oyseelehiv .gt_slash_mark {
 font-size: 0.7em;
 line-height: 0.7em;
 vertical-align: 0.15em;
}

#oyseelehiv .gt_fraction_numerator {
 font-size: 0.6em;
 line-height: 0.6em;
 vertical-align: 0.45em;
}

#oyseelehiv .gt_fraction_denominator {
 font-size: 0.6em;
 line-height: 0.6em;
 vertical-align: -0.05em;
}
&lt;/style>
&lt;table class="gt_table">
 
 &lt;thead class="gt_col_headings">
 &lt;tr>
 &lt;th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">selector&lt;/th>
 &lt;th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">description&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody class="gt_table_body">
 &lt;tr>&lt;td class="gt_row gt_left">&lt;div class='gt_from_md'>&lt;p>&lt;code>all_predictors()&lt;/code>&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/data-structures/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/data-structures/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Data Structures&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data Structures
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# R Base Data Structures

&amp;lt;!-- notes:
this is a new lecture that focuses on a general review of data structures
from the original lecture ("vectors-and-iteration") I kept the vectors and lists here 
and I need to enlarge this lecture with more data structures
I do not think I need all libraries listed there, double check

also check this lecture corresponding pages on the syllabus 
this lecture does not have notes (content &amp;gt; notes)
make sure to do that ahead of time to ensure things work!
--&amp;gt;

---

### R Base Data Structures

R data structures:
* Vectors
* Matrices
* Lists
* Data frames
* Arrays

These data structures can be organized by:
- their dimensions (1d, 2d, or nd)
- whether they are homogeneous (all contents must be of the same type, like atomic vectors and matrices) or heterogeneous (contents can be of different types, like lists and data frames)

Please, review:
* Lecture 2 (`introR_lecture`) to define, subset, and manipulate these data structures
* Chapter 20 "Vectors" in R for Data Science

---

### R is fundamentally a vector-based program

So far, we have been using predominantly data frames, which are very common when working with social science data. 

However, data frames are not actually the most fundamental type of object in R: **vectors are the ultimate building blocks of objects within R**.

A matrix is made of vectors, a list is made of vectors (a list is still a vector in R but not an atomic one), data frames are made by lists, etc.

Basically in R either something is a vector, or it's NULL...

---

### R is fundamentally a vector-based program

&amp;lt;img src="https://r4ds.had.co.nz/diagrams/data-structures-overview.png" width="60%" style="display: block; margin: auto;" /&amp;gt;

&amp;lt;!-- focus today is on atomic vectors and lists --&amp;gt;

---

class: inverse, middle

# Atomic vectors 

---

### Types of atomic vectors

Remember: **All values in an atomic vector must to be of the same type**.

**Logical**: you have used it every time you use a conditional test or operation (e.g., when you filter a data frame)

```r
logical_vector &amp;lt;- c("TRUE", "TRUE", "FALSE", "TRUE", "NA")
```

**Numeric**: can be integer or double (default)

```r
integer_vector &amp;lt;- c("1", "5", "3", "4", "12423")
double_vector &amp;lt;- c("4.2", "4", "6", "53.2")
```

**Character**: note you can use single or double quotations, you just need to be consistent

```r
character_vector &amp;lt;- c("Scary", "'1,2,3 ready!'", "Halloween", '10/31/2022')
```

---

### Scalars

In math a scalar is defined as a single real number. R has no concept of a scalar: **in R, a scalar is simply a vector of length 1**


```r
# set up a vector x of length 10
(x &amp;lt;- sample(10))
```

```
## [1] 10 6 5 4 1 8 2 7 9 3
```

```r
# add 100 to x
x + c(100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
```

```
## [1] 110 106 105 104 101 108 102 107 109 103
```

```r
# add 100 to x: the R way (vector recycling)
x + 100
```

```
## [1] 110 106 105 104 101 108 102 107 109 103
```

&amp;lt;!-- The second way to add the numbers is more efficient but can also be dangerous...--&amp;gt;

---

### Vector Recycling

When two vectors are involved in an operation, **R repeats the elements of the shorter vector to match the length of the longer vector**.

This will work for any vector of any length. For example:

```r
# x1 is sequence of numbers from 1 to 2
(x1 &amp;lt;- seq(from = 1, to = 2))
```

```
## [1] 1 2
```

```r
# x2 is a sequence of numbers from 1 to 10
(x2 &amp;lt;- seq(from = 1, to = 10))
```

```
## [1] 1 2 3 4 5 6 7 8 9 10
```

---

### Vector Recycling

If we add `x1` and `x2` together, R will do it, but the result might not be what we expect:

```r
(x1 + x2)
```

```
## [1] 2 4 4 6 6 8 8 10 10 12
```

The shorter vector, `x1`, is duplicated five times in order to match the length of the longer vector `x2.` 

This behavior is called **vector recycling** and happens automatically in R. You need to pay attention if this is what you intended to do. If not, extend the length of the shorter vector manually first, then add them up.

Note, if the shorter vector is not a multiple of the longer one, R will print a warning message.

---

### Subsetting vectors: slicing

To subset a vector we use the index location of its elements:


```r
x &amp;lt;- c("one", "two", "three", "four", "five")
```

```
# keep the first element
x[1]

# keep the first through third elements
x[c(1, 2, 3)] # long way
x[1:3] # shorter
x[c(seq(1, 3))] # sequence 
x[-c(4:5)] # negative indexing (values that you do not want to keep)
x[-c(4,5)] # negative indexing

x[c(-1,2,3)] # error! do not mix negative and positive subscripts
```

---

### Subset with a logical vector: conditional subsetting

Sometimes, rather than slicing, like we did in the previous example, we want to keep certain values based of a **condition**. 

This is more similar to a filtering operation (vs. slicing) and it is a 2-step operation:
1. create a logical vector of TRUEs and FALSEs, that identifies for each of the elements in the original vector, which one we want to keep

2. apply that vector to the vector we want to subset 

---

### Subset with a logical vector: conditional subsetting

Given a vector `x`:

```r
x &amp;lt;- c(NA, 10, 3, 5, 8, 1, NA)
```

We want to keep all the non-missing values in `x`. To find them we can use `is.na()`. This function outputs a logical vector of TRUEs and FALSEs.
Notice the `!` reverts the output, so we get TRUE for non-missing and FALSE for missing values -- we want to keep the TRUEs:

```r
!is.na(x)
```

```
## [1] FALSE TRUE TRUE TRUE TRUE TRUE FALSE
```

Then, we put the function into `[]` to apply it to our `x` vector. This says "keep all elements that are TRUE" in this vector:

```r
x[!is.na(x)]
```

```
## [1] 10 3 5 8 1
```

---

### Subset with a logical vector: conditional subsetting

This applies to any kind of conditional test. For example, given the same vector `x`:

```r
x &amp;lt;- c(NA, 10, 3, 5, 8, 1, NA)
```

We might want to get all even or missing values of `x`. To do so, we first use modular division: 

```r
x %% 2 == 0 
```

```
## [1] NA TRUE FALSE FALSE TRUE FALSE NA
```

Then, we apply it to our vector `x`:

```r
x[x %% 2 == 0]
```

```
## [1] NA 10 8 NA
```

---

class: inverse, middle

# Lists

---

## Lists

Lists are another type of vector, but they are not atomic vector. They differ from atomic vectors in two main ways:

1. They **store heterogeneous elements** (vs. all values in an atomic vector must be of the same type)
2. They **are structured differently** and are created with the `list()` function, not with the `c()` function. Notice the output is different than the output from an atomic vector:

```r
x &amp;lt;- list(1, 2, 3)
x
```

```
## [[1]]
## [1] 1
## 
## [[2]]
## [1] 2
## 
## [[3]]
## [1] 3
```

---

## Lists structure

List objects are structured as a list of **independent elements**. Use `str()` to see their structure: 

```r
x &amp;lt;- list(1, 2, 3)
str(x)
```

```
## List of 3
## $ : num 1
## $ : num 2
## $ : num 3
```

Here we have a list of length 3, and each of the elements of this list is a numeric atomic vector of length 1.

---

## Lists elements

Unlike atomic vectors, lists can contain **multiple data types**, and we can also name each of them:

```r
x_named &amp;lt;- list(a = "abc", b = 2, c = c(1, 2, 3))
str(x_named)
```

```
## List of 3
## $ a: chr "abc"
## $ b: num 2
## $ c: num [1:3] 1 2 3
```
Here we have a list of length 3, and each of the elements of this list is a different object: we have a character vector of length 1, one numeric vector of length 1, and one numeric vector of length 3. 

---

## Nested lists

You can also store lists inside a list: **nested list structure**. 

In this object `z` we have two lists:

```r
z &amp;lt;- list(list(1, 2), list(3, 4))
str(z)
```

```
## List of 2
## $ :List of 2
## ..$ : num 1
## ..$ : num 2
## $ :List of 2
## ..$ : num 3
## ..$ : num 4
```

This is often useful when you interact with API to get data from the web (frequently you get this type of nested list as output when you get data from API).

---

## Secret lists: data frames!

Notice, we have been using lists extensively in the class. Each column of a data frame is a list: 

```r
str(gun_deaths)
```

```
## spc_tbl_ [100,798 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
## $ id : num [1:100798] 1 2 3 4 5 6 7 8 9 10 ...
## $ year : num [1:100798] 2012 2012 2012 2012 2012 ...
## $ month : chr [1:100798] "Jan" "Jan" "Jan" "Feb" ...
## $ intent : chr [1:100798] "Suicide" "Suicide" "Suicide" "Suicide" ...
## $ police : num [1:100798] 0 0 0 0 0 0 0 0 0 0 ...
## $ sex : chr [1:100798] "M" "F" "M" "M" ...
## $ age : num [1:100798] 34 21 60 64 31 17 48 41 50 NA ...
## $ race : chr [1:100798] "Asian/Pacific Islander" "White" "White" "White" ...
## $ place : chr [1:100798] "Home" "Street" "Other specified" "Home" ...
## $ education: Factor w/ 4 levels "Less than HS",..: 4 3 4 4 2 1 2 2 3 NA ...
```

The only difference between data frames and actual lists is that the length of each list object in the data frame has to the same (a data frame is rectangular).

---

## Subsetting lists

Lists have a more complex structure than vectors, thus subsetting them also requires more attention.

.pull-left[

For example, `a` is a list that contains four elements: 
* a numeric vector
* a character vector
* a numeric vector
* a list object which in turns contains two distinct numeric vectors (notice the space in the middle)

]

.pull-right[

&amp;lt;img src="lists-subsetting-a-only.png" width="30%" style="display: block; margin: auto;" /&amp;gt;

]

---

## Subsetting lists

&amp;lt;img src="https://r4ds.had.co.nz/diagrams/lists-subsetting.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

---

class: inverse, middle

# Practice subsetting vectors and lists

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/data-transformation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/data-transformation/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Data transformation&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data transformation
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






## Reminders

- Check in on Homework 1
 - submit link to your repo on Canvas
 - check general rubric and HW specific rubric on our website
 
 
- Last lecture: visualization and ggplot2
 - review assigned readings and class notes (esp. "Defaults" section)
 - practice practice practice
 
 
- Homework 2 opens today 
 - covers data visualization, transformation, and exploration


---
# Editing your files: Script and RMD structure


* [Consider how to structure your R scripts](https://bookdown.org/yih_huynh/Guide-to-R-Book/r-conventions.html)
* [Rmarkdown (intermediate)](https://posit.co/blog/r-markdown-tips-tricks-2-cleaning-up-your-code/)
* [Rmarkdown resources](https://bookdown.org/yihui/rmarkdown-cookbook/)

---

class: inverse, middle

# Programming as a form of problem-solving

---

## `penguins`

&amp;lt;img src="../../../static/img/lter_penguins.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## `penguins`


```r
penguins
```

```
## # A tibble: 344 × 8
## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Adelie Torgersen 39.1 18.7 181 3750
## 2 Adelie Torgersen 39.5 17.4 186 3800
## 3 Adelie Torgersen 40.3 18 195 3250
## 4 Adelie Torgersen NA NA NA NA
## 5 Adelie Torgersen 36.7 19.3 193 3450
## 6 Adelie Torgersen 39.3 20.6 190 3650
## 7 Adelie Torgersen 38.9 17.8 181 3625
## 8 Adelie Torgersen 39.2 19.6 195 4675
## 9 Adelie Torgersen 34.1 18.1 193 3475
## 10 Adelie Torgersen 42 20.2 190 4250
## # ℹ 334 more rows
## # ℹ 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;
```

---

## What is the average body mass of an Adelie penguin?

.panelset[
.panel[.panel-name[Conceptual]

1. First we need to identify the **input**, or the data were going to analyze: `penguins` data frame
1. Next we need to **select** only the observations classified as species Adelie penguins
1. Finally we need to calculate the average value, or **mean**, of the variable `body_mass_g`




```r
head(penguins, 5)
```

```
## # A tibble: 5 × 8
## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Adelie Torgersen 39.1 18.7 181 3750
## 2 Adelie Torgersen 39.5 17.4 186 3800
## 3 Adelie Torgersen 40.3 18 195 3250
## 4 Adelie Torgersen NA NA NA NA
## 5 Adelie Torgersen 36.7 19.3 193 3450
## # ℹ 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;
```

]

.panel[.panel-name[Code]


```r
library(palmerpenguins)
data("penguins")
penguins_adelie &amp;lt;- filter(.data = penguins, species == "Adelie")
summarize(.data = penguins_adelie, avg_mass = mean(body_mass_g, na.rm = TRUE))
```

```
## # A tibble: 1 × 1
## avg_mass
## &amp;lt;dbl&amp;gt;
## 1 3701.
```

]
]

---

## What is the average body mass of a penguin for each species?

.panelset[
.panel[.panel-name[Conceptual]

1. First we need to identify the **input**, or the data were going to analyze: our `penguins` data frame
1. Next we need to **group** the observations by species
1. Finally we need to calculate the average value, or **mean**, of the variable `body_mass_g`


```
## # A tibble: 5 × 8
## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Adelie Torgersen 39.1 18.7 181 3750
## 2 Adelie Torgersen 39.5 17.4 186 3800
## 3 Adelie Torgersen 40.3 18 195 3250
## 4 Adelie Torgersen NA NA NA NA
## 5 Adelie Torgersen 36.7 19.3 193 3450
## # ℹ 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;
```

]

.panel[.panel-name[Code]


```r
library(palmerpenguins)
data("penguins")
penguins_species &amp;lt;- group_by(.data = penguins, species)
summarize(.data = penguins_species, avg_mass = mean(body_mass_g, na.rm = TRUE))
```

```
## # A tibble: 3 × 2
## species avg_mass
## &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Adelie 3701.
## 2 Chinstrap 3733.
## 3 Gentoo 5076.
```

]
]

---

class: inverse, middle

# Data transformation with dplyr

---

&amp;lt;img src="https://raw.githubusercontent.com/allisonhorst/stats-illustrations/main/rstats-artwork/dplyr_wrangling.png" alt="Cartoon of a fuzzy monster with a cowboy hat and lasso, riding another fuzzy monster labeled 'dplyr', lassoing a group of angry / unruly looking creatures labeled 'data.'" width="55%" style="display: block; margin: auto;" /&amp;gt;

Documentation: **https://dplyr.tidyverse.org/**

.footnote[Source of image: [Allison Horst](https://github.com/allisonhorst/stats-illustrations)]

---

## Flow for data transformation


1. The first argument is a data frame
--

1. Subsequent arguments describe what to do with the data frame

--
1. The result is a **new data frame**

--

`dplyr` contains useful functions for transforming and manipulating data frames. 

These functions can be thought of as **verbs that define actions** to be performed on the data: 
the noun is the data, and the verb is acting on the noun. 

All of the dplyr verbs (all the verbs in the wider tidyverse) work similarly.

---

## Key functions in `dplyr`


`function()` | **Action performed**
--------------|--------------------------------------------------------
`filter()` | Picks observations from the data frame based on their values (operates on rows)
`arrange()` | Changes the order of observations based on their values
`select()` | Picks columns/variables from the data frame based on their names (operates on columns)
`rename()` | Changes the name of columns in the data frame
`mutate()` | Creates new columns from existing ones
`group_by()` | Changes the unit of analysis from the complete data frame to individual groups
`summarize()` | Collapses the data frame to a smaller number of rows which summarize the larger data

These are the basic verbs you will commonly use to transform your data. By **combining them together**, you can perform powerful data manipulation tasks.

---

## American vs. British English

.pull-left[

&lt;blockquote class="twitter-tweet" data-width="550" data-lang="en" data-dnt="true" data-theme="light">&lt;p lang="en" dir="ltr">The holy grail: &amp;quot;For consistency, aim to use British (rather than American) spelling.&amp;quot; &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw">#rstats&lt;/a> &lt;a href="http://t.co/7qQSWIowcl">http://t.co/7qQSWIowcl&lt;/a>. Colour is right!&lt;/p></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/data-wrangling-relational-data-and-factors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/data-wrangling-relational-data-and-factors/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Data wrangling: relational data&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data wrangling: relational data
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---








class: inverse, middle

# Relational data structures

---
# Agenda

* Recap
* Relational data
* Practice from webpage
* Factors


---
## Recap

* Loading data
* Plotting
* PIPES!

---

## Introduction to relational data

A **relational database** can be defined as a set of multiple tables that are linked based on data common to them. 

&amp;lt;!--
Data you need for the analysis is not and cannot be stored in one single table 
but it is split across tables; usually two but potentially more
--&amp;gt;

--

* These tables answer research questions only when combined together. 

* The important elements in the analysis are not defined by individual rows or columns in one table, but they emerge from the relations between tables.

---

## Example 

Example of a relational database: `library(nycflights13)` from R for Data Science, Chapter 13.

Five tables: 
* `flights` flights info
* `airlines` info about the full name of airplane company, identified the career abbreviated code
* `airports` info about each airport, identified by the faa airport code
* `planes` info about each plane, identified by its tailnum
* `weather` info about the weather at each NYC airport for each hour

---

## Example

Graphical representation of the relations among the tables in `nycflights13`:

&amp;lt;img src="relational-nycflights.png" width="60%" style="display: block; margin: auto;" /&amp;gt;

To understand diagrams like this, remember that each relation always concerns a **pair of tables**. Even if you have several tables in your relational database, relations are defined between a pair.

---

## Formal definitions 

A **KEY** of a table is a subset of columns (or attributes). There are two types of keys:

* **PRIMARY KEY**
uniquely identifies an observation in its own table; e.g. `tailnum` is the primary key of the `planes` table

* **FOREIGN KEY**
matches the primary key of another table; e.g. `tailnum` is a foreign key of the `flights` plane (it appears in the flights table where it matches each flight to a unique plane)

&amp;lt;!--
A variable can be both a primary key and a foreign key. For example, origin is part of the weather primary key, and is also a foreign key for the airports table. 
--&amp;gt;

--

A relation is defined between a **pair of tables**: a primary key and the corresponding foreign key in another table form a **relation**.

&amp;lt;!--
Relations can be
* one-to-one
* one-to-many: each flight has one plane, but each plane has many flights
* many-to-many
--&amp;gt;

---

class: inverse, middle

# Tools for combining tables: Mutating joins

---
&amp;lt;!--- there are mutating and filtering joins ---&amp;gt;

## Mutating joins

**inner join**: keeps observations that appear in both tables

outer join: keeps observations that appear in at least one of the tables
 * **left join**: keeps all observations in left table
 * **right join**: keeps all observations in right table
 * **full join**: keeps all observations

--

Venn diagram of mutating joins:

&amp;lt;img src="join-venn.png" width="60%" style="display: block; margin: auto;" /&amp;gt;

---

## inner_join()

Keeps observations that appear in both tables. Unmatched rows: not included in the result

.pull-left[


&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

--

.pull-right[

&amp;lt;img src="join-inner.png" width="120%" style="display: block; margin: auto;" /&amp;gt;

```
inner_join(x, y, by = "key")

# with pipes
x %&amp;gt;% 
 inner_join(y, by = "key")
 
# if two cols do not have same name
inner_join(x, y, by = c("a" = "b")) 
 
```

]

&amp;lt;!-- by convention, x is assigned as the first dataframe or left one, and y as the second or right one; the by argument specifies that we are joining it based on the key column (which you cannot see from the drawing but its the column name of the colored columns in each x and y). Compare this to the left_join() operation which is another form of mutating join
--&amp;gt;

---

## left_join()

Keeps all observations in the left table (x), even if there is not a match in y

.pull-left[

&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

&amp;lt;img src="join-outer-left.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

```
left_join(x, y, by = "key")
```

] 

---

## right_join()

Keeps all observations in the right table (y), even if there is not a match in x

.pull-left[

&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

&amp;lt;img src="join-outer-right.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

```
right_join(x, y, by = "key")
```

] 

&amp;lt;!-- same thing as left join but reversing the order of the data frame or table
typically right join is utilized less because by convention we think as the primary 
data for these kind of operations as the left or x table 
--&amp;gt;

---

## full_join()

Keeps all observations, matches and non-matches

&amp;lt;!-- more missing values --&amp;gt;

.pull-left[

&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

&amp;lt;img src="join-outer-full.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

```
full_join(x, y, by = "key")
```

] 

---

class: inverse, middle

# Tools for combining tables: Filtering joins

---

## Filtering joins

- **semi_join**: keeps all observations in x that have a match in y
- **anti_join** drops all observations in x that have a match in y

Essentially the filtering operation uses information from the second data frame (y) to filter the first data frame (x).

---

## semi_join()

Keeps all observations in x that have a match in y. Only keeps columns from x

.pull-left[

&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

&amp;lt;img src="join-semi.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

```
semi_join(x, y, by = "key")
```

] 


---

## anti_join()

Drops all observations in x that have a match in y. Only keeps columns from x

.pull-left[

&amp;lt;img src="join-setup.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

&amp;lt;img src="join-anti.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

```
anti_join(x, y, by = "key")
```
]

---

class: inverse, middle

# Practice working with relational data
### Download the exercises from the website

---

class: inverse, middle

# Factors

---

## Factors

* Used for **categorical (discrete) variables**
* Factors store categorical variables values as numbers rather than as characters (e.g., Likert scale)
* Historically used for purposes of efficiency
* Best used to sort categorical variables other than alphabetically (e.g., 1 to 5 rather than alphabetically)
* `forcats` in `tidyverse` to manipulate factors

---

## Character vector

Define a character vectors with four months and sort it:


```r
(x1 &amp;lt;- c("Dec", "Apr", "Jan", "Mar"))
```

```
## [1] "Dec" "Apr" "Jan" "Mar"
```

```r
sort(x1)
```

```
## [1] "Apr" "Dec" "Jan" "Mar"
```

Notice the default behavior of R is sorting character vectors alphabetically. As humans, we understand that's not the a very meaningful way to sort months. Instead, we might want to sort months chronologically. To tell that to R, we need to convert them to factors.

&amp;lt;!--
note we use sort() because this is a standalone vector, 
while we used arrange() when working with dataframes
--&amp;gt;

---

### Step 1: Levels

To convert a character vector to a factor, the first thing to do is to define all possible values that the variable can take. We do so by creating another character vector:


```r
month_levels &amp;lt;- c(
 "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
 "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
```

---

### Step 2: Factor

We then use the `factor()` or the `parse_factor()` function to convert this character vector into a factor, and apply the given order to it:


```r
(y1 &amp;lt;- factor(x1, levels = month_levels))
```

```
## [1] Dec Apr Jan Mar
## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
```

```r
parse_factor(x1, levels = month_levels)
```

```
## [1] Dec Apr Jan Mar
## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
```

---

### Step 3: Sort

Finally, we sort the new factor vector `y1`, exactly like we did for the original character vector `x1`:


```r
# sort y1: chronologically correctly
sort(y1)
```

```
## [1] Jan Mar Apr Dec
## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
```

```r
# sort x1: alphabetically sorted
sort(x1)
```

```
## [1] "Apr" "Dec" "Jan" "Mar"
```

---

## Different levels/labels

Another situation you might encounter, is that rather than working directly with character vectors, you might find their numerical representation:


```r
(x2 &amp;lt;- c(12, 4, 1, 3))
```

```
## [1] 12 4 1 3
```

Define levels and labels separately: 


```r
y2 &amp;lt;- factor(x2,
 levels = seq(from = 1, to = 12),
 labels = month_levels
)
y2
```

```
## [1] Dec Apr Jan Mar
## Levels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
```

---

## `forcats` package

Provides a suite of tools that solve common problems with factors. Some examples include:

- `fct_reorder()`: Reordering a factor by another variable
- `fct_infreq()`: Reordering a factor by the frequency of values
- `fct_relevel()`: Changing the order of a factor by hand
- `fct_lump()`: Collapsing the least/most frequent values of a factor into “other”

Documentation and Cheat Sheet: https://forcats.tidyverse.org/

&amp;lt;!-- show hw3 work with factors --&amp;gt;
---

class: inverse, middle

# Practice working with factors
### Download the exercises from the website

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/data-wrangling-tidy-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/data-wrangling-tidy-data/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Data wrangling: import and tidy data in R&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data wrangling: import and tidy data in R
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Importing data in R

---

## base R VS `readr`

To load data into R we need importing functions. 

There are a number of them depending on the type of file we want to import (see Chapter 11 of R for Data Science for details).

The most common importing functions are those that read **comma delimited files**. There are two versions of them:

- **base R**: `read.csv()`

- **`readr` package**: `read_csv()`

&amp;lt;!-- `read.csv` is a special case of `read.table`, while `read_csv` is special case of `read_delim`
--&amp;gt;

--

&amp;gt; They are similar, in that they both import comma delimited files, but one comes from base R, while the other comes from the newest `readr` package (part of the `tidyverse`, like `ggplot2` and `dplyr`). We focus on `read_csv`

---

## `read_csv()`

The `read_csv()` function takes several arguments, see https://readr.tidyverse.org/reference/read_delim.html. For example:

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```
--

The `file` argument must specified, the other arguments can be left as default:

```
library(readr)

# load data into my local R Studio
test &amp;lt;- read_csv(file = "/Users/jclip/Desktop/testdata.csv")

# load data into my R Workbench 
test &amp;lt;- read_csv(file = "/home/jclip/lecture/testdata.csv")

# trick if you're not sure where it is / want to select it
test &amp;lt;- read_csv(file = file.choose())
```

&amp;lt;!--
Make sure the file is located in the given path and you are typing the path correctly. Let's practice!
--&amp;gt;

---

## Practice


1. Create a `testdata.csv` file on your desktop, and save it as plain `csv` [Try to have at least three columns, including integers, characters, and maybe a factor/categorical variable. Include at least one NA.]
&amp;lt;!--#testfile &amp;lt;- data.frame(num_teas = c(5,3,2,4,5,na,NA),
# days = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"),
# favorite = c("matcha", "black", "green", "chai", "black", "matcha", ""))
# write_csv(testfile, "/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/slides/data-wrangling-tidy-data/test.csv") --&amp;gt;

1. Open R Workbench: upload the file to the server (skip this step if you are using R locally)

1. Look at your current directory by typing `getwd()` in the console. That's where R looks at files by default

1. Load the data into R using the `read_csv()` function. Make sure to specify the correct path

1. Modify the `read_csv()` function arguments: set `col_names = FALSE` (default is TRUE). What happens?

---

### Modify `read_csv()` arguments: `col_types`

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```


```r
# set col_types option 1
test &amp;lt;- read_csv("test.csv", #note: if I don't specify the location, it assumes my working directory
 col_types = cols(
 num_teas = col_integer(),
 days = readr::col_factor( #ASK ME ABOUT THIS!!
 c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
 ),
 favorite = col_character()
 )
 )
test
```

```
## # A tibble: 7 × 3
## num_teas days favorite
## &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5 Monday matcha 
## 2 3 Tuesday black 
## 3 2 Wednesday green 
## 4 4 Thursday chai 
## 5 5 Friday black 
## 6 3 Saturday matcha 
## 7 NA Sunday &amp;lt;NA&amp;gt;
```


```r
# set col_types option 2
test &amp;lt;- read_csv("test.csv",
 col_types = ("ifc") #i(integer)f(factor)c(character)
 )
test
```

```
## # A tibble: 7 × 3
## num_teas days favorite
## &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5 Monday matcha 
## 2 3 Tuesday black 
## 3 2 Wednesday green 
## 4 4 Thursday chai 
## 5 5 Friday black 
## 6 3 Saturday matcha 
## 7 NA Sunday &amp;lt;NA&amp;gt;
```

---

### Modify `read_csv()` arguments: `na`

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```

Load the data and leave the `na` argument as default. Check your loaded data and notice what happened to the missing values.

Load the data again, but this time modify the `na` argument as follows:

```
test &amp;lt;- read_csv("/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/slides/data-wrangling-tidy-data/test.csv",
 na = c("na", "NA")
 )
```

Check your loaded data and notice what happened to the missing values. Then modify the `na` argument again using the code below, and check:

```
test &amp;lt;- read_csv("/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/slides/data-wrangling-tidy-data/test.csv",
 na = c("na", "NA", "N/A", "")
 )
```

---

&amp;lt;!--


&amp;lt;img src="index_files/figure-html/compare-speed-small-plot-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

## `readr` vs. base R



&amp;lt;img src="index_files/figure-html/compare-speed-large-plot-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
--&amp;gt;

## Other file formats

The `readr` package and other packages include several functions to load almost all possible file formats that you might encounter (when given an option though, choose a csv over other formats). For example:

* **Comma separated csv** use `read_csv()` from the `readr` package
* **Semi column separated csv** use `read_csv2()`from the `readr` package
* **Tab separated files** use `read_tsv()`from the `readr` package
* **RDS** use `readRDS()` or `read_rds()`
* **Excel** use `read_excel()` from the `readxl` package
* **SPSS/Stata** use the`haven` package (several functions)

--

Cheat Sheet `readr` and `readxl`:
**Help &amp;gt; Cheat Sheets &amp;gt; Browse Cheat Sheets**

&amp;lt;!--
## `challenge`

To illustrate these different file formats, we use the challange.csv dataset from the readings:


```
## # A tibble: 2,000 × 2
## x y 
## &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;
## 1 404 NA 
## 2 4172 NA 
## 3 3004 NA 
## 4 787 NA 
## 5 37 NA 
## 6 2332 NA 
## 7 2489 NA 
## 8 1449 NA 
## 9 3665 NA 
## 10 3863 NA 
## # ℹ 1,990 more rows
```
## RDS

R file format. 

* because is native to R, can only be opened by R
* does not render well on GitHub
* can be easily compressed
* faster
* guarantees consistency

&amp;lt;!--



```r
# compare file size
file.info(here("static", "data", "challenge.rds"))$size %&amp;gt;%
 utils:::format.object_size("auto")
```

```
## [1] "11.6 Kb"
```

```r
file.info(here("static", "data", "challenge.csv"))$size %&amp;gt;%
 utils:::format.object_size("auto")
```

```
## [1] "37.1 Kb"
```

## RDS

&amp;lt;img src="index_files/figure-html/rds-3-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

## `feather`



&amp;lt;img src="index_files/figure-html/feather-2-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
--&amp;gt;

---

## `readxl`

From the `readxl` package https://readxl.tidyverse.org/, use `read_excel()` to import excel files:


```r
library(readxl)
xlsx_example &amp;lt;- readxl_example(path = "datasets.xlsx")
read_excel(path = xlsx_example)
```

```
## # A tibble: 150 × 5
## Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5.1 3.5 1.4 0.2 setosa 
## 2 4.9 3 1.4 0.2 setosa 
## 3 4.7 3.2 1.3 0.2 setosa 
## 4 4.6 3.1 1.5 0.2 setosa 
## 5 5 3.6 1.4 0.2 setosa 
## 6 5.4 3.9 1.7 0.4 setosa 
## 7 4.6 3.4 1.4 0.3 setosa 
## 8 5 3.4 1.5 0.2 setosa 
## 9 4.4 2.9 1.4 0.2 setosa 
## 10 4.9 3.1 1.5 0.1 setosa 
## # ℹ 140 more rows
```

---

## `readxl`

We can specify the specific worksheet by name or position


```r
excel_sheets(path = xlsx_example)
```

```
## [1] "iris" "mtcars" "chickwts" "quakes"
```


```r
read_excel(path = xlsx_example, sheet = "chickwts")
```

```
## # A tibble: 71 × 2
## weight feed 
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 179 horsebean
## 2 160 horsebean
## 3 136 horsebean
## 4 227 horsebean
## 5 217 horsebean
## 6 168 horsebean
## 7 108 horsebean
## 8 124 horsebean
## 9 143 horsebean
## 10 140 horsebean
## # ℹ 61 more rows
```

---

## `haven` and SAS


```r
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
 package = "haven"
))
```

```
## # A tibble: 150 × 5
## Sepal_Length Sepal_Width Petal_Length Petal_Width Species
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5.1 3.5 1.4 0.2 setosa 
## 2 4.9 3 1.4 0.2 setosa 
## 3 4.7 3.2 1.3 0.2 setosa 
## 4 4.6 3.1 1.5 0.2 setosa 
## 5 5 3.6 1.4 0.2 setosa 
## 6 5.4 3.9 1.7 0.4 setosa 
## 7 4.6 3.4 1.4 0.3 setosa 
## 8 5 3.4 1.5 0.2 setosa 
## 9 4.4 2.9 1.4 0.2 setosa 
## 10 4.9 3.1 1.5 0.1 setosa 
## # ℹ 140 more rows
```

---

## `haven` and SPSS


```r
read_sav(file = system.file("examples", "iris.sav",
 package = "haven"
))
```

```
## # A tibble: 150 × 5
## Sepal.Length Sepal.Width Petal.Length Petal.Width Species 
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt; 
## 1 5.1 3.5 1.4 0.2 1 [setosa]
## 2 4.9 3 1.4 0.2 1 [setosa]
## 3 4.7 3.2 1.3 0.2 1 [setosa]
## 4 4.6 3.1 1.5 0.2 1 [setosa]
## 5 5 3.6 1.4 0.2 1 [setosa]
## 6 5.4 3.9 1.7 0.4 1 [setosa]
## 7 4.6 3.4 1.4 0.3 1 [setosa]
## 8 5 3.4 1.5 0.2 1 [setosa]
## 9 4.4 2.9 1.4 0.2 1 [setosa]
## 10 4.9 3.1 1.5 0.1 1 [setosa]
## # ℹ 140 more rows
```

---

## `haven` and Stata


```r
read_dta(file = system.file("examples", "iris.dta",
 package = "haven"
))
```

```
## # A tibble: 150 × 5
## sepallength sepalwidth petallength petalwidth species
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5.10 3.5 1.40 0.200 setosa 
## 2 4.90 3 1.40 0.200 setosa 
## 3 4.70 3.20 1.30 0.200 setosa 
## 4 4.60 3.10 1.5 0.200 setosa 
## 5 5 3.60 1.40 0.200 setosa 
## 6 5.40 3.90 1.70 0.400 setosa 
## 7 4.60 3.40 1.40 0.300 setosa 
## 8 5 3.40 1.5 0.200 setosa 
## 9 4.40 2.90 1.40 0.200 setosa 
## 10 4.90 3.10 1.5 0.100 setosa 
## # ℹ 140 more rows
```

---

class: inverse, middle

# Exporting Data from R

---

## `write_csv()`

Similar to the `read_csv()` function used for reading in csv files into R, there is a `write_csv()` function that **generates csv files** from R data frames.

Documentation: https://readr.tidyverse.org/reference/write_delim.html

```
# import
test &amp;lt;- read_csv(file = "/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/slides/data-wrangling-tidy-data/test.csv)

# export
write_csv(test, file = "/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/slides/data-wrangling-tidy-data/testdata_cleaned.csv")
```


---

class: inverse, middle

# Tidy data

---

## Tidy data

&amp;lt;img src="tidydata_1.jpg" alt="Stylized text providing an overview of Tidy Data. The top reads 'Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.' On the left reads 'In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.' There is an example table on the lower right with columns ‘id’, ‘name’ and ‘color’ with observations for different cats, illustrating tidy data structure." width="70%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst)]

&amp;lt;!-- tidy data is a way of standardizing info in a dataframe
but it is not the only way and we are going to see some examples
the opposite of tidy would be messy data or untidy 
the reason why tidy data is popular is because provides a STANDARDIZED form
all packages we have learned so far ggplot, dplyr work with tidy data
which means you can simply load the dataset and start working on it
without reshaping it or cleaning it up (if tidy)
so point here: as soon as you get data and you know u want to work on them
within the tidyverse (ggplot, dplyr etc) get them in a tidy format first, 
then focus with the analyses or anything else u want to do!

NB: this also means if you are working outside tidyverse, in another package 
or basic R you might not need tidy data

are there ? on the tidy structure, i wanna make sure you konw not only 
the definition but also why we emphasize it so much here
--&amp;gt;

---

## Tidy data

&amp;lt;img src="tidydata_2.jpg" alt="There are two sets of anthropomorphized data tables. The top group of three tables are all rectangular and smiling, with a shared speech bubble reading 'our columns are variables and our rows are observations!'. Text to the left of that group reads 'The standard structure of tidy data means that 'tidy datasets are all alike…' The lower group of four tables are all different shapes, look ragged and concerned, and have different speech bubbles reading (from left to right) 'my column are values and my rows are variables', 'I have variables in columns AND in rows', 'I have multiple variables in a single column', and 'I don’t even KNOW what my deal is.' Next to the frazzled data tables is text '...but every messy dataset is messy in its own way. -Hadley Wickham.'" width="70%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst)]

---

## Tidy data

&amp;lt;img src="tidydata_3.jpg" alt="On the left is a happy cute fuzzy monster holding a rectangular data frame with a tool that fits the data frame shape. On the workbench behind the monster are other data frames of similar rectangular shape, and neatly arranged tools that also look like they would fit those data frames. The workbench looks uncluttered and tidy. The text above the tidy workbench reads 'When working with tidy data, we can use the same tools in similar ways for different datasets…' On the right is a cute monster looking very frustrated, using duct tape and other tools to haphazardly tie data tables together, each in a different way. The monster is in front of a messy, cluttered workbench. The text above the frustrated monster reads '...but working with untidy data often means reinventing the wheel with one-time approaches that are hard to iterate or reuse.'" width="70%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst)]

---

## Common tidying tasks

* Pivoting
 * Longer
 * Wider
* Separating
* Uniting

We are going to illustrate these tasks with datasets from the readings (Chapter 12 R for Data Science). Each dataset shows the same values of four variables country, year, population, and cases, but each dataset organises the values in a different way.

--

Remember the tidy data principles:
- Each variable must have its own column
- Each observation must have its own row
- Each value must have its own cell

---

## Pivot longer

Look at this dataset. Why is it messy/untidy? 


```r
library(tidyverse)
table4a
```

```
## # A tibble: 3 × 3
## country `1999` `2000`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 745 2666
## 2 Brazil 37737 80488
## 3 China 212258 213766
```

--

"Each variable must have its own column". Thus, the column names should be names of variables. Instead, here they are values of a variable: 1999 and 2000 are values of the year variable 

"Each observation must have its own row". Here we have one row for every country, but that's not sufficient because this is panel data. We should have the country-year pair to define one observation, rather than only country.

---

## Pivot longer

.pull-left[


```r
table4a
```

```
## # A tibble: 3 × 3
## country `1999` `2000`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 745 2666
## 2 Brazil 37737 80488
## 3 China 212258 213766
```

]


.pull-right[


```r
pivot_longer(
 data = table4a,
 cols = c(`1999`, `2000`),
 names_to = "year",
 values_to = "cases"
)
```

```
## # A tibble: 6 × 3
## country year cases
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 1999 745
## 2 Afghanistan 2000 2666
## 3 Brazil 1999 37737
## 4 Brazil 2000 80488
## 5 China 1999 212258
## 6 China 2000 213766
```

]

&amp;lt;!--
We can reshape and tidy it using `pivot_longer`, which takes four main arguments:
- data: data we are reshaping -- notice we go from a 3by3 to a 6by3
- cols: name of the columns we use to make this pivot (or to drop); note the use of back ticks!
- names_to column: variable we wish to create from column names
- values_to column: variable we wish to create and fill with values
--&amp;gt;

--

---

## Pivot wider

Look at this dataset. Why is it messy/untidy? 

.pull-left[

```r
library(tidyverse)
table2
```

```
## # A tibble: 12 × 4
## country year type count
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 1999 cases 745
## 2 Afghanistan 1999 population 19987071
## 3 Afghanistan 2000 cases 2666
## 4 Afghanistan 2000 population 20595360
## 5 Brazil 1999 cases 37737
## 6 Brazil 1999 population 172006362
## 7 Brazil 2000 cases 80488
## 8 Brazil 2000 population 174504898
## 9 China 1999 cases 212258
## 10 China 1999 population 1272915272
## 11 China 2000 cases 213766
## 12 China 2000 population 1280428583
```

]

--

.pull-right[

"Each variable must have its own column". The current values of the type column are not values but are variables names. 
 
"Each observation must have its own row". Here an observation is scattered across multiple rows: an observation is a country in a year, but each observation is spread across two rows.

]

---

## Pivot wider

.pull-left[


```r
table2
```

```
## # A tibble: 12 × 4
## country year type count
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 1999 cases 745
## 2 Afghanistan 1999 population 19987071
## 3 Afghanistan 2000 cases 2666
## 4 Afghanistan 2000 population 20595360
## 5 Brazil 1999 cases 37737
## 6 Brazil 1999 population 172006362
## 7 Brazil 2000 cases 80488
## 8 Brazil 2000 population 174504898
## 9 China 1999 cases 212258
## 10 China 1999 population 1272915272
## 11 China 2000 cases 213766
## 12 China 2000 population 1280428583
```

]

--

.pull-right[


```r
pivot_wider(
 data = table2,
 names_from = type,
 values_from = count
)
```

```
## # A tibble: 6 × 4
## country year cases population
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Afghanistan 1999 745 19987071
## 2 Afghanistan 2000 2666 20595360
## 3 Brazil 1999 37737 172006362
## 4 Brazil 2000 80488 174504898
## 5 China 1999 212258 1272915272
## 6 China 2000 213766 1280428583
```

]

---

## Separating

Look at this dataset. Why is it messy/untidy? 


```r
table5
```

```
## # A tibble: 6 × 4
## country century year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19 99 745/19987071 
## 2 Afghanistan 20 00 2666/20595360 
## 3 Brazil 19 99 37737/172006362 
## 4 Brazil 20 00 80488/174504898 
## 5 China 19 99 212258/1272915272
## 6 China 20 00 213766/1280428583
```


---

## Separating

.pull-left[


```r
table3
```

```
## # A tibble: 6 × 3
## country year rate 
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 1999 745/19987071 
## 2 Afghanistan 2000 2666/20595360 
## 3 Brazil 1999 37737/172006362 
## 4 Brazil 2000 80488/174504898 
## 5 China 1999 212258/1272915272
## 6 China 2000 213766/1280428583
```

]

--

.pull-right[


```r
separate(
 data = table3,
 col = rate,
 into = c(
 "cases",
 "population"
 ),
 convert = TRUE
)
```

```
## # A tibble: 6 × 4
## country year cases population
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Afghanistan 1999 745 19987071
## 2 Afghanistan 2000 2666 20595360
## 3 Brazil 1999 37737 172006362
## 4 Brazil 2000 80488 174504898
## 5 China 1999 212258 1272915272
## 6 China 2000 213766 1280428583
```

]


---


## Uniting

Look at this dataset. Why is it messy/untidy? 


```r
table5
```

```
## # A tibble: 6 × 4
## country century year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19 99 745/19987071 
## 2 Afghanistan 20 00 2666/20595360 
## 3 Brazil 19 99 37737/172006362 
## 4 Brazil 20 00 80488/174504898 
## 5 China 19 99 212258/1272915272
## 6 China 20 00 213766/1280428583
```

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 × 4
## country century year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19 99 745/19987071 
## 2 Afghanistan 20 00 2666/20595360 
## 3 Brazil 19 99 37737/172006362 
## 4 Brazil 20 00 80488/174504898 
## 5 China 19 99 212258/1272915272
## 6 China 20 00 213766/1280428583
```

]

--

.pull-right[


```r
unite(
 data = table5,
 col = "year",
 century, year
)
```

```
## # A tibble: 6 × 3
## country year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19_99 745/19987071 
## 2 Afghanistan 20_00 2666/20595360 
## 3 Brazil 19_99 37737/172006362 
## 4 Brazil 20_00 80488/174504898 
## 5 China 19_99 212258/1272915272
## 6 China 20_00 213766/1280428583
```

]

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 × 4
## country century year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19 99 745/19987071 
## 2 Afghanistan 20 00 2666/20595360 
## 3 Brazil 19 99 37737/172006362 
## 4 Brazil 20 00 80488/174504898 
## 5 China 19 99 212258/1272915272
## 6 China 20 00 213766/1280428583
```

]

.pull-right[


```r
unite(
 data = table5,
 col = "year",
 century, year,
 # remove underscore
 sep = ""
)
```

```
## # A tibble: 6 × 3
## country year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 1999 745/19987071 
## 2 Afghanistan 2000 2666/20595360 
## 3 Brazil 1999 37737/172006362 
## 4 Brazil 2000 80488/174504898 
## 5 China 1999 212258/1272915272
## 6 China 2000 213766/1280428583
```

]

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 × 4
## country century year rate 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 19 99 745/19987071 
## 2 Afghanistan 20 00 2666/20595360 
## 3 Brazil 19 99 37737/172006362 
## 4 Brazil 20 00 80488/174504898 
## 5 China 19 99 212258/1272915272
## 6 China 20 00 213766/1280428583
```

]

.pull-right[


```r
unite(
 data = table5,
 col = "year",
 century, year,
 # remove underscore
 sep = ""
) %&amp;gt;%
 # store as numeric
 mutate(year = parse_number(year))
```

```
## # A tibble: 6 × 3
## country year rate 
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Afghanistan 1999 745/19987071 
## 2 Afghanistan 2000 2666/20595360 
## 3 Brazil 1999 37737/172006362 
## 4 Brazil 2000 80488/174504898 
## 5 China 1999 212258/1272915272
## 6 China 2000 213766/1280428583
```
]

---

# Let's get messy!

&amp;lt;img src="https://media.giphy.com/media/fCUCbWXe9JONVsJSUd/giphy.gif" width="40%" style="display: block; margin: auto;" /&amp;gt;

[https://macs30500.netlify.app/notes/data-wrangle/tidy-exercise/](https://macs30500.netlify.app/notes/data-wrangle/tidy-exercise/)

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/debugging-and-defensive-programming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/debugging-and-defensive-programming/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Debugging and defensive programming&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Debugging and defensive programming
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# R Base Data Structures

---

## Bugs

&amp;gt; An error, flaw, failure or fault in a computer program or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways.

When we talk about a bug mostly we refer to a syntactic error or a typo, but a bug is also related to understanding R rules, data types, structures, and how to use functions. Computers are powerful tools but you need to follow their rules

Debugging has two goals:
* Prevent bugs from occurring in the first place
* Fix bugs once they occur

**Debugging (like programming) requires patience!** 


---

class: inverse, middle

# Defensive programming

---

## Defensive programming

Two elements of defensive programming...

**Style guide for writing code:**
* Notation and naming guide (file names, object names, etc.)
* Syntax (spacing, curly braces, line length, indentation, assignment, calling functions)
* Comments (# and space)
* Auto-formatting in RStudio

**Failing fast:**
* Condition handling


---

## Writing code

Programming |	Language
------------|----------
Scripts |	Essays
Sections | Paragraphs
Lines Breaks | Sentences
Parentheses |	Punctuation
Functions |	Verbs
Variables |	Nouns

---

### A text with no syntax

Text taken from a speech given by Ronald Reagan in 1987, after the spacial Challenger exploded on take off. Reagan's address: https://youtu.be/Qa7icmqgsow
 
"weve grown used to wonders in this century its hard to dazzle us but for 25 years the united states space program has been doing just that weve grown used to the idea of space and perhaps we forget that weve only just begun were still pioneers they the members of the Challenger crew were pioneers and i want to say something to the school children of America who were watching the live coverage of the shuttles takeoff i know it is hard to understand but sometimes painful things like this happen its all part of the process of exploration and discovery its all part of taking a chance and expanding mans horizons the future doesnt belong to the fainthearted it belongs to the brave the challenger crew was pulling us into the future and well continue to follow them the crew of the space shuttle challenger honored us by the manner in which they lived their lives we will never forget them nor the last time we saw them this morning as they prepared for the journey and waved goodbye and slipped the surly bonds of earth to touch the face of god"


---

### A text with syntax

"We've grown used to wonders in this century. It's hard to dazzle us. But for 25 years the United States space program has been doing just that. We've grown used to the idea of space, and perhaps we forget that we've only just begun. We're still pioneers. They, the members of the Challenger crew, were pioneers.

And I want to say something to the school children of America who were watching the live coverage of the shuttle's takeoff. I know it is hard to understand, but sometimes painful things like this happen. It's all part of the process of exploration and discovery. It's all part of taking a chance and expanding man's horizons. The future doesn't belong to the fainthearted; it belongs to the brave. The Challenger crew was pulling us into the future, and we'll continue to follow them....

The crew of the space shuttle Challenger honoured us by the manner in which they lived their lives. We will never forget them, nor the last time we saw them, this morning, as they prepared for the journey and waved goodbye and 'slipped the surly bonds of earth' to 'touch the face of God.'"

---

## Object names

```r
# Optimal (short and use of snake case)
day_one
day_1

# Not optimal
first_day_of_the_month
DayOne
dayone
djm1
```

The tidyverse style guide https://style.tidyverse.org/

---

## Overwriting objects

Avoid assigning the same to object or functions that already exists in R or assigning something wrong:

```r
# Not Good

T &amp;lt;- FALSE

c &amp;lt;- 10

x &amp;lt;- seq(from = 1, to = 10)
mean &amp;lt;- function(x) sum(x)
mean(x)
```

---

## Line length

R does not necessary require you to split your code across multiple lines in order to run, but it is good practice to do so:

```r
# Optimal
scdbv &amp;lt;- scdbv %&amp;gt;%
 mutate(chief = factor(chief,
 levels = c("Jay", "Rutledge", "Ellsworth",
 "Marshall", "Taney", "Chase",
 "Waite", "Fuller", "White",
 "Taft", "Hughes", "Stone",
 "Vinson", "Warren", "Burger",
 "Rehnquist", "Roberts")))

# Not optimal
scdbv &amp;lt;- mutate(scdbv, chief = factor(chief, levels = c("Jay", "Rutledge", "Ellsworth", "Marshall", "Taney", "Chase", "Waite", "Fuller", "White", "Taft", "Hughes", "Stone", "Vinson", "Warren", "Burger", "Rehnquist", "Roberts")))
```

---

## Indentation

Indentation makes the code more readable. For example, it is helpful to identify which values are part of which function:

```r
# in a mutate() function
scdbv &amp;lt;- scdbv %&amp;gt;%
 mutate(majority = majority - 1,
 chief = factor(chief,
 levels = c("Jay", "Rutledge", "Ellsworth",
 "Marshall", "Taney", "Chase",
 "Waite", "Fuller", "White",
 "Taft", "Hughes", "Stone",
 "Vinson", "Warren", "Burger",
 "Rehnquist", "Roberts")))
```

---

## Calling functions

If you are using functions that you have not written (e.g., from packages), you do not have the ability to rename them. Sometimes functions have the **same name across different packages**:

```r
library(purrr)
map()
```
--

```r
library(purrr)
library(maps)

map()
```
--

`map()` is defined both in the `purrr` and `maps` package. By default, R will call the function from the package most recently loaded.

---

## `::` notation

To fix this problem, we can detach and re-attach a package, but more frequently we use the `::` notation 

```r
library(purrr)
library(maps)

purrr::map() # use map() from the purrr library
maps::map() # use map() from the maps library
```

--

We can also avoid loading a given package, and just load the specific function that we need from it: 

```r
library(purrr)

map() # use map() from the purrr library
maps::map() # use map() from the maps library
```

---

## Auto-formatting in RStudio

RStudio helps out with these issues:

* `Code &amp;gt; Reformat Code` (Shift + Cmd/Ctrl + A)
* `Code &amp;gt; Reindent Lines` (Cmd/Ctrl + I)
* For better help see [`styler`](http://styler.r-lib.org/) 

&amp;lt;!-- * [This code example](/notes/style-guide/#exercise-style-this-code) --&amp;gt;


---

## Auto-formatting in RStudio
Try it out!
* option 1: `Code &amp;gt; Reformat Code` (Shift + Cmd/Ctrl + A)
* option 2: `Code &amp;gt; Reindent Lines` (Cmd/Ctrl + I)
* option 3: `install.packages("styler")` (should be abel to find it under addins at top right)


```r
 y&amp;lt;-10
if (y &amp;lt; 20) {
 x &amp;lt;- "Too low" 
 } else {
 x &amp;lt;-"Too high"}
```

---

class: inverse, middle

# Condition handling

---

## Condition handling

**Coding style** is one way to practice defensive programming and prevent bugs.

Another way is **condition handling**: set up our code in a way that it tells us if something is problematic.

Three types of conditions:
* (Fatal) Errors
* Warnings
* Messages

---

## Errors

**Code is written incorrectly or asks R to do something that is not possible.**

For example, this `addition()` function takes two arguments and adds them together. Notice the condition checks if either `x` or `y` is not a number. If that's TRUE, the `stop()` function triggers a error and notifies the user:


```r
addition &amp;lt;- function(x, y) {
 if (!is_numeric(c(x, y))) {
 stop("One of your inputs is not a number")
 } else {
 return(x + y)
 }
}

addition(3, "2")
```

```
## Error in is_numeric(c(x, y)): could not find function "is_numeric"
```

---

## Errors

Notice, a function can test for more than one error; you need to check each of them separately with multiple if-else statements. The function stops as soon as it encounters one of them.

How to determine what errors to check for?
1. The more conditional tests you build into the function, the more robust is the function against incorrect uses; BUT the longer it takes to write it
1. Think about who is going to use that function and how frequently
1. Can provide documentation on how to use the function to reduce tests

---

## Warnings

**Code runs but you might want to take a look, as it might be problematic.**

For example, this code defines a function that takes as input `x` a probability value (between 0 and 1) and we want to convert it to a natural logarithm value.

R will execute this code, but when the function is called with values outside the probability range, it gives a warning that says the result produces a “NaN” value ("Not a Number", impossible to calculate):


```r
logit &amp;lt;- function(x) {
 return(log(x / (1 - x)))
}

logit(-1)
```

```
## Warning in log(x/(1 - x)): NaNs produced
```

```
## [1] NaN
```

---

## Warnings

To fix the warning, we can add a condition that signals and triggers an error instead than a warning. 

For example, if `x` is not between 0 and 1, then stop the code:


```r
logit &amp;lt;- function(x) {
 if (x &amp;lt; 0 | x &amp;gt; 1) {
 stop('x not between 0 and 1')
 } else {
 return(log(x / (1 - x)))
 }
}

logit(-1)
```

```
## Error in logit(-1): x not between 0 and 1
```
---

&amp;lt;!--

## Warnings

Same code of the previous slide, written more compactly:


```r
logit &amp;lt;- function(x) {
 if (x &amp;lt; 0 | x &amp;gt; 1) stop('x not between 0 and 1')
 log(x / (1 - x))
}

logit(-1)
```

```
## Error in logit(-1): x not between 0 and 1
```

Notice here we can write `if` and the condition one the same line without the `{}` and still preserve code legibility of this single `if` statement; we can also remove `return`

--&amp;gt;

## Warnings

If we do not want to stop the code from running, we can also fix the warning in other ways, without triggering an error. For example: (1) we can check if `x` is outside the range, if so, replace it with a missing value; (2) trigger a warning if `x` is a missing value (whose log is a missing value)


```r
logit &amp;lt;- function(x) {
 x &amp;lt;- if_else(x &amp;lt; 0 | x &amp;gt; 1,
 NA_real_,
 x)
 if (is.na(x)) {
 warning('x not between 0 and 1') 
 return(log(x / (1 - x)))
 }
}

logit(-1)
```

```
## Warning in logit(-1): x not between 0 and 1
```

```
## [1] NA
```

---

## Messages

**Messages do not indicate that something is wrong, but provide useful information to the user.**

For example, here we are plotting with `geom_point()` and `geom_smooth()`, which automatically decides which smoothing algorithm to use to create the line (default is `gam` based on sample size):


```r
ggplot(diamonds, aes(carat, price)) +
 geom_point() + geom_smooth()
```

```
## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'
```

&amp;lt;img src="index_files/figure-html/message_ggplot-1.png" width="35%" style="display: block; margin: auto;" /&amp;gt;

---

## Messages

To write a message in your code, use the `message()` function.


```r
demo_message &amp;lt;- function() message("This is a message")
demo_message()
```

```
## This is a message
```

You can also suppress a message, if you want, with `suppressMessages()`:

```r
suppressMessages(demo_message()) # no output
```

--

You do not want to use `print()` to create a message. The `supressMessages()` function would not work with it.

---

class: inverse, middle

# Debugging

---

## Debugging techniques

1. Realize that you have a bug
1. Make it repeatable
1. Figure out where it is
1. Fix it

---

## The call stack

**Often times, when we run a piece of code the actual cause of the problem is not in the line we run.** 

For example, here we have several functions that call other functions: `f` is a function that takes an input `a` and passes it into another function `g`; `g` takes an input `b` and passes it into function `h`, etc. 

The problem is in function `i`, but let's say in our code we call function `f`:


```r
f &amp;lt;- function(a) g(a)
g &amp;lt;- function(b) h(b)
h &amp;lt;- function(c) i(c)
i &amp;lt;- function(d) "a" + d

f(10)
```

```
## Error in "a" + d: non-numeric argument to binary operator
```

---

## The call stack

We cannot fix function `f`, because the problem does not occur there. We need to fix function `i` which triggers a the entire call sequence. 

Use `traceback()`, which is often shown automatically in RStudio, and read it from bottom to top. The line at the top is where the error occurred:


```r
traceback()
```

```
# 4: i(c) at exceptions-example.R#3
# 3: h(b) at exceptions-example.R#2
# 2: g(a) at exceptions-example.R#1
# 1: f(10)
```
---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/exploratory-data-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/exploratory-data-analysis/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Exploratory Data Analysis&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Exploratory Data Analysis
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Exploratory Data Analysis

---

## Definition of Exploratory Data Analysis (EDA)

**All set of initial investigations in order to get a sense of your data and generate questions**: 
+ discovering patterns 
+ spot anomalies (outliers)
+ formulate and refine questions 
+ check initial hypotheses before formally testing them

--

Exploratory Data Analysis (EDA):
* relies on **visualizations** and frequently goes together with **descriptive statistics**
* is different from **Explanatory or Confirmatory Data Analysis** 

---

## Exploratory Data Analysis as iterative cycle

Chapter 7 of R for Data Science defines EDA as an iterative process:

1. Generate questions about your data
1. Search for answers in the data by transforming, visualizing, and modeling the data
1. Use what you learn to refine your questions and/or generate new questions
1. Repeat until necessary

--

EDA is a **creative process**: it is not an exact science. It requires knowledge of your data and a lot of time. At the most basic level, it involves answering two questions:

1. What type of **variation** occurs within my variables?
2. What type of **covariation** occurs between my variables?


---

## How to perform Exploratory Data Analysis?

EDA relies on:
- **descriptive stats** such as measures of central tendency (mean, mode, median) and of dispersion (variance, standard deviation)
- **visualization tools** such box plots, histograms, bar charts, and scatter plots 

--

We focus on visualizations, and especially on:
- *Variation* that is how values within a single variable vary (univariate analysis)
- *Covariation* that how values of two variables co-vary (bivariate analysis)

--

&amp;gt; Visualizations are employed in both Exploratory and Confirmatory Data Analysis, but their use is different. 

&amp;lt;!--
In Exploratory Analysis you might generate 100 or even 1000 graphs, but not all of them will be useful for your research. In Confirmatory Analysis, you generate only a few graphs and each graph is well refined.
--&amp;gt;

---

class: inverse, middle

# Exploratory VS Confirmatory Data Analysis

---

## Comparing Exploratory and Confirmatory plots


```r
library(palmerpenguins)
data("penguins")

head(penguins)
```

```
## # A tibble: 6 × 8
## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Adelie Torgersen 39.1 18.7 181 3750
## 2 Adelie Torgersen 39.5 17.4 186 3800
## 3 Adelie Torgersen 40.3 18 195 3250
## 4 Adelie Torgersen NA NA NA NA
## 5 Adelie Torgersen 36.7 19.3 193 3450
## 6 Adelie Torgersen 39.3 20.6 190 3650
## # ℹ 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;
```

We want build a plot of two continuous variables: penguins body mass (in grams) and penguins flipper length (in millimeters)

---



count: false
 
## Exploratory plot
.panel1-penguins-eda-auto[

```r
*ggplot(
* data = penguins,
* mapping = aes(
* x = body_mass_g,
* y = flipper_length_mm
* )
*) 
```
]
 
.panel2-penguins-eda-auto[
&amp;lt;img src="index_files/figure-html/penguins-eda_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Exploratory plot
.panel1-penguins-eda-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
* geom_point()
```
]
 
.panel2-penguins-eda-auto[
&amp;lt;img src="index_files/figure-html/penguins-eda_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Exploratory plot
.panel1-penguins-eda-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
 geom_point() +
* geom_smooth()
```
]
 
.panel2-penguins-eda-auto[
&amp;lt;img src="index_files/figure-html/penguins-eda_auto_03_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-penguins-eda-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-penguins-eda-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-penguins-eda-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



Simple exploratory plot. What does this graph tell us?

--

Pros: minimum code, easy to replicate, good for your internal use
Cons: not well refined, not good for publication or external audience

How can we improve this graph?

---



count: false
 
## Confirmatory plot
.panel1-penguins-final-auto[

```r
*ggplot(
* data = penguins,
* mapping = aes(
* x = body_mass_g,
* y = flipper_length_mm
* )
*) 
```
]
 
.panel2-penguins-final-auto[
&amp;lt;img src="index_files/figure-html/penguins-final_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Confirmatory plot
.panel1-penguins-final-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
* geom_point(alpha = .1)
```
]
 
.panel2-penguins-final-auto[
&amp;lt;img src="index_files/figure-html/penguins-final_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Confirmatory plot
.panel1-penguins-final-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
 geom_point(alpha = .1) +
* geom_smooth(se = FALSE)
```
]
 
.panel2-penguins-final-auto[
&amp;lt;img src="index_files/figure-html/penguins-final_auto_03_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Confirmatory plot
.panel1-penguins-final-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
 geom_point(alpha = .1) +
 geom_smooth(se = FALSE) +
* labs(
* title = "Relationship between body mass and\nflipper length of a penguin",
* subtitle = "Sample of 344 penguins",
* x = "Body mass (g)",
* y = "Flipper length (mm)"
* )
```
]
 
.panel2-penguins-final-auto[
&amp;lt;img src="index_files/figure-html/penguins-final_auto_04_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Confirmatory plot
.panel1-penguins-final-auto[

```r
ggplot(
 data = penguins,
 mapping = aes(
 x = body_mass_g,
 y = flipper_length_mm
 )
) +
 geom_point(alpha = .1) +
 geom_smooth(se = FALSE) +
 labs(
 title = "Relationship between body mass and\nflipper length of a penguin",
 subtitle = "Sample of 344 penguins",
 x = "Body mass (g)",
 y = "Flipper length (mm)"
 ) +
* theme_xaringan(
* title_font_size = 18,
* text_font_size = 16
* )
```
]
 
.panel2-penguins-final-auto[
&amp;lt;img src="index_files/figure-html/penguins-final_auto_05_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-penguins-final-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-penguins-final-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-penguins-final-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



Plot for confirmatory purposes. It requires more code. Good for a final report, class presentation, paper, etc. but not necessary for exploratory purposes.




---

class: inverse, middle

# EDA with the `scorecard` dataset

### Data on every four-year college university in the U.S.
The Department of Education collects annual statistics on colleges and universities in the United States. We are going to look at a subset of this data from 2018-19.

---

## `scorecard`


```r
library(rcis)
data("scorecard")
glimpse(scorecard)
```

```
## Rows: 1,721
## Columns: 14
## $ unitid &amp;lt;dbl&amp;gt; 100654, 100663, 100706, 100724, 100751, 100830, 100858, 1009…
## $ name &amp;lt;chr&amp;gt; "Alabama A &amp;amp; M University", "University of Alabama at Birmin…
## $ state &amp;lt;chr&amp;gt; "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", …
## $ type &amp;lt;fct&amp;gt; "Public", "Public", "Public", "Public", "Public", "Public", …
## $ admrate &amp;lt;dbl&amp;gt; 0.8965, 0.8060, 0.7711, 0.9888, 0.8039, 0.9555, 0.8507, 0.60…
## $ satavg &amp;lt;dbl&amp;gt; 959, 1245, 1300, 938, 1262, 1061, 1302, 1202, 1068, NA, 1101…
## $ cost &amp;lt;dbl&amp;gt; 23445, 25542, 24861, 21892, 30016, 20225, 32196, 32514, 3483…
## $ netcost &amp;lt;dbl&amp;gt; 15529, 16530, 17208, 19534, 20917, 13678, 24018, 19808, 2050…
## $ avgfacsal &amp;lt;dbl&amp;gt; 68391, 102420, 87273, 64746, 93141, 69561, 96498, 62649, 533…
## $ pctpell &amp;lt;dbl&amp;gt; 0.7095, 0.3397, 0.2403, 0.7368, 0.1718, 0.4654, 0.1343, 0.22…
## $ comprate &amp;lt;dbl&amp;gt; 0.2866, 0.6117, 0.5714, 0.3177, 0.7214, 0.3040, 0.7870, 0.70…
## $ firstgen &amp;lt;dbl&amp;gt; 0.3658281, 0.3412237, 0.3101322, 0.3434343, 0.2257127, 0.381…
## $ debt &amp;lt;dbl&amp;gt; 15250, 15085, 14000, 17500, 17671, 12000, 17500, 16000, 1425…
## $ locale &amp;lt;fct&amp;gt; City, City, City, City, City, City, City, City, City, Suburb…
```

---

## Types of visualization we can perform:

#### *Variation* -- how values within a single variable vary (univariate analysis)
 
* continuous variable: histogram
* categorical variable: bar chart


#### *Covariation* -- how values of two variables co-vary (bivariate analysis)

* continuous variables: scatter plot
* categorical variables: compute count for each, then visualize
* categorical and continuous variables: box plot

---

class: inverse, middle

# Variation: univariate analysis

---



count: false
 
## Histogram
.panel1-histogram-auto[

```r
*ggplot(
* data = scorecard,
* mapping = aes(x = cost)
*) 
```
]
 
.panel2-histogram-auto[
&amp;lt;img src="index_files/figure-html/histogram_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Histogram
.panel1-histogram-auto[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = cost)
) +
* geom_histogram()
```
]
 
.panel2-histogram-auto[
&amp;lt;img src="index_files/figure-html/histogram_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-histogram-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-histogram-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-histogram-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



HISTOGRAM: for **continuous variables** (here cost). It splits the input variable into n sets of equal width and does a frequency count within each set.

--

What does this histogram tell us?

--

Follow up questions we might ask: Why do we have these different picks? Who are the outliers?

---



count: false
 
## Histogram
.panel1-histogram-bins-rotate[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = cost)
) +
* geom_histogram(bins = 50)
```
]
 
.panel2-histogram-bins-rotate[
&amp;lt;img src="index_files/figure-html/histogram-bins_rotate_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Histogram
.panel1-histogram-bins-rotate[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = cost)
) +
* geom_histogram(bins = 30)
```
]
 
.panel2-histogram-bins-rotate[
&amp;lt;img src="index_files/figure-html/histogram-bins_rotate_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Histogram
.panel1-histogram-bins-rotate[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = cost)
) +
* geom_histogram(bins = 10)
```
]
 
.panel2-histogram-bins-rotate[
&amp;lt;img src="index_files/figure-html/histogram-bins_rotate_03_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-histogram-bins-rotate {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-histogram-bins-rotate {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-histogram-bins-rotate {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



Bins: each bar is a bin and represents one interval or set of data; `bins` control the size of each bar. In these examples, we divided the data into 50, 30 (default), or 10 equally sized bars.

---



count: false
 
## Bar chart
.panel1-barplot-auto[

```r
*ggplot(
* data = scorecard,
* mapping = aes(x = type)
*) 
```
]
 
.panel2-barplot-auto[
&amp;lt;img src="index_files/figure-html/barplot_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Bar chart
.panel1-barplot-auto[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = type)
) +
* geom_bar()
```
]
 
.panel2-barplot-auto[
&amp;lt;img src="index_files/figure-html/barplot_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-barplot-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-barplot-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-barplot-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



BAR CHART: for **categorical variables** (here type). It takes each category of the variable and automatically applies a frequency count to aggregate the data by variable. 

---

## Bar chart 



The default stats for `geom_bar()` is `count`. See [documentation](https://ggplot2.tidyverse.org/reference/geom_bar.html) for more info.

It means that under the hood `geom_bar()` performs the equivalent of the following:


```r
scorecard %&amp;gt;%
 count(type)
```

```
## # A tibble: 3 × 2
## type n
## &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Public 533
## 2 Private, nonprofit 1103
## 3 Private, for-profit 85
```

Unless we explicitly tell `geom_bar()` not to do so with `geom_bar(stats = "identity")`

---

## Reorder factor levels in a bar chart

.panelset[
.panel[.panel-name[Not Ordered]


&amp;lt;img src="index_files/figure-html/not-ordered-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]

.panel[.panel-name[Ordered]

&amp;lt;img src="index_files/figure-html/reordered-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## Reorder factor levels in a bar chart

The most straightforward approach to reorder the levels of a categorical variables is with dplyr and ggplot combined:

```
# calculate count for variable of interest and save in new dataframe
count_type &amp;lt;- scorecard %&amp;gt;%
 count(type)

# use the new dataframe to create the graph
ggplot(count_type,
 mapping = aes(x = reorder(type, desc(n)), 
 y = n)) +
 geom_bar(stat = "identity")
```

--

```
# same results in one step
scorecard %&amp;gt;%
 count(type) %&amp;gt;%
 ggplot(mapping = aes(x = reorder(type, desc(n)), 
 y = n)) +
 geom_bar(stat = "identity")
```


---

## Reorder factor levels in a bar chart

[`fct_relevel()`](https://forcats.tidyverse.org/reference/fct_relevel.html): allows to reorder factor levels by hand

```
scorecard %&amp;gt;%
 mutate(
 type = fct_relevel(.f = type, 
 levels = "Private, nonprofit", "Public", "Private, for-profit" )) %&amp;gt;%
 ggplot(
 mapping = aes(x = type)) +
 geom_bar()
```

[`fct_infreq()`](https://forcats.tidyverse.org/reference/fct_inorder.html): reorders factor levels by the number of obs. with each level (e.g., by frequency)

```
scorecard %&amp;gt;%
 mutate(type = fct_infreq(type)) %&amp;gt;%
 ggplot(
 mapping = aes(x = type)) +
 geom_bar()
```

---

## Other types of univariate and bivariate graphs

See the Visualization cheat sheet! 

Help &amp;gt; Cheat Sheets &amp;gt; Data Visualization with ggplot2

---

class: inverse, middle

# Covariation: bivariate analysis

---

## Covariation

1. Two-dimensional graphs
1. Multiple window plots
1. Utilizing additional channels

---



count: false
 
## Box plot
.panel1-boxplot-auto[

```r
*ggplot(
* data = scorecard,
* mapping = aes(
* x = type,
* y = cost
* )
*) 
```
]
 
.panel2-boxplot-auto[
&amp;lt;img src="index_files/figure-html/boxplot_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Box plot
.panel1-boxplot-auto[

```r
ggplot(
 data = scorecard,
 mapping = aes(
 x = type,
 y = cost
 )
) +
* geom_boxplot()
```
]
 
.panel2-boxplot-auto[
&amp;lt;img src="index_files/figure-html/boxplot_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-boxplot-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-boxplot-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-boxplot-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



BOX PLOT: looks at the relationship between a **continuous variable** (here cost) and a **categorical variable** (here type). It summarizes the continuous variable distribution across each of the categorical variables.

--

What does this box plot tell us?

&amp;lt;!-- median is the line in the middle, the middle value 
Here we see that on average, public universities are the least expensive, followed by private for-profit institutions. I was somewhat surprised by this since for-profit institutions by definition seek to generate a profit, so wouldn't they be the most expensive? But perhaps this makes sense, because they have to attract students so need to offer a better financial value than competing nonprofit or public institutions. Is there a better explanation for these differences? Another question you could explore after viewing this visualization.
--&amp;gt;

---

## Box plot

&amp;lt;img src="https://d33wubrfki0l68.cloudfront.net/153b9af53b33918353fda9b691ded68cd7f62f51/5b616/images/eda-boxplot.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source of image: R for Data Science Chapter 7]


---



count: false
 
## Scatterplot
.panel1-scatterplot-auto[

```r
*ggplot(
* data = scorecard,
* mapping = aes(
* x = cost,
* y = netcost
* )
*) 
```
]
 
.panel2-scatterplot-auto[
&amp;lt;img src="index_files/figure-html/scatterplot_auto_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Scatterplot
.panel1-scatterplot-auto[

```r
ggplot(
 data = scorecard,
 mapping = aes(
 x = cost,
 y = netcost
 )
) +
* geom_point()
```
]
 
.panel2-scatterplot-auto[
&amp;lt;img src="index_files/figure-html/scatterplot_auto_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-scatterplot-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-scatterplot-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-scatterplot-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



SCATTERPLOT: looks at the relationship between two **continuous variables** (here cost and netcost). 


--

What does this scatterplot tell us?

&amp;lt;!--

As the advertised price increases, the net cost also increases though with significant variation. Some schools have a much lower net cost than their advertised price.

No clear alignment on diagonal, net costs tend to be lower than adv costs for several schools, especially as the adv costs increase; in most universities the average student pay less than the adv costs. It is a 2d plot bcs we are mapping two variables: one on the y and one on the x.

Link to next slide: for histogram does not make sense to map a second variable on the y, beside count/frequency bcs with a histogram see the total distribution (vs box plot in which you see summary stats of the distribution). 
--&amp;gt;

---



count: false
 
## Multiple windows plot - faceted histogram
.panel1-histogram-facet-user[

```r
*ggplot(
* data = scorecard,
* mapping = aes(x = cost)
*) +
* geom_histogram()
```
]
 
.panel2-histogram-facet-user[
&amp;lt;img src="index_files/figure-html/histogram-facet_user_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Multiple windows plot - faceted histogram
.panel1-histogram-facet-user[

```r
ggplot(
 data = scorecard,
 mapping = aes(x = cost)
) +
 geom_histogram() +
* facet_wrap(facets = vars(type))
```
]
 
.panel2-histogram-facet-user[
&amp;lt;img src="index_files/figure-html/histogram-facet_user_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-histogram-facet-user {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-histogram-facet-user {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-histogram-facet-user {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



Multiple windows plot - HISTOGRAM WITH FACETS: looks at **categorical variables**. 

On the y axis is frequency count (calculated from the x). With histograms we cannot map a second variable on the y, but we can use facets to compare the distribution of each college type. Compare with box plot.

---



count: false
 
## Multiple windows plot - faceted scatterplot
.panel1-scatterplot-facet-user[

```r
*ggplot(
* data = scorecard,
* mapping = aes(
* x = cost,
* y = netcost
* )
*) +
* geom_point()
```
]
 
.panel2-scatterplot-facet-user[
&amp;lt;img src="index_files/figure-html/scatterplot-facet_user_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Multiple windows plot - faceted scatterplot
.panel1-scatterplot-facet-user[

```r
ggplot(
 data = scorecard,
 mapping = aes(
 x = cost,
 y = netcost
 )
) +
 geom_point() +
* facet_wrap(facets = vars(type))
```
]
 
.panel2-scatterplot-facet-user[
&amp;lt;img src="index_files/figure-html/scatterplot-facet_user_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-scatterplot-facet-user {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-scatterplot-facet-user {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-scatterplot-facet-user {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



Multiple windows plot - SCATTERPLOT WITH FACETS: looks at **continuous variables** (here cost and netcost) and plot each in a separate panel with same scale range on the x and y.

---



count: false
 
## Utilizing additional aesthetics
.panel1-scatterplot-mult-channels-rotate[

```r
ggplot(
 data = scorecard,
 mapping = aes(
 x = cost,
 y = netcost,
* color = type,
 )
) +
 geom_point()
```
]
 
.panel2-scatterplot-mult-channels-rotate[
&amp;lt;img src="index_files/figure-html/scatterplot-mult-channels_rotate_01_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 
## Utilizing additional aesthetics
.panel1-scatterplot-mult-channels-rotate[

```r
ggplot(
 data = scorecard,
 mapping = aes(
 x = cost,
 y = netcost,
* color = type, size = debt
 )
) +
 geom_point()
```
]
 
.panel2-scatterplot-mult-channels-rotate[
&amp;lt;img src="index_files/figure-html/scatterplot-mult-channels_rotate_02_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-scatterplot-mult-channels-rotate {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 60%
}
.panel2-scatterplot-mult-channels-rotate {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 60%
}
.panel3-scatterplot-mult-channels-rotate {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 60%
}
&amp;lt;/style&amp;gt;



Additional info: rather than using facets to sort each distribution, we could use the color aesthetic to automatically incorporate the `type` info into the same visualization.

We can also add a fourth variable such as `depth` and render it through the size aesthetic. However, does adding `depth` make the graph more informative? 


---

class: inverse, middle

# Factors

---

Categorical variables, also called discrete variables, are variables that have a fixed set of possible values. R uses **factors** to work these variables.

[**Chapter 15 of R for Data Science**](https://r4ds.had.co.nz/factors.html) goes in-depth on creating and modifying factors: 


```r
month_string &amp;lt;- c(
 "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
 "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
month_string
typeof(month_string) # character
class(month_string) # character
```


```r
month_factor &amp;lt;- factor(month_string, levels = month_string)
month_factor
typeof(month_factor) # integer
class(month_factor) # factor
```

* `class`: attribute of the object, regardless of R internal storage
* `typeof`: R internal storage of the object

---

class: inverse, middle

# Practice exploring data

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/getting-data-from-the-web-api-access/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/getting-data-from-the-web-api-access/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Getting data from the web: API access&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Getting data from the web: API access
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Getting data from the web (aka web scraping)

---
## Agenda
1. Broad overview of APIs and getting data
1. Examples: here we're going to increase in order of difficulty / challenge
 1. world bank data
 1. geonames
 1. OMDB
 

&amp;gt; Note: You'll want to get your accounts setup so that you have an API key for today's exercises if you haven't already: [see class page for links &amp;gt; and details](https://macs30500.netlify.app/syllabus/getting-data-from-the-web-api-access/)
---

&amp;lt;img src="webscraping.png" width="70%" style="display: block; margin: auto;" /&amp;gt;

[Image Source](https://medium.com/analytics-vidhya/web-scraping-in-python-for-data-analysis-6bf355e4fdc8)

---

## Web scraping

Web scraping is **the process of collecting or "scraping" information from a website**. 

If you have ever copied and pasted information from the Internet, you have performed the same task as any scraper, just on a small scale! Web scraping allows automating this process to collect hundreds, thousands, or even millions of information. 

--

Examples: 
* companies' names, emails, and phone numbers 
* newspaper articles 
* customer reviews
* products' prices, descriptions, and characteristics 
* real estate data
* statistical data
* social media data
* etc.

---

class: inverse, middle

# Two main ways to scrape data from the web
 ### Option 1: Using a web API (with or without a R package)
 ### Option 2: Directly scraping the website

---

## Two main ways to scrape data from the web
### Option 1: Using a web API

 &amp;gt; A web API (Application Programming Interface) is an interface provided by the website that helps users to collect data from that specific website.

When using an API, we might have two approaches available to us:

* approach 1: using an API through an R package that someone has written to interact with that API. The package acts as a **wrapper for the given API**, and is generally easier to use than the API. If such a package exists (not all APIs have a wrapper in R) all you have to do is to install it, and learn how to use it (e.g., read the documentation for that specific package)

* approach 2: if no R wrapper exists, you can **directly use the API** provided by the website. In this case, the user relies on R to directly interact with the website's API.

NB: sometimes both approaches are available; other times only approach 2 is available (if no one has developed an R package to interact with that specific API).

---

## Two main ways to scrape data from the web
### Option 2: Directly scraping the website

 &amp;gt; Every website, behind the pretty display we see, is made up of code (a mix of HTML, CSS and Javascript). Therefore, each website, and the information stored in it, are directly accessible by users, if they know how to interact with the website's raw code. 

 &amp;gt; Often scraping a website directly is necessary to collect the data we need. However, (1) if a website has an API, the general rule is to use it; and (2) you want to check the website's rules for scraping (ToS and `robots.txt`)

---

## Our plan

Today we focus on option 1: using APIs. We see examples of both approaches: using an API in R, with and without an R wrapper. 

Next lecture we focus on option 2: direct scraping. 
 
But, before we delve into the APIs world, there are two broad concepts that we need to learn:

&amp;gt; Concept 1: **What is behind a website** (e.g., what websites are made of)

&amp;gt; Concept 2: **How the web works** (e.g., how computers interact on the web)

---

class: inverse, middle

# Concept 1: What is behind a website (e.g., what websites are made of)

---

## What is behind a website

A website is made of the following elements:

+ **HTML**, which means *HyperText Markup Language*, is the core element of a website. HTML uses a set of tags to organize the webpage (i.e., makes the text bold, creates body text, paragraphs, inserts hyperlinks, etc.), but when the page is displayed the markup language is hidden

+ **CSS**, which means *Cascading Style Sheets*, adds styling to make the page looks nicer

+ **Javascript (JS)** code, which is used to add interactive elements to the page (you need "dynamic web scraping" techniques to interact with JS)

+ **Other stuff** such as images, hyperlinks, videos or multimedia

---

## HTML

* most important element we need to learn for web scraping
* makes the "skeleton" or structure of a website
* quite messy to read, but it follows a hierarchical, tree-like structure since it embeds tags within tags (everything marked with `&amp;lt;&amp;gt;` is a tag)

Standard HTML syntax, simplified example:
```
 &amp;lt;html&amp;gt;
 &amp;lt;head&amp;gt;
 &amp;lt;title&amp;gt;general info about the page&amp;lt;/title&amp;gt;
 &amp;lt;/head&amp;gt;
 &amp;lt;body&amp;gt;
 &amp;lt;p&amp;gt;a paragraph with some text about the page&amp;lt;/p&amp;gt;
 &amp;lt;p&amp;gt;another paragraph with more text&amp;lt;/p&amp;gt;
 &amp;lt;p&amp;gt;...&amp;lt;/p&amp;gt;
 &amp;lt;/body&amp;gt;
 &amp;lt;/html&amp;gt;
 
```

Tree-like structure:[click here for a visual example of html](https://www.researchgate.net/figure/HTML-source-code-represented-as-tree-structure_fig10_266611108) 


---

## HTML Tags

In web scraping, we collect information from websites using **tags**. 

Tags:

* are organized in a tree-like structure and are nested within each other
* go in pairs: one on each end of the content that they display; for example `&amp;lt;p&amp;gt;ciao&amp;lt;/p&amp;gt;` only the word "ciao" shows up on the webpage (the `/` signals the end of the tag)
* can have attributes which provide more information

Refer to this **[list of tags](https://developer.mozilla.org/en-US/docs/Web/HTML/Element )** for your scraping projects

&amp;lt;!-- add more info here
https://plsc-31101.github.io/course/collecting-data-from-the-web.html#webscraping
* more frequently used tags
* more on tags attributes
* CSS 
* CSS and HTML
* see staff from my Python course, lecture 2 (e.g. every page is different, no perfect structure,etc.)
--&amp;gt;

--

**Knowing how read the HTML (and CSS) language, is fundamental for web scraping.** Especially when we scrape the website directly. When we use an API and/or an API wrapper, this is less important, but still useful.

---

class: inverse, middle

# Concept 2: How the web works (e.g., how computers interact on the web)

---

## High-level: How do computers interact on the web?

Computers talk to each other on the web by sending and receiving (GET) **data requests** and (POST) **data responses**: some making requests, some receiving and answering them, some doing both. Every computer has an address that other computers can refer to.

When you click on a webpage, the **web browser** of your computer (e.g., chrome, safari, etc.) makes a data request to the **web server** of that page (a database where all the info about that page are stored), and gets back a response.

&amp;lt;img src="request_response.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

Image Source [at this link](https://www.linkedin.com/pulse/what-happens-when-you-enter-url-browser-he-asked-victor-ohachor)

---

## Example: How do computers interact on the web? 

Navigating the web basically means **sending a bunch of requests to different servers and receiving different files written in HTML.**

For example, if you type `https://macss.uchicago.edu/content/current-student-resources` into your web browser and hit enter, these steps occur under the hood:

--
1. your web browser translates what you typed into a HTTP request to tell the `macss` web server that you would like to access the info stored at `/content/current-student-resources` and that the protocol to use is the `https`

--
1. the web server that hosts `macss` receives your request and sends back to your web browser an HTTP response and the response content (a bunch of files written in HTML)

--
1. your browser receives and transforms the response content into a nice visual display that might include texts, graphics, hyperlinks, etc.

--

 
When we perform these operations with the goal of scraping data, there are packages in R that perform these steps for us (either via APIs or without). 

---

class: inverse, middle

# Scraping using an API: Application Programming Interface

---

## API: Terminology

 &amp;gt; A web API (Application Programming Interface) is an interface provided by the website that helps users to collect data from that specific website.

The majority of web APIs use a particular style know as **REST** or **RESTful** which stands for *Representational State Transfer*. These allows to query the website database using URLs, just like you would construct an URL to view a web page.

An **URL**, which stays for *Uniform Resource Location*, is a string of characters that uses the **HTTP**, or *HyperText Transfer Protocol*, to send request for data.

---

## Sending queries to APIs 

The process described in the `macss` example is very similar to how APIs work, with only a few changes:

* The character string that you use for sending requests (aka queries) to an API (e.g., the URL or website address) will have search terms and/or filtering parameters, and authentication codes specific to that API.

* The response you get back from the API server is not formatted as HTML, but it will likely be a raw text response.

* You need R to parse that response and convert it into a format that you like (dataframe, lists, etc.) and then export it as `.csv` or `.json`.

---

## Using APIs with a wrapper package

* Specific packages written for existing APIs. If a package for a given API exists, that package is tailored to that specific API and not transferable to other APIs. 

* Wrapper packages can be useful because they are 
 * Reproducible
 * Up-to-date (ideally)
 * Easy to access
 
* How do I know if a R wrapper package for a specific API exists? **Google it**

* How do I learn how to use a specific R wrapper package? **Each package should come with documentation (either a pdf, or a GitHub repo, or both) that explains how to use it and the main functions defined in it. It is essential to read the documentation to understand how to use a package.**

---

## Using APIs with a wrapper package: examples

The class materials for today (download it from the website: `usethis::use_course("CFSS-MACSS/web-api-access")`) include five examples of APIs that have a wrapper package:

* Omdb database
* GeoNames
* Census
* Manifesto Project
* Wordbank

We will review the first two in class. Please, work through the other two examples on your own.

---

## Using APIs with a wrapper package: examples

**Wordbank database API**: `wbstats` R wrapper package
* rich set of socioeconomic indicators spanning several decades and dozens of topics
* full data available for bulk download as CSV files from their website (see HW5); but frequently you only need to obtain a handful of indicators or a subset of countries
* the `wbstats` package provides a wrapper for R for easier access to the API; it returns the results in a tidy data frame 


**GeoNames geographical database API**: `geonames` R wrapper package
* geographical information for all countries and other locations
* the `geonames` package provides a wrapper for R

---

## Using APIs with a wrapper package: examples

**Census Bureau API**: `tidycensus` R wrapper package
* statistical data from the US Census Bureau
* the `tidycensus` provides a R wrapper for the US Census Bureau’s Census and five-year American Community Survey APIs

**Manifesto Project API**: `manifestoR` R wrapper package
* political party manifestos from around the world
* covers 1,000+ parties from 1945 until today in 50+ countries on five continents. 
* the `manifestoR` package provides a wrapper for R


---

## Using APIs directly (without a wrapper package)

Not all APIs have a R wrapper package to help us interact with them. If such wrapper does not exist, we can always interact directly with the API! This usually entrails more code (such as writing our own functions), but also the ability to customize our data requests. 

The class materials for today also include one example of this kind: **OMDb Open Movie Database**

**Looking for more examples?** See the HW7 instructions for suggestions

---

class: inverse, middle

# Scraping using an API: registering for access

---

## Using APIs: register for access

**Many APIs require you to register for access.** Sometimes this is as quick as providing email and password; and receiving an email with your username, private API key, etc.. Other times you have to submit an application and go through a review process (e.g., Twitter). Often this process is free, but some APIs require you to pay. 

Registering for access, allows APIs to track which users are submitting queries and manage demand. If you submit too many queries too quickly, you might be **rate-limited** and your requests de-prioritized or blocked: when in doubt, check the API access policy of the web site to determine what these limits are.

Notice if a given API requires you to register and obtain a username, password, or key to interact with it, you will have to provide this same information also in the R wrapper package.

---

## Using APIs: store username and other private info

**To tell R your APIs username (and key, if necessary), you have two options**. For example, the `geonames` API requires you to register and set a username:

1. You could run the line `options(geonamesUsername = "my_user_name")` in R.

1. However, this is insecure, especially if you plan to put your work on GitHub. We don't want to risk committing this line and pushing it to our public GitHub page. Instead, you should (please do so for your HW7):
 * create a file in the same place as your `.Rproj` file. To do that, run the following command from the R console `usethis::edit_r_profile(scope = "project")`. This will create a special file called `.Rprofile` in the same directory as your `.Rproj` file (assuming you are working in an R project)
 * the file should open automatically in your RStudio script editor; otherwise open the file and add `options(geonamesUsername = "my_user_name")` to that file, replacing `my_user_name` with your Geonames username.

---

## Using APIs: store username and other private info

Important:
* Make sure your `.Rprofile` ends with a blank line
* Make sure `.Rprofile` is included in your `.gitignore` file, otherwise it will be posted on GitHub
* Restart RStudio after modifying `.Rprofile` in order to load any new keys into memory
* Spelling is important when you set the option in your `.Rprofile`


---
## Exercises

For the remainder of class, we'll walk through these resources: `usethis::use_course("CFSS-MACSS/web-api-access")`
1. **world bank**: this has a wrapper and does not require any user names / prior registration
1. **geonames**: this has ai wrapper and requires a user name with prior registration (free)
1. **OMDB**: this does not have a wrapper and requires an api key with prior registration (free)

---

## Acknowledgments 

APIs examples are drawn from Rochelle Terman’s "Finding APIs" page [here](https://plsc-31101.github.io/course/collecting-data-from-the-web.html#finding-apis) and Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/getting-data-from-the-web-scraping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/getting-data-from-the-web-scraping/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Getting data from the web: scraping&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Getting data from the web: scraping
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






# Agenda
* Recap: APIs
* Intro to rvest
* Example: Scraping presidential statements
* Applications: work in groups
* Ethics / considerations when scraping
* Recap


---
class: inverse, middle

# Scraping without an API

### Last time we learned two main concepts...

---

### Last time we learned two main concepts...

#### Concept 1: What is behind a website
* a website is made of mostly HTML, CSS, JS
* **HTML** the website's "skeleton"; it is built with **tags** that follow a hierarchical, tree-like structure 
* **CSS** builds on top of HTML and makes it prettier

#### Concept 2: How computers interact on the web
* the browser sends a request to the server that hosts the website
* the server sends back a response code + a response content written in HTML
* the browser translates the response content written in HTML into nicely rendered the website

---

class: inverse, middle

# HTML: HyperText Markup Language

---

## HTML structure

* `html`
 * `head`
 * `title`
 * `a href`
 * `script`
 * `body`
 * `div`
 * `p`
 * `b`
 * `span`
 * `table`
 * `tr`
 * `td`
 * `td`
 * `img`

---

## HTML structure

* `html`
 * `head`
 * `title`
 * `a href` -- links
 * `script` -- code
 * `body`
 * `div` -- generic container for content (block)
 * `p` -- paragraph
 * `b` -- bold formatting
 * `span` -- generic container for content (in line)
 * `table`
 * `tr` -- row of cells
 * `td` -- actual cell element 
 * `td`
 * `img`


---

## HTML structure: example

.small[
```html
&amp;lt;html&amp;gt;
 &amp;lt;head&amp;gt;
 &amp;lt;title&amp;gt;Title&amp;lt;/title&amp;gt;
 &amp;lt;a href="http://github.com"&amp;gt;GitHub&amp;lt;/a&amp;gt;
 &amp;lt;script src="https://c.js"&amp;gt;&amp;lt;/script&amp;gt;
 &amp;lt;/head&amp;gt;
 &amp;lt;body&amp;gt;
 &amp;lt;div&amp;gt;
 &amp;lt;p&amp;gt;Click &amp;lt;b&amp;gt;here&amp;lt;/b&amp;gt; now.&amp;lt;/p&amp;gt;
 &amp;lt;span&amp;gt;Frozen&amp;lt;/span&amp;gt;
 &amp;lt;/div&amp;gt;
 &amp;lt;table style="width:100%"&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td&amp;gt;Kristen&amp;lt;/td&amp;gt;
 &amp;lt;td&amp;gt;Bell&amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/table&amp;gt;
 &amp;lt;img src="http://ia.media-imdb.com/images.png"/&amp;gt;
 &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
```
]
Find: (1) the text content `Frozen`; (2) the GitHub link and the text content `GitHub`

---

## Components of HTML code

**Find the text content `Frozen`:**

```html
&amp;lt;span&amp;gt;Frozen&amp;lt;/span&amp;gt;
```

* `&amp;lt;span&amp;gt;&amp;lt;/span&amp;gt;` - tag name
* `Frozen` - content as text

&amp;lt;!--In this ex. there is only one span tag: what if the HTML has multiple span tags?--&amp;gt;
--

**Find the GitHub link and text content `GitHub`:**

```html
&amp;lt;a href="http://github.com"&amp;gt;GitHub&amp;lt;/a&amp;gt;
```

* `&amp;lt;a&amp;gt;&amp;lt;/a&amp;gt;` - tag name
* `href` - tag attribute (argument)
* `"http://github.com"` - tag attribute (value)
* `GitHub` - content as text

---

## HTML Useful references:

* HTML overview: https://www.w3schools.com/html/html_intro.asp
* List of tags: https://developer.mozilla.org/en-US/docs/Web/HTML/Element 

---

class: inverse, middle

# CSS: Cascading Style Sheet

---

## CSS code

Often a website has HTML + CSS:
* **HTML defines the content** 
* **CSS defines the format** 

This is an example of CSS code. Notice the `span` HTML tag can be styled using CSS `color`: 

```css
span {
 color: #ffffff;
}

table.data {
 width: auto;
```
--

Most websites use HTML with tags such `class` and `id` to provide “hooks” for their CSS. This way the CSS "knows" where to apply CSS stylistic elements.

Example: https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/class

&amp;lt;!-- https://plsc-31101.github.io/course/collecting-data-from-the-web.html#webscraping 
[CSS diner](http://flukeout.github.io) --&amp;gt;

---

## HTML + CSS code: example 

.pull-left[

```html
&amp;lt;body&amp;gt;
 &amp;lt;table id="content"&amp;gt;
 &amp;lt;tr class='name'&amp;gt;
 &amp;lt;td class='firstname'&amp;gt;
 Kurtis
 &amp;lt;/td&amp;gt;
 &amp;lt;td class='lastname'&amp;gt;
 McCoy
 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr class='name'&amp;gt;
 &amp;lt;td class='firstname'&amp;gt;
 Leah
 &amp;lt;/td&amp;gt;
 &amp;lt;td class='lastname'&amp;gt;
 Guerrero
 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/table&amp;gt;
&amp;lt;/body&amp;gt;
```

]

.pull-right[

Find the HTML/CSS code to extract:
1. The entire table
1. The general element(s) containing first names
1. Just the specific element "Kurtis"

]


---

class: inverse, middle

# `rvest`

---
## Packages to read html: rvest

* [`rvest`](https://rvest.tidyverse.org/): allows you to scrape (harvest...get it...) data from the web
* works great with tidyverse
* can 'flatten' the hierarchical html/css elements into something we can more easily work with:
 * by HTML tags or attributes
 * by CSS selectors


---
## Using `rvest` to read HTML: functions to know

`read_html` - read HTML data from a url or character string.

`html_nodes` - select specified nodes from the HTML document using CSS selectors.

`html_table` - parse an HTML table into a data frame.

`html_text` - extract tag pairs' content.

`html_name` - extract tags' names.

`html_attrs` - extract all of each tag's attributes.

`html_attr` - extract tags' attribute value by name.



---

class: inverse, middle

# Exercise: Practice all of this in R using `rvest`

### `rvest`: https://rvest.tidyverse.org/
### Scraping presidential statements

---
# Exercise: Practice all of this in R using `rvest`

**Let’s start with step one:**

* We use the `read_html` function from the `rvest` package to call the URL we want data from, grab the HTML response, and store it as an object.
* We are going to scrape data from this URL: `https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration`

---

## Get the page with `read_html`


```r
library(tidyverse)
library(rvest)

url &amp;lt;- "https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration"

dwight &amp;lt;- read_html(x = url)

dwight
```
--

This is not very informative. We can do better! How? `rvest` lets us find and grab the specific HTML/CSS elements that we want from a webpage:
 * by HTML tags or attributes
 * by CSS selectors

---

## Find specific elements with `html_elements`

For example, if we want to find **all `a` elements** in the HTML of our webpage (which we saved in the object `dwight`), we run the following code:

.panelset[
.panel[.panel-name[R Code]

```r
html_elements(x = dwight, css = "a") 
```
]
.panel[.panel-name[R output]

```r
out
```
]
]

--

Observe the output: 
* Many elements on the same page have the same HTML tag. So, if we search for all `a` tags, we will likely get a lot of stuff, much of which we do not want.
* We can be more precise! For example, we might want to find **only the element that contains the document's speaker: "Dwight D. Eisenhower"**. How?
 * find it on the webpage
 * modify the above code accordingly

---

## Find specific elements with `html_elements`

#### To find a specific element, we need to inspect the HTML of the website. We can do so in two ways:

1. **Directly**: by right clicking on the page and select "Inspect" (notice here we need the content of the specific `a` tag, which is nested under `&amp;lt;h3 class="diet-title"&amp;gt;`).

--

2. Using the **SelectorGadget**: 
* See [here](https://selectorgadget.com/) and [here](https://rvest.tidyverse.org/articles/articles/selectorgadget.html)
* Drag the SelectorGadget link into your browser's bookmark bar
* Navigate to a webpage and open the SelectorGadget bookmark
* Click on the item to scrape, it will turn green
* Click on yellow items you do not want to scrape (scroll up and down to check)
* Copy the selector to use with `html_elements()`

I generally rely on method 1 or start with the SelectorGadget and confirm with method 1.

---

## Find specific elements with `html_elements`

Finally, we are ready to find **only the element that contains the document's speaker: "Dwight D. Eisenhower".** We modify the previous code accordingly:


```r
html_elements(x = dwight, css = ".diet-title a")
```

--

Once we have identified the element(s) of interest, usually we want to **access further information included in those elements**. Oftentimes this means two things: text and attributes, and `rvest` has two handy functions: 
* `html_text2()` for text
* `html_attr()` for attributes

---

### Get text of elements with `html_text2()`


```r
speaker_name &amp;lt;- html_elements(dwight, ".diet-title a") %&amp;gt;% 
 html_text2() 

speaker_name
```
--

### Get attributes of elements with `html_attr()`


```r
speaker_link &amp;lt;- html_elements(dwight, ".diet-title a") %&amp;gt;% 
 html_attr("href") # note a is the tag, href is its attribute

speaker_link
```

#### We can keep using `html_text2()` and `html_attr()` to select other things of interest such as: this statement's date, its title, or its text body.

---

### Date of statement

As a string (character):

```r
date &amp;lt;- html_elements(x = dwight, css = ".date-display-single") %&amp;gt;%
 html_text2()

date
```

As a date (double of class "Date"):

```r
library(lubridate)

date &amp;lt;- html_elements(x = dwight, css = ".date-display-single") %&amp;gt;%
 html_text2() %&amp;gt;%
 mdy() # format the element text using lubridate

date
class(date)
```

---

### Title


```r
title &amp;lt;- html_elements(x = dwight, css = "h1") %&amp;gt;%
 html_text2()
title
```

--

### Text


```r
text &amp;lt;- html_elements(x = dwight, css = "div.field-docs-content") %&amp;gt;%
 html_text2()

# display the first 1,000 characters
text %&amp;gt;% str_sub(1, 1000) 
```
 
**Now we know how to extract, the speaker, date, title, and full text from this document!**

---

## Make a function

Think: **Why are we doing through all this effort to scrape just one page?**

Make a function called `scrape_docs` that:

- Take as argument an URL of an single webpage
- Get the HTML of that page 
- Scrapes it
- Returns a data frame containing the document's
 - Date
 - Speaker
 - Title
 - Full text

---

.small[

```r
scrape_doc &amp;lt;- function(url) {
 
 # get HTML page
 url_contents &amp;lt;- read_html(x = url)
 
 # extract elements we want
 date &amp;lt;- html_elements(x = url_contents, css = ".date-display-single") %&amp;gt;%
 html_text2() %&amp;gt;% mdy()
 
 speaker &amp;lt;- html_elements(x = url_contents, css = ".diet-title a") %&amp;gt;%
 html_text2()
 
 title &amp;lt;- html_elements(x = url_contents, css = "h1") %&amp;gt;%
 html_text2()
 
 text &amp;lt;- html_elements(x = url_contents, css = "div.field-docs-content") %&amp;gt;%
 html_text2()
 
 # store in a data frame and return it
 url_data &amp;lt;- tibble(
 date = date,
 speaker = speaker,
 title = title,
 text = text
 )
 return(url_data)
}
```
]

---

### Call the function to scrape documents from the UCSB website:


```r
url_1 &amp;lt;- "https://www.presidency.ucsb.edu/documents/letter-t-keith-glennan-administrator-national-aeronautics-and-space-administration"
scrape_doc(url_1)
```


```r
url_2 &amp;lt;- "https://www.presidency.ucsb.edu/documents/letter-the-president-the-senate-and-the-speaker-the-house-representatives-proposing"
scrape_doc(url_2)
```

**Challenge**: How could we further automate our scraper so we do not have to pass 4000+ URLs (that's the amount of URLs in `https://www.presidency.ucsb.edu/documents/app-categories/presidential/letters`) each time?
* collect all URLs on that page, and store them in a list or character vector
* notice each page has about 10 URLs, so we need to tell the scraper to turn page
* apply our `scrape_doc` function to the list of URLs, one at a time 

*recall your practice with homework 05 to loop over filenames!*

---

class: inverse, middle

# Other examples (see today's class materials)

---

### Both examples are included in today's class materials:

#### Example 01: Sperling's Best Places 

&amp;gt; **Task 1:** look up the cost of living for your hometown on Sperling's Best Places website: http://www.bestplaces.net/ and extract it with `html_elements()` and `html_text2()`

&amp;gt; **Task 2:** get the first table with `html_table()` and put it to a data frame

&amp;gt; **Task 3:** extract the climate statistics table of your hometown 

#### Example 02: Movie information from IMDb 

&amp;gt; Note: this is different than OMDb, which we used as example to scrape with an API

---

class: inverse, middle

# Rectangling or Simplifying lists

---

### Rectangling

Rectangling or simplifying lists: means taking a deeply nested list (often sourced from wild caught JSON or XML) and taming it into a tidy data set of rows and columns.

If you need to simplify nested lists for your scraping project **make sure to check today's class materials for a tutorial and examples of rectangling!**

---

class: inverse, middle

# Scraping challanges, tips, and ethics 


---

## Scraping: General tips

* Confirm that there is no R package and no API
* Make sure your code scrapes only what you want (and not additional information)
* Save and store the content of what you scrape, so to avoid scraping it again

---

## Scraping: Challanges &amp;amp; Solutions

* **Variety:** every website is different, so pretty much every website requires a new project

* **Bad formatting**: websites should be built using "logical formatting" following a properly nested HTML structure. In practice, that's often not the case. If you are having trouble parsing, try selecting a smaller subset of the thing you are seeking

* **Change:** the same website might change over time, so you might find that your code of a few months ago does not work anymore. The good news is that, usually, it takes only a few changes to run it again

* **Limits:** some websites set a max amount of data you can scrape at once, for example 50 pages or 2500 articles max. The solution is to break your requests into "chunks"

* **Messy:** the scraped data are usually a bit messy, and they need to be cleaned

* **Dynamic Scraping:** this not really a challenge but something to keep in mind: many websites incorporate Javascript dynamic parts which requires advanced scraping skills

---

## Scraping: Ethics

* **Private data (not OK) VS. Public data (OK):** If there is a password, it is private data. For example, it is not OK to scrape data from an online community where only logged-in users can access posts (unless you use the API provided by the website and follow its rules). **In general: if the website has an API, use it.**

* **Check the `robots.txt`** before you scrape by adding `/robots.txt` at the end of your URL. For example, for the NYT Robot File, type: `https://www.nytimes.com/robots.txt`. The star after "User-agent" means "the following is valid for all robots"; things you cannot scrape are under "Disallow". More info [here](https://www.robotstxt.org/robotstxt.html)

* **Read the website’s Terms of Service (ToS):** legal rules you agree to observe in order to use a service. Violating ToS exposes you to the risk of violating CFAA or "Computer Fraud &amp;amp; Abuse Act", which is a federal crime.

* **If you are scraping lots of data:** use `rvest` together with `polite`. The polite package ensures that you’re respecting the `robots.txt` and not hammering the site with too many requests.

* For more info on ethical issues, check the **hiQ Labs v. LinkedIn** lawsuit case.

---

## Recap

* Use an API when you can
* Be `polite`
* Read `robots.txt`
* Use publicly available data

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/intro/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Introduction to Computing for the Social Sciences&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Introduction to Computing for the Social Sciences
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Intro to the course

---

## Instructor

- Jean Clipperton



## TAs

- Bhavya Pandey
- Loizos Bitsikokos


## You
---



## Course Objectives

The goal of this course is to acquire and practice **basic computational skills**. We focus on: learning R and learning practices for reproducible research. 

* Programming as a means to an end: analyzing social science data

* You will learn fundamental computational skills and techniques, and gain the confidence necessary to learn new techniques as you encounter them in your own research

More info on the [Introduction to the course notes](https://macs30500.netlify.app/notes/intro-to-course/) in our website


---

## Major Topics

Major topics:

* Basic R, Git/GitHub, R Markdown
* Data Visualization and Data Transformation 
* Exploratory Data Analysis
* Data Wrangling
* R Programming: Control Structures, Functions, Data Structures
* Debugging and defensive Programming
* Reproducible research
* Scraping
* Text-Analysis


---

## How we will do this

We will start small and progressively build more complex code



```r
print("Hello world!")
```

```
## [1] "Hello world!"
```

---

class: inverse, middle

# Who is this class for?

---

## Who is this class for?


### Jeri

.pull-left[

&amp;lt;img src="../../img/stock-photos/000022.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

* Starting points
 * Ph.D. student in Sociology
 * Has experience analyzing data in Stata
 * Feels comfortable with regression and other stats methods 
 * Tried to learn Git on her own once, quickly became frustrated and gave up
* Needs
 * Wants to transition from Stata to R 
 * Will be analyzing a large-scale dataset for her dissertation
 * Seeks a reproducible workflow to manage her data projects

]

---

## Who is this class for?


### Ryan

.pull-left[

&amp;lt;img src="../../img/stock-photos/000284.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

* Starting points
 * Entering the [MAPSS program](https://mapss.uchicago.edu/)
 * Undergraduate degree in journalism
 * Hasn't taken a statistics class in years
 * Took an online course of introduction to R, but hasn't used it in his day-to-day work
* Needs
 * Writing a master's thesis in a single year
 * Expects to analyze a collection of published news articles 
 * Wants to understand code samples found online and adapt them to his own work

]

---

## Who is this class for?


### Fernando

.pull-left[

&amp;lt;img src="../../img/stock-photos/000232.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

* Starting points
 * Third-year undergraduate student
 * Majoring in political science
 * Has taken general education math/stats courses
 * Does not have programming experience, but isn't afraid to tackle a new challenge
* Needs
 * Wants to work as a research assistant on a project exploring the onset of civil conflict, which is run exclusively in R
 * Will start contributing to a new research paper next quarter
 * Wants to produce high-quality visualizations

]

---

## Who is this class for?


### Fang

.pull-left[

&amp;lt;img src="../../img/stock-photos/000251.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

]

.pull-right[

* Starting points
 * First year grad-student
 * Background in psychology, plans to apply for doctoral programs in marketing
 * Has experience using Excel, SPSS, and Stata
* Needs
 * Is going to analyze data collected by her lab members in the next six months
 * Wants to produce analysis notebooks that are easily shareable with her colleagues
 * Expects to take courses in machine learning and statistics which require a background in R

]

---

class: inverse, middle

# Succeeding in the class

---

## General Expectations/Suggestions


* Attend classes

* Bring a laptop

* Complete the readings before coming to class

* Please no abuse of emails, texts, social media, etc. during lectures 

* Collaborate and ask for help

* Start early to work on the homework assignments 


---

## Asking for help


### 15-minute rule

When stuck, you HAVE to try on your own for 15 min. After 15 min, you HAVE to ask for help


### Resources

* [Google](https://www.google.com)

* [StackOverflow](http://stackoverflow.com/)

* Me and TAs

* Fellow students (e.g. study groups)

* [Class discussion page on Ed Discussion](https://edstem.org/us/courses/40496/discussion/)
 * [How to ask for help](https://macs30500.netlify.app/faq/asking-questions/)

---

class: middle

&amp;lt;img src="../../../../../../../../../../../img/plagiarism.jpg" width="70%" style="display: block; margin: auto;" /&amp;gt;

---

## Plagiarism

### Collaboration is good - *to a point*

* Collaboration is good: researchers usually collaborate with one another on projects. Developers work in teams to write programs. Learning from others and/or the internet is fine (e.g., to debug something, to get unstuck on a specific part of your code, etc.)


* BUT you are expected to complete your own work, understand what the code is doing and be prepared to explain it in details to someone else.


* In your homework, at the top: please mention the resources you had access to complete the homework (e.g., I met with the Prof. Clipperton for the part of code ... I asked advice to my colleague name for... )


---

## Homework and Evaluation


* **Regular programming assignments**: eight in total.

* **Late Work Policy**: you can submit up to two assignments up to 24 hours late without penalty; no questions asked. After 24 hours, we do not accept late work. 

* **Extraordinary circumstances** (illness, family emergency, etc.): I may grant additional extensions on a case-by-case basis. Whenever possible, inform me before the deadline. Please, note that having a heavy workload in a given week does not qualify as an extraordinary circumstance. The purpose of the two extensions is precisely to give you some flexibility in weeks when you are busier than usual.

* **[Rubric](https://macs30500.netlify.app/faq/homework-evaluations/)** 

---

## Software Set up

Go to our course website under **[Setup](https://macs30500.netlify.app/setup/)**

Two options:

* Option 1 use R Studio Workbench -- recommended

* Option 2 install the software locally

---

class: inverse, middle

# Group chat

---

# In groups of 3-4 people

* Introduce yourself

* Share your expectations/goals for this course

* Share strategies
 * reflect upon the best and worst classes you have taken in this field or related fields; describe what made the course successful (or not) for you
 * strategies you plan to adopt to be successful in the course 
 * anything else

* Explore the website

* Questions


---

class: inverse, middle

# Programming and reproducible workflow

---

## Program

&amp;gt; A series of instructions that specifies how to perform a computation

* Input
* Output
* Math
* Logic (e.g. conditional execution)
* Repetition

---

## Windows 3.1 GUI 

class: middle

&amp;lt;img src="../../../../../../../../../../../img/windows_3.1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Mac OSX GUI

class: middle

&amp;lt;img src="../../../../../../../../../../../img/mac_os_x.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: middle

&amp;lt;img src="../../../../../../../../../../../img/stata14.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

Stata is for the most part a GUI software. 

A GUI software runs using all the basic programming elements, but the end user is not aware of any of this. Instructions in GUI software are implicit to the user, whereas programming requires the user to make instructions explicit.

**What are the advantages of learning to program VS. using a GUI software, such as Stata?**

---

## Two different approaches

**TASK**: Write a report analyzing the relationship between ice cream consumption and crime rates in New York City.

**APPROACH**: Read how Jane and Sally approach this task [in our website](https://macs30500.netlify.app/notes/intro-to-course/#benefits-to-programming-vs-gui-software) (5 min readings start from "Benefits to programming vs. GUI software")

--

.pull-left[

### Jane: a GUI workflow

1. Searches for data files online
1. Cleans the files in Excel
1. Analyzes the data in Stata
1. Writes her report in Google Docs

]

--

.pull-right[

### Sally: a programmatic workflow

1. Creates a folder specifically for this project
 * `data`
 * `graphics`
 * `output`
1. Searches for data files online
1. Cleans the files in R
1. Analyzes the files in R
1. Writes her report in R Markdown

]

---

class: middle

&amp;lt;img src="https://i.imgflip.com/1szkun.jpg" width="70%" height="70%" style="display: block; margin: auto;" /&amp;gt;

---

## Automation


* Jane forgets how she transformed and analyzed the data
 * Extension of analysis will fall flat
 
 
* Sally uses *automation*
 * Re-run programs
 * No mistakes
 * Much easier to implement *in the long run*

---

## Reproducibility

* Are my results valid? Can it be *replicated*?
* The idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them
* Also allows the researcher to precisely replicate his/her analysis

---

## Version control

* Revisions in research
* Tracking revisions
* Multiple copies
 * `analysis-1.r`
 * `analysis-2.r`
 * `analysis-3.r`
* Cloud storage (e.g. Dropbox, Google Drive, Box) vs. Version Control Software
 * Repository on your computer for which the VCS tracks all changes (who, when, what, etc.). Example: Git
 * Usually implemented in conjunction with remote serves to store backups of your repository. Example: GitHub

---

## Documentation

* *Comments* are the what
* *Code* is the how
* Computer code should also be *self-documenting*
* Future-proofing

---

## Badly documented code


```r
library(tidyverse)
library(rtweet)
tml1 &amp;lt;- get_timeline("MeCookieMonster", 3000)
tml2 &amp;lt;- get_timeline("Grover", 3000)
tml3 &amp;lt;- get_timeline("elmo", 3000)
tml4 &amp;lt;- get_timeline("CountVonCount", 3000)
ts_plot(group_by(bind_rows(select(tml1, created_at), select(tml2, created_at), select(tml3, created_at), select(tml4, created_at), .id = "screen_name"), screen_name), by = "months")
```


* What does this program do?
* What do the variable names mean? 
* What does 3000 refer to?
* What are we doing with the `ts_plot()` function?


---

## Good code



.tiny[

```r
# get_to_sesame_street.R
# Program to retrieve recent tweets from Sesame Street characters

# load packages for data management and Twitter API
library(tidyverse)
library(rtweet)

# retrieve most recent 3000 tweets of best Sesame Street residents
cookie &amp;lt;- get_timeline(
 user = "MeCookieMonster",
 n = 3000
)

grover &amp;lt;- get_timeline(
 user = "Grover",
 n = 3000
)

elmo &amp;lt;- get_timeline(
 user = "elmo",
 n = 3000
)

count_von_count &amp;lt;- get_timeline(
 user = "CountVonCount",
 n = 3000
)

# combine, group by character, and plot weekly tweet frequency
bind_rows(
 `Cookie Monster` = cookie %&amp;gt;% select(created_at),
 Grover = grover %&amp;gt;% select(created_at),
 Elmo = elmo %&amp;gt;% select(created_at),
 `Count von Count` = count_von_count %&amp;gt;% select(created_at),
 .id = "screen_name"
) %&amp;gt;%
 group_by(screen_name) %&amp;gt;%
 ts_plot(by = "months")
```
]


---

# To complete by next class 

See today's topic, under [Schedule of Topics](https://macs30500.netlify.app/syllabus/introduction-to-computing-for-the-social-sciences/)

---

# Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin's and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/machine-learning/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>An introduction to machine learning&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="INFO 5940 Cornell University" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# An introduction to machine learning
]
.author[
### INFO 5940 &lt;br /> Cornell University
]

---




class: inverse, middle

# What is machine learning?

---

class: middle

&amp;lt;img src="../../../../../../../../img/amazon-recommendations.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: middle

&amp;lt;img src="https://miro.medium.com/max/1400/1*j5aWfH9t1_EZPJC92CJ7oQ.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

.footnote[https://medium.com/tmobile-tech/small-data-big-value-f783ceca4fdb]

---

class: middle

&amp;lt;img src="https://techcrunch.com/wp-content/uploads/2017/12/facebook-facial-recognition-photo-review.png?w=730&amp;amp;crop=1" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: middle, inverse

# What is machine learning?

---

class: middle, center

&amp;lt;img src="https://imgs.xkcd.com/comics/machine_learning.png" width="40%" style="display: block; margin: auto;" /&amp;gt;

---

class: middle

&amp;lt;img src="images/intro.002.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: middle

&amp;lt;img src="images/intro.003.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Types of machine learning

- Supervised
- Unsupervised

---

&amp;lt;img src="images/all-of-ml.jpg" width="80%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Credit: &amp;lt;https://vas3k.com/blog/machine_learning/&amp;gt;]

---

## Examples of supervised learning

- Ad click prediction
- Supreme Court decision making
- Police misconduct prediction

---

## Two modes

--

.pull-left[

### Classification

Is your hospital in a state of crisis care?

]

--

.pull-left[

### Regression

What percentage of hospital beds are occupied?

]

---

## Two cultures

.pull-left[

### Statistics

- model first
- inference emphasis

]

.pull-right[


### Machine Learning

- data first
- prediction emphasis

]

---
name: train-love
background-image: url(images/train.jpg)
background-size: contain
background-color: #f6f6f6

---
template: train-love
class: center, top

# Statistics

---

template: train-love
class: bottom


&amp;gt; *"Statisticians, like artists, have the bad habit of falling in love with their models."*
&amp;gt;
&amp;gt; &amp;amp;mdash; George Box

---

## Predictive modeling


```r
library(tidymodels)
```

```
## ── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──
```

```
## ✔ broom 1.0.0 ✔ recipes 1.0.1
## ✔ dials 1.0.0 ✔ rsample 1.1.0
## ✔ dplyr 1.0.9 ✔ tibble 3.1.8
## ✔ ggplot2 3.3.6 ✔ tidyr 1.2.0
## ✔ infer 1.0.2 ✔ tune 1.0.0
## ✔ modeldata 1.0.0 ✔ workflows 1.0.0
## ✔ parsnip 1.0.0 ✔ workflowsets 1.0.0
## ✔ purrr 0.3.4 ✔ yardstick 1.0.0
```

```
## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
## ✖ purrr::discard() masks scales::discard()
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag() masks stats::lag()
## ✖ recipes::step() masks stats::step()
## • Search for functions across packages at https://www.tidymodels.org/find/
```





---

## Bechdel Test

&amp;lt;img src="https://fivethirtyeight.com/wp-content/uploads/2014/04/hickey-bechdel-11.png" width="60%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source:[FiveThirtyEight](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/)]

---

## Bechdel Test

1. It has to have at least two [named] women in it
1. Who talk to each other
1. About something besides a man

--


```r
library(rcis)
data("bechdel")
glimpse(bechdel)
## Rows: 1,394
## Columns: 10
## $ year &amp;lt;dbl&amp;gt; 2013, 2013, 2013, 2013, 2013, 2013, …
## $ title &amp;lt;chr&amp;gt; "12 Years a Slave", "2 Guns", "42", …
## $ test &amp;lt;fct&amp;gt; Fail, Fail, Fail, Fail, Fail, Pass, …
## $ budget_2013 &amp;lt;dbl&amp;gt; 2.00, 6.10, 4.00, 22.50, 9.20, 1.20,…
## $ domgross_2013 &amp;lt;dbl&amp;gt; 5.310703, 7.561246, 9.502021, 3.8362…
## $ intgross_2013 &amp;lt;dbl&amp;gt; 15.860703, 13.249301, 9.502021, 14.5…
## $ rated &amp;lt;chr&amp;gt; "R", "R", "PG-13", "PG-13", "R", "R"…
## $ metascore &amp;lt;dbl&amp;gt; 97, 55, 62, 29, 28, 55, 48, 33, 90, …
## $ imdb_rating &amp;lt;dbl&amp;gt; 8.3, 6.8, 7.6, 6.6, 5.4, 7.8, 5.7, 5…
## $ genre &amp;lt;chr&amp;gt; "Biography", "Action", "Biography", …
```

---

## Bechdel test data

- N = 1394
- 1 categorical outcome: `test`
- 9 predictors

---

class: middle

&amp;lt;img src="index_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;


---

class: inverse, middle

# What is the goal of machine learning?

--

## Build .white[models] that

--


## generate .white[accurate predictions]

--


## for .white[future, yet-to-be-seen data].

--

.footnote[Max Kuhn &amp;amp; Kjell Johnston, http://www.feat.engineering/]

---

## Machine learning

We'll use this goal to drive learning of 3 core `tidymodels` packages:

- `parsnip`
- `yardstick`
- `rsample`

---

class: inverse, middle

## 🔨 Build models with `parsnip`

---

class: middle, center, frame

## parsnip

&amp;lt;iframe src="https://parsnip.tidymodels.org" width="100%" height="400px" data-external="1"&amp;gt;&amp;lt;/iframe&amp;gt;

---

## `glm()`



```r
glm(test ~ metascore, family = binomial, data = bechdel)
## 
## Call: glm(formula = test ~ metascore, family = binomial, data = bechdel)
## 
## Coefficients:
## (Intercept) metascore 
## 0.052274 -0.004563 
## 
## Degrees of Freedom: 1393 Total (i.e. Null); 1392 Residual
## Null Deviance:	 1916 
## Residual Deviance: 1914 	AIC: 1918
```

---

class: center

&amp;lt;img src="images/predicting/predicting.001.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## To specify a model with `parsnip`

1. Pick a model
1. Set the engine
1. Set the mode (if needed)

---

## To specify a model with `parsnip`


```r
logistic_reg() %&amp;gt;%
 set_engine("glm") %&amp;gt;%
 set_mode("classification")
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm
```

---

## To specify a model with `parsnip`


```r
decision_tree() %&amp;gt;%
 set_engine("C5.0") %&amp;gt;%
 set_mode("classification")
## Decision Tree Model Specification (classification)
## 
## Computational engine: C5.0
```

---

## To specify a model with `parsnip`


```r
nearest_neighbor() %&amp;gt;% 
 set_engine("kknn") %&amp;gt;% 
 set_mode("classification") 
## K-Nearest Neighbor Model Specification (classification)
## 
## Computational engine: kknn
```

---

## 1\. Pick a model

All available models are listed at

&amp;lt;https://www.tidymodels.org/find/parsnip/&amp;gt;

&amp;lt;iframe src="https://www.tidymodels.org/find/parsnip/" width="100%" height="400px" data-external="1"&amp;gt;&amp;lt;/iframe&amp;gt;

---

## `logistic_reg()`

Specifies a model that uses logistic regression


```r
logistic_reg(penalty = NULL, mixture = NULL)
```

---

## `logistic_reg()`

Specifies a model that uses logistic regression


```r
logistic_reg(
 mode = "classification", # "default" mode, if exists
 penalty = NULL, # model hyper-parameter
 mixture = NULL # model hyper-parameter
 )
```

---

## `set_engine()`

Adds an engine to power or implement the model.


```r
logistic_reg() %&amp;gt;% set_engine(engine = "glm")
```

---

## `set_mode()`

Sets the class of problem the model will solve, which influences which output is collected. Not necessary if mode is set in Step 1.


```r
logistic_reg() %&amp;gt;% set_mode(mode = "classification")
```

---
class: your-turn

## Your turn 1

Run the chunk in your .Rmd and look at the output. Then, copy/paste the code and edit to create:

+ a decision tree model for classification 

+ that uses the `C5.0` engine. 

Save it as `tree_mod` and look at the object. What is different about the output?

*Hint: you'll need https://www.tidymodels.org/find/parsnip/*

&lt;div class="countdown" id="timer_62f3ecba" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">03&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---




```r
lr_mod 
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm

tree_mod &amp;lt;- decision_tree() %&amp;gt;% 
 set_engine(engine = "C5.0") %&amp;gt;% 
 set_mode("classification")
tree_mod 
## Decision Tree Model Specification (classification)
## 
## Computational engine: C5.0
```

---
class: inverse, middle

## Now we've built a model.

--

## But, how do we .white[use] a model?

--

## First - what does it mean to use a model?

---
class: inverse, middle, center

![](https://media.giphy.com/media/fhAwk4DnqNgw8/giphy.gif)

Statistical models learn from the data. 

Many learn model parameters, which *can* be useful as values for inference and interpretation.

---

## A fitted model

.pull-left[


```r
lr_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel) %&amp;gt;% 
 broom::tidy()
## # A tibble: 3 × 5
## term estimate std.error statistic p.value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 2.70 0.436 6.20 5.64e-10
## 2 metascore 0.0202 0.00481 4.20 2.66e- 5
## 3 imdb_rating -0.606 0.0889 -6.82 8.87e-12
```
]

.pull-right[

&amp;lt;img src="index_files/figure-html/unnamed-chunk-27-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## "All models are wrong, but some are useful"



&amp;lt;img src="index_files/figure-html/unnamed-chunk-29-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## "All models are wrong, but some are useful"



&amp;lt;img src="index_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Predict new data


```r
bechdel_new &amp;lt;- tibble(metascore = c(40, 50, 60), 
 imdb_rating = c(6, 6, 6),
 test = c("Fail", "Fail", "Pass")) %&amp;gt;% 
 mutate(test = factor(test, levels = c("Fail", "Pass")))
bechdel_new
## # A tibble: 3 × 3
## metascore imdb_rating test 
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;
## 1 40 6 Fail 
## 2 50 6 Fail 
## 3 60 6 Pass
```

---

## Predict old data


```r
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel) %&amp;gt;% 
 predict(new_data = bechdel) %&amp;gt;% 
 mutate(true_bechdel = bechdel$test) %&amp;gt;% 
 accuracy(truth = true_bechdel, 
 estimate = .pred_class)
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.580
```

---

## Predict new data

.pull-left[
### out with the old...

```r
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel) %&amp;gt;% 
 predict(new_data = bechdel) %&amp;gt;% 
 mutate(true_bechdel = bechdel$test) %&amp;gt;% 
 accuracy(truth = true_bechdel, 
 estimate = .pred_class)
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.580
```

]

.pull-right[

### in with the 🆕


```r
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel) %&amp;gt;% 
* predict(new_data = bechdel_new) %&amp;gt;%
* mutate(true_bechdel = bechdel_new$test) %&amp;gt;%
 accuracy(truth = true_bechdel, 
 estimate = .pred_class)
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.333
```

]

---

## `fit()`

Train a model by fitting a model. Returns a parsnip model fit.


```r
fit(tree_mod, test ~ metascore + imdb_rating, data = bechdel)
```

---

## `fit()`

Train a model by fitting a model. Returns a parsnip model fit.


```r
tree_mod %&amp;gt;% # parsnip model
 fit(test ~ metascore + imdb_rating, # a formula
 data = bechdel # dataframe
 )
```

---

## `fit()`

Train a model by fitting a model. Returns a parsnip model fit.


```r
tree_fit &amp;lt;- tree_mod %&amp;gt;% # parsnip model
 fit(test ~ metascore + imdb_rating, # a formula
 data = bechdel # dataframe
 )
```

---

class: center

&amp;lt;img src="images/predicting/predicting.001.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.003.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## `predict()`

Use a fitted model to predict new `y` values from data. Returns a tibble.


```r
predict(tree_fit, new_data = bechdel_new) 
```

---


```r
tree_fit %&amp;gt;% 
 predict(new_data = bechdel_new)
## # A tibble: 3 × 1
## .pred_class
## &amp;lt;fct&amp;gt; 
## 1 Pass 
## 2 Pass 
## 3 Pass
```

---

## Axiom

The best way to measure a model's performance at predicting new data is to .display[predict new data].

---

## Data splitting

&amp;lt;img src="index_files/figure-html/all-split-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: inverse, middle

# ♻️ Resample models with `rsample`

---

## `rsample`

&amp;lt;iframe src="https://tidymodels.github.io/rsample/" width="100%" height="400px" data-external="1"&amp;gt;&amp;lt;/iframe&amp;gt;

---

## `initial_split()*`

"Splits" data randomly into a single testing and a single training set.


```r
initial_split(data, prop = 3/4)
```

.footnote[`*` from `rsample`]

---


```r
bechdel_split &amp;lt;- initial_split(data = bechdel, strata = test, prop = 3/4)
bechdel_split
## &amp;lt;Training/Testing/Total&amp;gt;
## &amp;lt;1045/349/1394&amp;gt;
```

---

## `training()` and `testing()*`

Extract training and testing sets from an `rsplit`


```r
training(bechdel_split)
testing(bechdel_split)
```

.footnote[`*` from `rsample`]

---


```r
bechdel_train &amp;lt;- training(bechdel_split) 
bechdel_train
## # A tibble: 1,045 × 10
## year title test budge…¹ domgr…² intgr…³ rated metas…⁴
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 2013 12 Yea… Fail 2 5.31 15.9 R 97
## 2 2013 2 Guns Fail 6.1 7.56 13.2 R 55
## 3 2013 42 Fail 4 9.50 9.50 PG-13 62
## 4 2013 47 Ron… Fail 22.5 3.84 14.6 PG-13 29
## 5 2013 A Good… Fail 9.2 6.73 30.4 R 28
## 6 2013 After … Fail 13 6.05 24.4 PG-13 33
## 7 2013 Cloudy… Fail 7.8 12.0 27.2 PG 59
## 8 2013 Don Jon Fail 0.55 2.45 2.64 R 66
## 9 2013 Escape… Fail 7 2.52 10.4 R 49
## 10 2013 Gangst… Fail 6 4.60 10.4 R 40
## # … with 1,035 more rows, 2 more variables:
## # imdb_rating &amp;lt;dbl&amp;gt;, genre &amp;lt;chr&amp;gt;, and abbreviated
## # variable names ¹​budget_2013, ²​domgross_2013,
## # ³​intgross_2013, ⁴​metascore
## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names
```

---

class: center

&amp;lt;img src="images/predicting/predicting.001.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.003.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.004.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.006.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.007.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.008.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.009.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Your turn 2

Fill in the blanks. 

Use `initial_split()`, `training()`, and `testing()` to:

1. Split **bechdel** into training and test sets. Save the rsplit!

2. Extract the training data and fit your classification tree model.

3. Predict the testing data, and save the true `test` values.

4. Measure the accuracy of your model with your test set. 

Keep `set.seed(100)` at the start of your code.

&lt;div class="countdown" id="timer_62f3ebcf" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">04&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---


```r
set.seed(100) # Important!

bechdel_split &amp;lt;- initial_split(bechdel, strata = test, prop = 3/4)
bechdel_train &amp;lt;- training(bechdel_split)
bechdel_test &amp;lt;- testing(bechdel_split)

tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel_train) %&amp;gt;% 
 predict(new_data = bechdel_test) %&amp;gt;% 
 mutate(true_bechdel = bechdel_test$test) %&amp;gt;% 
 accuracy(truth = true_bechdel, estimate = .pred_class)
```

---

class: inverse, middle

# Goal of Machine Learning

## 🎯 generate accurate predictions

---

## Axiom

Better Model = Better Predictions (Lower error rate)

---

## `accuracy()*`

Calculates the accuracy based on two columns in a dataframe: 

The .display[truth]: `\({y}_i\)` 

The predicted .display[estimate]: `\(\hat{y}_i\)` 


```r
accuracy(data, truth, estimate)
```

.footnote[`*` from `yardstick`]

---


```r
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel_train) %&amp;gt;% 
 predict(new_data = bechdel_test) %&amp;gt;% 
 mutate(true_bechdel = bechdel_test$test) %&amp;gt;% 
* accuracy(truth = true_bechdel, estimate = .pred_class)
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.547
```

---

class: center

&amp;lt;img src="images/predicting/predicting.006.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.007.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.008.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center

&amp;lt;img src="images/predicting/predicting.009.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Your Turn 3

What would happen if you repeated this process? Would you get the same answers?

Note your accuracy from above. Then change your seed number and rerun just the last code chunk above. Do you get the same answer? 

Try it a few times with a few different seeds.

&lt;div class="countdown" id="timer_62f3e974" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">02&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---

.pull-left[


```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.553
```





```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.559
```




```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.567
```

]

--

.pull-right[




```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.539
```




```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.504
```




```
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.550
```

]

---

## Quiz

Why is the new estimate different?



---

## Data Splitting

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-74-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-75-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-76-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-77-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-78-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-79-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-80-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-81-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="index_files/figure-html/unnamed-chunk-82-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-83-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-84-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-85-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-86-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-87-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-88-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

&amp;lt;img src="index_files/figure-html/unnamed-chunk-89-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

--

.right[Mean accuracy]

---

## Resampling

Let's resample 10 times 

then compute the mean of the results...

---







```r
acc %&amp;gt;% tibble::enframe(name = "accuracy")
## # A tibble: 10 × 2
## accuracy value
## &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1 0.550
## 2 2 0.625
## 3 3 0.599
## 4 4 0.587
## 5 5 0.605
## 6 6 0.593
## 7 7 0.542
## 8 8 0.530
## 9 9 0.564
## 10 10 0.599
mean(acc)
## [1] 0.5793696
```

---

## Guess

Which do you think is a better estimate?

The best result or the mean of the results? Why? 

---

## But also...

Fit with .display[training set]

Predict with .display[testing set]

--

Rinse and repeat?

---

## There has to be a better way...


```r
acc &amp;lt;- vector(length = 10, mode = "double")
for (i in 1:10) {
 new_split &amp;lt;- initial_split(bechdel)
 new_train &amp;lt;- training(new_split)
 new_test &amp;lt;- testing(new_split)
 acc[i] &amp;lt;-
 lr_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, data = new_train) %&amp;gt;% 
 predict(new_test) %&amp;gt;% 
 mutate(truth = new_test$test) %&amp;gt;% 
 accuracy(truth, .pred_class) %&amp;gt;% 
 pull(.estimate)
}
```

---
background-image: url(images/diamonds.jpg)
background-size: contain
background-position: left
class: middle, center
background-color: #f5f5f5

.pull-right[
## The .display[testing set] is precious...

## we can only use it once!

]

---
background-image: url(images/diamonds.jpg)
background-size: contain
background-position: left
class: middle, center
background-color: #f5f5f5

.pull-right[

## How can we use the training set to compare, evaluate, and tune models?

]

---

class: middle

&amp;lt;img src="https://www.tidymodels.org/start/resampling/img/resampling.svg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide2.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide3.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide4.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide5.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide6.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide7.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide8.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide9.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide10.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Cross-validation

&amp;lt;img src="images/cross-validation/Slide11.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## V-fold cross-validation


```r
vfold_cv(data, v = 10, ...)
```

---
exclude: true



---

## Guess

How many times does an observation/row appear in the assessment set?

&amp;lt;img src="index_files/figure-html/vfold-tiles-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="index_files/figure-html/unnamed-chunk-105-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Quiz

If we use 10 folds, which percent of our data will end up in the training set and which percent in the testing set for each fold?

--

90% - training

10% - test

---

## Your Turn 4

Run the code below. What does it return?


```r
set.seed(100)
bechdel_folds &amp;lt;- vfold_cv(data = bechdel_train, v = 10, strata = test)
bechdel_folds
```

&lt;div class="countdown" id="timer_62f3e9e7" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">01&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---

```r
set.seed(100)
bechdel_folds &amp;lt;- vfold_cv(data = bechdel_train, v = 10, strata = test)
bechdel_folds
## # 10-fold cross-validation using stratification 
## # A tibble: 10 × 2
## splits id 
## &amp;lt;list&amp;gt; &amp;lt;chr&amp;gt; 
## 1 &amp;lt;split [940/105]&amp;gt; Fold01
## 2 &amp;lt;split [940/105]&amp;gt; Fold02
## 3 &amp;lt;split [940/105]&amp;gt; Fold03
## 4 &amp;lt;split [940/105]&amp;gt; Fold04
## 5 &amp;lt;split [940/105]&amp;gt; Fold05
## 6 &amp;lt;split [940/105]&amp;gt; Fold06
## 7 &amp;lt;split [941/104]&amp;gt; Fold07
## 8 &amp;lt;split [941/104]&amp;gt; Fold08
## 9 &amp;lt;split [941/104]&amp;gt; Fold09
## 10 &amp;lt;split [942/103]&amp;gt; Fold10
```

---

## We need a new way to fit


```r
split1 &amp;lt;- bechdel_folds %&amp;gt;% pluck("splits", 1)
split1_train &amp;lt;- training(split1)
split1_test &amp;lt;- testing(split1)

tree_mod %&amp;gt;% 
 fit(test ~ ., data = split1_train) %&amp;gt;% 
 predict(split1_test) %&amp;gt;% 
 mutate(truth = split1_test$test) %&amp;gt;% 
 accuracy(truth, .pred_class)

# rinse and repeat
split2 &amp;lt;- ...
```

---

## `fit_resamples()`

Trains and tests a resampled model.


```r
tree_mod %&amp;gt;% 
 fit_resamples(
 test ~ metascore + imdb_rating, 
 resamples = bechdel_folds
 )
```

---


```r
tree_mod %&amp;gt;% 
 fit_resamples(
 test ~ metascore + imdb_rating, 
 resamples = bechdel_folds
 )
## # Resampling results
## # 10-fold cross-validation using stratification 
## # A tibble: 10 × 4
## splits id .metrics .notes 
## &amp;lt;list&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt; &amp;lt;list&amp;gt; 
## 1 &amp;lt;split [940/105]&amp;gt; Fold01 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 2 &amp;lt;split [940/105]&amp;gt; Fold02 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 3 &amp;lt;split [940/105]&amp;gt; Fold03 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 4 &amp;lt;split [940/105]&amp;gt; Fold04 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 5 &amp;lt;split [940/105]&amp;gt; Fold05 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 6 &amp;lt;split [940/105]&amp;gt; Fold06 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 7 &amp;lt;split [941/104]&amp;gt; Fold07 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 8 &amp;lt;split [941/104]&amp;gt; Fold08 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 9 &amp;lt;split [941/104]&amp;gt; Fold09 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
## 10 &amp;lt;split [942/103]&amp;gt; Fold10 &amp;lt;tibble [2 × 4]&amp;gt; &amp;lt;tibble&amp;gt;
```

---

## `collect_metrics()`

Unnest the metrics column from a tidymodels `fit_resamples()`


```r
_results %&amp;gt;% collect_metrics(summarize = TRUE)
```

--

.footnote[`TRUE` is actually the default; averages across folds]

---


```r
tree_mod %&amp;gt;% 
 fit_resamples(
 test ~ metascore + imdb_rating, 
 resamples = bechdel_folds
 ) %&amp;gt;% 
 collect_metrics(summarize = FALSE)
## # A tibble: 20 × 5
## id .metric .estimator .estimate .config 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Fold01 accuracy binary 0.610 Preprocessor1_Model1
## 2 Fold01 roc_auc binary 0.587 Preprocessor1_Model1
## 3 Fold02 accuracy binary 0.438 Preprocessor1_Model1
## 4 Fold02 roc_auc binary 0.434 Preprocessor1_Model1
## 5 Fold03 accuracy binary 0.6 Preprocessor1_Model1
## 6 Fold03 roc_auc binary 0.570 Preprocessor1_Model1
## 7 Fold04 accuracy binary 0.562 Preprocessor1_Model1
## 8 Fold04 roc_auc binary 0.547 Preprocessor1_Model1
## 9 Fold05 accuracy binary 0.6 Preprocessor1_Model1
## 10 Fold05 roc_auc binary 0.572 Preprocessor1_Model1
## # … with 10 more rows
## # ℹ Use `print(n = ...)` to see more rows
```

---

## 10-fold CV

- 10 different analysis/assessment sets

- 10 different models (trained on .display[analysis] sets)

- 10 different sets of performance statistics (on .display[assessment] sets)

---

## Your Turn 5

Modify the code below to use `fit_resamples` and `bechdel_folds` to cross-validate the classification tree model. What is the ROC AUC that you collect at the end?


```r
set.seed(100)
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, 
 data = bechdel_train) %&amp;gt;% 
 predict(new_data = bechdel_test) %&amp;gt;% 
 mutate(true_bechdel = bechdel_test$test) %&amp;gt;% 
 accuracy(truth = true_bechdel, estimate = .pred_class)
```

&lt;div class="countdown" id="timer_62f3ebc2" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">03&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---


```r
set.seed(100)
tree_mod %&amp;gt;% 
 fit_resamples(test ~ metascore + imdb_rating, 
 resamples = bechdel_folds) %&amp;gt;% 
 collect_metrics()
## # A tibble: 2 × 6
## .metric .estimator mean n std_err .config 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 accuracy binary 0.560 10 0.0157 Preprocessor1_Mod…
## 2 roc_auc binary 0.547 10 0.0154 Preprocessor1_Mod…
```

---

## How did we do?


```r
tree_mod %&amp;gt;% 
 fit(test ~ metascore + imdb_rating, data = bechdel_train) %&amp;gt;% 
 predict(bechdel_test) %&amp;gt;% 
 mutate(truth = bechdel_test$test) %&amp;gt;% 
 accuracy(truth, .pred_class)
## # A tibble: 1 × 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.550
```


```
## # A tibble: 2 × 6
## .metric .estimator mean n std_err .config 
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 accuracy binary 0.560 10 0.0157 Preprocessor1_Mod…
## 2 roc_auc binary 0.547 10 0.0154 Preprocessor1_Mod…
```

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/pipes-and-functions-in-r/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/pipes-and-functions-in-r/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Functions in R&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Functions in R
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Agenda
* Homeworks: HW 3 due today and HW 4 due Thurs!
* Explanation of functions
* Creating your own function
* Practice
* Functions + for loops = party
* Anonymous functions

---
# Functions

---

### Using existing functions

Functions are all over R! We have been **using functions** from day 1 of this class. For example:

```r
a &amp;lt;- c(1:10)
a
```

```
## [1] 1 2 3 4 5 6 7 8 9 10
```

```r
mean(a)
```

```
## [1] 5.5
```

```r
sqrt(a)
```

```
## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
## [9] 3.000000 3.162278
```

---

### Using existing functions

To use a function, we need to know its arguments and pass them correctly. In the console, type `help()` with the function's name in parenthesis to learn more about a function behavior and its arguments:

```r
help(mean)
help(sqrt)
help(max)
```

--

Some functions come from base R, like those I listed here, other functions have been developed from packages (e.g., all the functions from the tidyverse that we have been using). 

---

### Writing your own function

Other than using already defined functions, we can **create our own function**! 

A function has the following components:

* name
* arguments (input)
* body
* return values (ouput)

Syntax:
```
name &amp;lt;- function(arg1, arg2, ...) { # name of function and arguments (input) it takes
 value &amp;lt;- body_of_function # the body is the code that manipulates arguments
 return(value) # what the function returns (output)
 }
```
&amp;lt;!-- we can assign the func to a named object like any other object and pass one or more argument --&amp;gt;

---

### Writing your own function


For example, instead than using the built-in `mean()` function, we could **write our own mean function** to calculate the mean of a vector of numbers.

Syntax:
```
name &amp;lt;- function(arg1, arg2, ...) { # name of function and arguments (inputs) it takes
 value &amp;lt;- body_of_function # the body is the code that manipulates arguments
 return(value) # what the function returns (results)
 }
```

Our mean function:

```r
my_mean &amp;lt;- function(vector) {
 tot_values &amp;lt;- length(vector)
 m &amp;lt;- (sum(vector/tot_values))
 return(m)
}
```


---

### Writing your own function

Like any other piece of code, you can write a function by specifying all the intermediate steps in the body, or you can "skip" passages. 

Below are two different ways to write the same function: the first is longer because defines two intermediate variables; the second is more compact.


```r
# long version
my_mean &amp;lt;- function(vector) {
 tot_values &amp;lt;- length(vector)
 m &amp;lt;- (sum(vector/tot_values))
 return(m)
}
```


```r
# short version
my_mean &amp;lt;- function(vector) {
 return(sum(vector/length(vector)))
}
```

---

### Writing your own function

To make a function work, we need to *call* it with some values:

```r
my_mean &amp;lt;- function(vector) {
 return(sum(vector/length(vector)))
}
```


```r
a &amp;lt;- c(1:10)
my_mean(vector = a)
```

```
## [1] 5.5
```

```r
b &amp;lt;- c(1, 3, 6, 9, 20, 30)
my_mean(b)
```

```
## [1] 11.5
```
This function has one argument: `vector`. When we call the function, this argument will take a concrete vector, such as `a`, `b`, etc. Notice, we can, but we do not have to, specify the argument name.

---

### Same code without a function

Without using a function, we have to type the code to calculate the mean every time we need it:

```r
# calculate the mean of vector a
a &amp;lt;- c(1:10)
m &amp;lt;- (sum(a/length(a)))
m
```

```
## [1] 5.5
```


```r
# calculate the mean of vector b
b &amp;lt;- c(1, 3, 6, 9, 20, 30)
m &amp;lt;- (sum(b/length(b)))
m
```

```
## [1] 11.5
```

&amp;lt;!--
Can do with a loop

```r
v &amp;lt;- list(a, b)
output &amp;lt;- vector(mode = "list", length = length(v))

for (i in seq_along(v)) {
 output[[i]] &amp;lt;- (sum(v[[i]]/length(v[[i]])))
 #output[[i]] &amp;lt;- (mean(v[[i]]))
}
output
```

```
## [[1]]
## [1] 5.5
## 
## [[2]]
## [1] 11.5
```
--&amp;gt;

This code is redundant, more prone to errors, and less organized.

---

### So... What is a function? Why using one?

A function is **code that is organized and named so that it can be executed by simply executing the name** (referred to as ‘calling’ a function). 

Functions:
* take some values as input and return output values
* reduce repetitive code and chances for mistakes
* make it easier to reuse code
* organize code (e.g., one function imports the data, another cleans the data, another split text into words, etc.)

---

### Writing your own function: things to notice

Names:

* provide **unique names for your functions** (e.g., `my_mean` vs `mean`); if you accidentally pick a function name that matches the name of existing R function, your function will override the existing function and only your function will be active in your current session. Type `help()` with your function name in parenthesis to see if the function is already in use 

* unless you have a reason to do so, **do not create a new function if one already exists** (e.g., you do not want to create a `my_mean` function since `mean` is already defined in R)

* provide **informative names** to your function: the name should tell you what the function does and should not be too long

* avoid using reserved words, such as `if`, `else`, `for`, `function`, etc. Type `help(reserved)` in the console to see the full list

---

### Writing your own function: things to notice

**Variables defined inside the function are not available outside the function**. Their scope lies within and is limited to the function itself:


```r
my_mean &amp;lt;- function(vector) {
 tot_values &amp;lt;- length(vector)
 mean_var &amp;lt;- (sum(vector/tot_values))
 return(mean_var)
}
```


```r
tot_values
```

```
## Error in eval(expr, envir, enclos): object 'tot_values' not found
```


```r
mean_var
```

```
## Error in eval(expr, envir, enclos): object 'mean_var' not found
```

---

### Writing your own function: things to notice

If you do not write a **`return` statement**, the last statement will be your output:

```r
my_mean &amp;lt;- function(vector) {
 tot_values &amp;lt;- length(vector)
 mean_var &amp;lt;- sum(vector/tot_values)
 mean_var
}

my_mean(c(1:10))
```

```
## [1] 5.5
```

However, it is good practice to write a `return` statement: it makes your code easier to read and more explicit. Every piece of code after your `return` statement will be ignored. 

---

### Writing your own function: things to notice

`return` statements are useful: **conditional returns** 


```r
check_number &amp;lt;- function(x) {
 if (x &amp;gt; 0) {
 return("positive")
 }
 else if (x &amp;lt; 0) {
 return("negative")
 }
 else {
 return("zero")
 }
}
check_number(1)
```

```
## [1] "positive"
```

In this example, if x &amp;gt; 0, the function returns "positive" without evaluating rest of the body.

---

### Writing your own function: things to notice

`return` statements are useful: **return multiple objects** and collect them into a list or a vector:


```r
my_mean &amp;lt;- function(vector) {
 tot_values &amp;lt;- length(vector)
 mean_var &amp;lt;- (sum(vector/tot_values))
 return(list(tot_values, mean_var))
}
my_mean(1:10)
```

```
## [[1]]
## [1] 10
## 
## [[2]]
## [1] 5.5
```

---

### stop()

Let’s define a function `celsius_to_fahr()` that converts temperatures from Celsius to Fahrenheit. Example adapted from the carpentry lecture [at this link](https://swcarpentry.github.io/r-novice-gapminder/10-functions/index.html)


```r
celsius_to_fahr &amp;lt;- function(temp) {
 fahr &amp;lt;- (9/5) * temp + 32
 return(fahr)
}
```


```r
celsius_to_fahr(0)
```

```
## [1] 32
```

```r
celsius_to_fahr(-20)
```

```
## [1] -4
```

---

### stop()

For the `celsius_to_fahr()` function to work as intended, the argument `temp` must be a numeric value. Otherwise, the conversion between the two temperature scales will not work. 

To create an error, we can use the function `stop()`: use an `if-else` statement to check that the argument `temp` is a numeric value, and throw and error if that's not the case:


```r
celsius_to_fahr &amp;lt;- function(temp) {
 if (!is.numeric(temp)) {
 stop("temp must be a numeric vector")
 } else {
 fahr &amp;lt;- (9/5) * temp + 32
 return(fahr) 
 }
}
```


```r
celsius_to_fahr("zero")
```

```
## Error in celsius_to_fahr("zero"): temp must be a numeric vector
```

---

class: inverse, middle

# Practice writing functions

&amp;lt;!-- do them together in 5 min --&amp;gt;
---

### Functions and for loops

Consider this simulated data frame (example taken from Chapter 21 of your book):

```r
simulated_df &amp;lt;- tibble(
 a = rnorm(10),
 b = rnorm(10),
 c = rnorm(10),
 d = rnorm(10)
)

head(simulated_df, n = 5)
```

```
## # A tibble: 5 × 4
## a b c d
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -1.21 -0.477 0.134 1.10 
## 2 0.277 -0.998 -0.491 -0.476
## 3 1.08 -0.776 -0.441 -0.709
## 4 -2.35 0.0645 0.460 -0.501
## 5 0.429 0.959 -0.694 -1.63
```

---

### Functions and for loops

To compute the mean for each column, we learned we could use a **for loop**:

```r
output &amp;lt;- vector("double", length(simulated_df))

for (i in seq_along(simulated_df)) {
 output[[i]] &amp;lt;- mean(simulated_df[[i]])
}

output
```

```
## [1] -0.3831574 -0.1181707 -0.3879468 -0.7661931
```

---

### Functions and for loops

BUT if you are going to compute the mean for each column pretty frequently, and/or on different data frames, you want to **put your for loop into a function**. 

This way you only write the code once, and call the function every time you need it:

```r
col_mean &amp;lt;- function(df) {
 output &amp;lt;- vector("double", length(df))
 for (i in seq_along(df)) {
 output[i] &amp;lt;- mean(df[[i]])
 }
 output
}

col_mean(simulated_df)
```

```
## [1] -0.3831574 -0.1181707 -0.3879468 -0.7661931
```

---

### Functions and for loops

BUT what if instead than only computing the mean, you want to include also the median and standard deviation? You **could write a function for each**, replacing the `mean()` with `median()` and `sd()`:


```r
col_median &amp;lt;- function(df) {
 output &amp;lt;- vector("double", length(df))
 for (i in seq_along(df)) {
 output[i] &amp;lt;- median(df[[i]])
 }
 output
}

col_sd &amp;lt;- function(df) {
 output &amp;lt;- vector("double", length(df))
 for (i in seq_along(df)) {
 output[i] &amp;lt;- sd(df[[i]])
 }
 output
}
```

--

But this way you copied and pasted the code more than twice... and the differences among these chunks of code are hard to spot! **How can we re-write this code more efficiently?** 

---

### Functions with more than one argument

We can **set up our function with more than one argument**: the first is the data frame, the second is the name of the operation to perform, which **can be another function** like `mean()`, `median()`, `sd()`:


```r
col_summary &amp;lt;- function(df, fun) {
 output &amp;lt;- vector("double", length(df))
 for (i in seq_along(df)) {
 output[i] &amp;lt;- fun(df[[i]])
 }
 output
}
```


```r
col_summary(simulated_df, median)
```

```
## [1] -0.5555419 -0.4941011 -0.4656169 -0.6053490
```

```r
col_summary(simulated_df, mean)
```

```
## [1] -0.3831574 -0.1181707 -0.3879468 -0.7661931
```

---

### Functions as a way to organize your code 

Ideally, functions are short and do **one single thing**.

- it is a good habit to break up your code into sequential logical blocks, and write one function for each action (e.g. one function to import data, one to remove NA, one to rename variables, etc.)

- you can write functions so that the output from one function, is the first argument to the next function (functions composition)

---

### Functions as a way to organize your code 

Given this vector:

```r
v &amp;lt;- c(1:10, NA, NA)
v
```

```
## [1] 1 2 3 4 5 6 7 8 9 10 NA NA
```

I want to perform the following two operations, sequentially: remove NAs and calculate the mean (notice here I am using the functions `is.na` and `mean` inside my own functions)


```r
vect_remove_NA &amp;lt;- function(vector){
 return(vector[!is.na(vector)])
}
```


```r
vect_mean &amp;lt;- function(vector) {
 return(mean(vector))
}
```

---

### Functions as a way to organize your code 

First, I call the first function, `vect_remove_NA()`, on my vector `v`. Then, I save the results, and pass them to the second function, `vect_mean()`:

```r
vv &amp;lt;- vect_remove_NA(v)
vv &amp;lt;- vect_mean(vv)
vv
```

```
## [1] 5.5
```

I can do the same thing using `%&amp;gt;%` (for more see [here](https://rpubs.com/tjmahr/pipelines_2015)):

```r
p &amp;lt;- c(1,2,3,NA)
p %&amp;gt;% vect_remove_NA() %&amp;gt;% vect_mean()
```

```
## [1] 2
```

&amp;lt;!--
### Functions as a way to organize your code

**You can do anything with functions that you can do with vectors:**

- assign them to variables 
- store them in lists
- pass them as arguments to other functions 
- create them inside functions
- return them as the result of a function

https://github.com/annakrystalli/UNAM/blob/master/Functions_in_R.Rmd
--&amp;gt;

---

### Anonymous functions 

That is **functions without a name**. (AKA lambda expressions)

You probably won't define anonymous functions a lot, but you need to know they exist and recognize their syntax.

For example, anonymous functions can be particularly useful:
* if you just want to use a function once and do not want to name it
* when used in conjunction with other functions, such as those from the `apply()` family (your homework asks to explore `apply` as another alternative to for loops)

---

### Anonymous functions

Imagine we have the following function:

```r
f &amp;lt;- function(x) {
 x + 3
}
f(2)
```

```
## [1] 5
```

We can re-write it as an anonymous function. Notice the one-line, absence of name, and `()` to call it:

```r
(function(x) { x + 3 }) (2)
```

```
## [1] 5
```

Most often, anonymous functions are written without the `{}`, like this:

```r
(function(x) x + 3)(2)
```

```
## [1] 5
```

&amp;lt;!--
Here's an unammed function for calculating the mean of a vector `x`. In the following example, the input `x` to the function is each element of the list `l`.

```r
l &amp;lt;- list(1:5, 5:7)
lapply(l, FUN = function(x){sum(x)/length(x)})
```

```
## [[1]]
## [1] 3
## 
## [[2]]
## [1] 6
```

see http://adv-r.had.co.nz/Functional-programming.html#anonymous-functions
--&amp;gt;

---

### Anonymous functions: purrr
The purrr package in R (hello again, map function!) offers a different way to write anonymous functions: `~.` syntax. 

Example:

```r
# most efficient code
purrr::map_int(1:2, ~.x + 1L)

# middle-of-the-road code
(function(x) x + 1)(1:2)
(function(x) x + 1L)(1:2) #what is the difference here?

# most cumbersome code
xadd &amp;lt;-function(xadd) {
 xadd + 1
}

xadd(1:2)
```

---
## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin's and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/project-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/project-management/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Project management&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACS 30500 University of Chicago" />
 &lt;script src="libs/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="libs/remark-css/default.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/metropolis.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Project management
]
.author[
### &lt;a href="https://info5940.infosci.cornell.edu">MACS 30500&lt;/a> &lt;br /> University of Chicago
]

---





# Workspace

* Libraries with `library()`
* User-created objects
* Option to save image of current workspace
* Treat workspaces as disposable

---

![](/img/if-you-liked-it-you-should-have-saved-the-source-for-it.jpg)

---

# Save code, not workspace

* Enforces reproducibility
* Easy to regenerate on-demand
* Always save commands
* Always start R with a blank state
* Restart R often

---

# Bad approaches

```r
rm(list = ls())
```

* Good intent, but poor execution
* Only deletes user-created objects
* Enforces hidden dependencies on things you ran before `rm(list = ls())`

---

&amp;lt;iframe width="800" height="500" src="https://www.youtube.com/embed/GiPe1OiKQuk?start=7" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&amp;gt;&amp;lt;/iframe&amp;gt;

---

# How to store work

* Split work into projects
* **We already do this**
* But why?

---

# `setwd()`

```r
library(ggplot2)
setwd("/Users/bensoltoff/cuddly_broccoli/verbose_funicular/foofy/data")
df &amp;lt;- read.delim("raw_foofy_data.csv")
p &amp;lt;- ggplot(df, aes(x, y)) + geom_point()
ggsave("../figs/foofy_scatterplot.png")
```

---

# Project-based workflow

* File system discipline
* Working directory intentionality
* File path discipline

--

## Rationale for workflow

* Ensures portability
* Reliable, polite behavior

---

# RStudio Projects

* `.Rproj`
* Opening projects
* Switching between projects

---

# Use safe filepaths

* Avoid `setwd()`
* Split work into projects
* Declare each folder as a project
* Use `here()`

---

# `here::here()`


```r
library(here)
here()
```

```
## [1] "/Users/soltoffbc/Projects/Computing for Social Sciences/course-site"
```

--

* Build a file path


```r
here("static", "extras", "awesome.txt")
## [1] "/Users/soltoffbc/Projects/Computing for Social Sciences/course-site/static/extras/awesome.txt"
cat(readLines(here("static", "extras", "awesome.txt")))
## OMG this is so awesome!
```
 
--

* What if we change the working directory?


```r
setwd(here("static"))
getwd()
## [1] "/Users/soltoffbc/Projects/Computing for Social Sciences/course-site/static"
cat(readLines(here("static", "extras", "awesome.txt")))
## OMG this is so awesome!
```

---

# How does it know?

* Is a file named `.here` present?
* Is this an RStudio Project?
* Is this a checkout from a version control system?

---

# Filepaths and R Markdown

```
data/
 scotus.csv
analysis/
 exploratory-analysis.Rmd
final-report.Rmd
scotus.Rproj
```

--

* `.Rmd` and assumption of working directory
* Run `read_csv("data/scotus.csv")`
* Run `read_csv(here("data", "scotus.csv"))`

---

# R startup procedures

* Customized startup
* `.Renviron`
* `.Rprofile`

---

# `.Renviron`

* Define sensitive information
* Set R specific environmental variables
* Does not use R code syntax
* `usethis::edit_r_environ()`

--

## Example `.Renviron`

```shell
R_HISTSIZE=100000
GITHUB_PAT=abc123
R_LIBS_USER=~/R/%p/%v
```

---

# `.Rprofile`

* R code to run when R starts up
* Runs after `.Renviron`
* Multiple `.Rprofile` files
 * Home directory (`~/.Rprofile`)
 * Each R Project folder
* `usethis::edit_r_profile()`

---

# Common items in `.Rprofile`

1. Set a default CRAN mirror
1. Write a welcome message
1. Customize their R prompt
1. Change options, screen width, numeric display
1. Store API keys/tokens that are necessary for only a single project

---

# Git tracking of `.Rprofile`

&amp;lt;div style="width:100%;height:0;padding-bottom:56%;position:relative;"&amp;gt;&amp;lt;iframe src="https://giphy.com/embed/13e1PQJrKtqYKyO0FY" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;

---

# R Markdown

![](/img/data-science/base.png)

---

# R Markdown basics


````default

---
title: "Gun deaths"
date: "`r lubridate::today()`"
output: html_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rcis)

youth &amp;lt;- gun_deaths %&amp;gt;%
 filter(age &amp;lt;= 65)
```

# Gun deaths by age

We have data about `r nrow(gun_deaths)` individuals killed by guns. Only `r nrow(gun_deaths) - nrow(youth)` are older than 65. The distribution of the remainder is shown below:

```{r youth-dist, echo = FALSE}
youth %&amp;gt;% 
 ggplot(aes(age)) + 
 geom_freqpoly(binwidth = 1)
```

# Gun deaths by race

```{r race-dist}
youth %&amp;gt;%
 ggplot(aes(fct_infreq(race) %&amp;gt;% fct_rev())) +
 geom_bar() +
 coord_flip() +
 labs(x = "Victim race")
```

````

---

# Major components

1. A **YAML header** surrounded by `---`s
1. **Chunks** of R code surounded by ` ``` `
1. Text mixed with simple text formatting using the [Markdown syntax](../hw01-edit-README.html)

---

# Knitting process

.center[

![](https://r4ds.had.co.nz/images/RMarkdownFlow.png)

]

---

# Code chunks

* Naming code chunks
* Code chunk options
* `eval = FALSE`
* `include = FALSE`
* `echo = FALSE`
* `message = FALSE` or `warning = FALSE`
* `error = TRUE`
* `cache = TRUE`

--

## Global options

```r
knitr::opts_chunk$set(
 echo = FALSE
)
```

---

# Inline code



&amp;gt; We have data about 100798 individuals killed by guns. Only 15687 are older than 65. The distribution of the remainder is shown below:

---

# YAML header

```
--
title: "Gun deaths"
author: "Benjamin Soltoff"
date: 2017-02-01
output: html_document
---
```

* **Y**et **A**nother **M**arkup **L**anguage
* Standardized format for storing hierarchical data in a human-readable syntax
* Defines how `rmarkdown` renders your `.Rmd` file

---

# HTML document

```
---
title: "Untitled"
author: "Benjamin Soltoff"
date: "February 1, 2017"
output: html_document
---
```

---

# Table of contents

```
---
title: "Untitled"
author: "Benjamin Soltoff"
date: "February 1, 2017"
output:
 html_document:
 toc: true
 toc_depth: 2
---
```

---

# Appearance and style

```
---
title: "Untitled"
author: "Benjamin Soltoff"
date: "February 1, 2017"
output:
 html_document:
 theme: readable
 highlight: pygments
---
```

---

# PDF document

```
---
title: "Gun deaths"
date: 2017-02-01
output: pdf_document
---
```

---

# Presentations

* [ioslides](http://rmarkdown.rstudio.com/ioslides_presentation_format.html)
* [reveal.js](http://rmarkdown.rstudio.com/revealjs_presentation_format.html)
* [Slidy](http://rmarkdown.rstudio.com/slidy_presentation_format.html)
* [Beamer](http://rmarkdown.rstudio.com/beamer_presentation_format.html)
* [`xaringan`](https://bookdown.org/yihui/rmarkdown/xaringan.html)

---

# R scripts


```
# gun-deaths.R
# 2017-02-01
# Examine the distribution of age of victims in gun_deaths

# load packages
library(tidyverse)
library(rcis)

# filter data for under 65
youth &amp;lt;- gun_deaths %&amp;gt;%
 filter(age &amp;lt;= 65)

# number of individuals under 65 killed
nrow(gun_deaths) - nrow(youth)

# graph the distribution of youth
youth %&amp;gt;% 
 ggplot(aes(age)) + 
 geom_freqpoly(binwidth = 1)

# graph the distribution of youth, by race
youth %&amp;gt;%
 ggplot(aes(fct_infreq(race) %&amp;gt;% fct_rev())) +
 geom_bar() +
 coord_flip() +
 labs(x = "Victim race")
```

---

# When to use a script

* For troubleshooting
* Initial stages of project
* Building a reproducible pipeline
* It depends

--

## Running scripts

* Interactively
* Programmatically using `source()`

---

# Reproducible examples

* Minimal
* Complete
* Verifiable

---

# `reprex`




```
library(tidyverse)
count(diamonds, colour)
```

---

.center[

![](https://memeshappen.com/media/created/One-does-not-simply-understand-git-meme-60285.jpg)

]

---

# Git

## What files to commit

* Source files
* Markdown files
* Data files

## What files to not commit

* Temporary files
* Log files
* Files with private details
* Any file greater than 100 megabytes

---

# `.gitignore`

* System file
* Tells Git which files/directories to ignore

---

# Git LFS

* [Git Large File Storage](https://git-lfs.github.com/)
* Separate software for tracking large files
* Integrates with Git
* Generally charges a fee

---

# Accidentally cloned from the main

&amp;lt;div style="width:100%;height:0;padding-bottom:50%;position:relative;"&amp;gt;&amp;lt;iframe src="https://giphy.com/embed/3oxHQKW9lw6rK9kYtq" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;

---

# Accidentally cloned from the main

```bash
remote: Permission to hadley/ggplot2.git denied to bensoltoff.
fatal: unable to access 'https://github.com/hadley/ggplot2.git/': The requested URL returned error: 403
```

---

# Avoiding Git problems

1. Commit early and often
1. Push regularly to GitHub

---

# Burn it all down

.center[

![[Git (via xkcd)](https://xkcd.com/1597/)](https://imgs.xkcd.com/comics/git.png)

]
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script src="https://cfss.uchicago.edu/slides/macros.js">&lt;/script>
&lt;script src="https://platform.twitter.com/widgets.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/reproducible-examples-and-git/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/reproducible-examples-and-git/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Reproducible examples and Git&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Reproducible examples and Git
]
.author[
### MACS 30500 &lt;br /> University of Chicago
]

---









# Agenda

* Reproducible examples
* Git / GitHub
 * Vocabulary
 * Troubleshooting

---
class: middle
&amp;lt;img src="https://media.giphy.com/media/uRb2p09vY8lEs/giphy.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="../../img/allison_horst_art/reprex.png" alt="A side-by-side comparison of a monster providing problematic code to tech support when it is on a bunch of crumpled, disorganized papers, with both monsters looking sad and very stressed (left), compared to victorious looking monsters celebrating when code is provided in a nice box with a bow labeled 'reprex'. Title text reads 'reprex: make reproducible examples. Help them help everyone!'" width="80%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [Allison Horst](https://github.com/allisonhorst/stats-illustrations)]

---

## Reproducible examples

* reprex (noun)
* `reprex`
* `reprex::reprex()`

---

## Why reprexes?

Easier to talk about code that:

* Actually runs

--

* I don't have to run


--

* I can easily run

---

## `reprex`

```r
library(tidyverse)
count(diamonds, colour)
```

---
## Steps to creating a reproducible example:
1. Run your code
1. Copy your code
1. Run `reprex` in the console
1. paste your code into wherever you'd like!

(If it gets mad, you may not be copying your code first)


```r
m &amp;lt;- matrix(
 c(1:16),
 nrow = 4,
 ncol = 4,
 byrow = TRUE
)
m
```

```
## [,1] [,2] [,3] [,4]
## [1,] 1 2 3 4
## [2,] 5 6 7 8
## [3,] 9 10 11 12
## [4,] 13 14 15 16
```

```r
#&amp;gt; [,1] [,2] [,3] [,4]
#&amp;gt; [1,] 1 2 3 4
#&amp;gt; [2,] 5 6 7 8
#&amp;gt; [3,] 9 10 11 12
#&amp;gt; [4,] 13 14 15 16


for (row in 1:nrow(m)){ # going by rows OR columns
 for (col in 1:ncol(m)) { # by whatever's left (col OR rows)

 # m_sq[row,col]&amp;lt;-(m[row, col]^2)
 }
}
#&amp;gt; Error: object 'm_sq' not found
```

&amp;lt;sup&amp;gt;Created on 2023-07-05 with [reprex v2.0.2](https://reprex.tidyverse.org)&amp;lt;/sup&amp;gt;

---

## Customizing `reprex()`

.panelset[

.panel[

.panel-name[Include session info]

```r
reprex(
 x = mean(rnorm(100)),
 si = TRUE
)
```

]

.panel[

.panel-name[Change venue]

```r
reprex(
 x = mean(rnorm(100)),
 venue = "r"
)
```

]

.panel[

.panel-name[Style the code]

```r
reprex(
 x = {
if (TRUE) "true branch" else {
 "else branch"
}
 },
 style = TRUE
)
```

]

]

---

## Reprex do's and don'ts

* Ensure the example is **fully** reproducible
* Use the smallest, simplest, most built-in data possible
* Include commands on a strict "need to run" basis
* Consider including "session info"
* Use good coding style to ensure the readability of your code by other human beings
* Ensure portability of the code

---

## Build some reproducible examples

&amp;lt;img src="https://media.giphy.com/media/l4Ki2obCyAQS5WhFe/giphy.gif" width="65%" style="display: block; margin: auto;" /&amp;gt;

&lt;div class="countdown" id="timer_e5ff030c" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
&lt;div class="countdown-controls">&lt;button class="countdown-bump-down">&amp;minus;&lt;/button>&lt;button class="countdown-bump-up">&amp;plus;&lt;/button>&lt;/div>
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">15&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---

class: center, middle

&amp;lt;img src="../../img/git-meme.jpeg" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Git

* Version control system
* Repository (repo)
* GitHub is where we can store / distribute repos (distinction between Git and GitHub)
* COMMIT OFTEN!!
 * Think of it as taking a photo do of EVERYTHING to document where you are in your project
 * Try to have a meaningful message to remind yourself what changed (in case you need to go back later!)
* Push somewhat often (people vary on this)


---
## Why use Git? 

--
&amp;lt;img src="https://swcarpentry.github.io/git-novice/fig/phd101212s.png" width="450px" style="display: block; margin: auto;" /&amp;gt;


---
## Git

### What files to commit

* Source files (includes markdown files)
* Configuration files (e.g. gitignore, .Rproj)
* Data files

### What files to not commit

* Temporary files
* Log files
* Files with private details
* Any file greater than 100 megabytes

---

## `.gitignore`

* System file
* Tells Git which files/directories to ignore

--
### Getting started with gitignore:

* [example files here](https://github.com/github/gitignore)
* [creating a git ignore file](https://www.w3schools.com/git/git_ignore.asp?remote=github)

---
## Git LFS

* [Git Large File Storage](https://git-lfs.github.com/)
* Separate software for tracking large files
* Integrates with Git
* Generally charges a fee


---

## Vocabulary 
* Upstream: typically the original repo (see below on forking)
* Main / master: where you are typically working (note that )
* Branch: used to test out / develop new code in a safe local so you don't have to roll back any changes. These can be merged into the main when you're ready. 
* Forking: Copying from the repo to your own repo (typically when you do not have write access to the original)
* Cloning: Copying from the repo (typically to your machine when you have write access to the original)
* **Pulling** is when you are 'refreshing' your copy of the files to your machine. 
* **Pushing** is when you are sending your changes to GitHub 

The order of your workflow matters less when you are working on your own on a project, but when you are collaborating with others, it becomes crucial to have a good workflow. Think of a google doc you are collaboratively editing. You work offline and when you go back online, someone else has made changes, how could you reconcile this? The analogy is trying to push changes without pulling to update your files first. **It is a good habit to pull before starting work, even when working alone.** 



---
## Git and merge conflicts
*Typically* these occur when you haven't pulled before pushing changes in a collaborative project. Essentially, there are now two 'current' versions of a file and they need to be reconciled. Sometimes, they can be automatically resolved but sometimes you have to deal with the conflicts. In these instances, you can review the code side-by-side and confirm the changes. (**this option varies by how you interact with Git!**)


---
## Using Git and various interfaces

There are more options to consider when using Git, right now, we've mostly been using RStudio. You can also use other options, such as GitHub desktop, the terminal, or others. [See here for a partial list of options!](https://git-scm.com/downloads/guis)


---
## Command line Git
Once you feel comfortable in RStudio, you can switch to the terminal. See this [tutorial on command line Git here](https://docs.gitlab.com/ee/gitlab-basics/start-using-git.html)



---
## Command line Git

## Steps:
1. (initially) Setup git and navigate to relevant directory
1. (in terminal) git pull (everything is up to date!) 
1. (make changes)
1. git status to verify which files have been changed
1. git add (file name) OR git add ..
1. git status to double-check you're ready / didn't forget anything
1. git commit -m "comment you want to appear"
1. git push 

---

## Navigating to the relevant directory: fun with bash!
This is initially quite daunting (at least it was for me, but you get comfortable after awhile). You can also patch this together a bit if you need by getting file locations in, say, finder, and then using that to help navigate to relevant files. 

--
### Vocabulary:

* pwd to check your current directory
* cd to navigate to your desired directory and move around terminal 
 * .. can help you navigate up (command is cd ..)
 * (tab) can autofill text
 * (tab)(tab) can give you options
* ls to list all visible content in your current directory
* ls -a to list all visible and hidden contents in your current directory
* touch to create a new file; provide the filename and the extension
* :q to exit and end the execution of a process
* rm remove a file
* cp copy a file (can copy elsewhere)

---
## Command line Git

## Steps:
1. (initially) Setup git and navigate to relevant directory
1. (in terminal) git pull (everything is up to date!) 
--
1. (make changes)
1. git status to verify which files have been changed
1. git add (file name) OR git add ..
1. git status to double-check you're ready / didn't forget anything
1. git commit -m "comment you want to appear"
1. git push

---

## Command line Git: Vocabulary
* git init to initialize a new repo
* git status to check the current status of your repo
* git add . to add to the git staging area all new or changed files
* git commit -m "your commit message" to commit the staged files
* git push to push your committed files the online Github repo
* git diff to show differences in files
* git log to show all history of your commits
* git reset --hard HEAD~1 to delete a pushed commit (use with caution), followed by git push -f origin main to push the deleted commit to the online Github repo


---

class: center, middle, inverse

# Troubleshooting Git


---
## Key issues that pop up

* Cloning from main on accident

---

## Accidentally cloned from the main

&amp;lt;img src="https://media.giphy.com/media/3oxHQKW9lw6rK9kYtq/giphy.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Accidentally cloned from the main

```bash
remote: Permission to cfss-hmwks/hw03.git denied to cfss-student
fatal: unable to access 'https://github.com/cfss-hmwks/hw03.git/': The requested URL returned error: 403
```

--

```r
usethis::use_git_remote(
 name = "origin",
 url = "&amp;lt;YOUR_FORK_URL&amp;gt;",
 overwrite = TRUE
)
```

---


## Burn it all down

&amp;lt;img src="https://imgs.xkcd.com/comics/git.png" width="35%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [xkcd](https://xkcd.com/1597/)]

---
## Avoiding Git problems

1. Commit early and often
1. Push regularly to GitHub


---

## Recap

1. Commit early and often as you revise and update your project
1. Push regularly to GitHub
1. Each successful push results in a new “worst case scenario”
1. If you screw things up badly on your local machine, copy all the files in your repo to a safe place on your computer (i.e. a new folder)
1. Rename the existing local repository as a temporary measure
1. Clone the repository from GitHub to your local machine. This version of the repository works as intended
1. Copy all relevant files back over from your safe space. That is, the ones whose updated state you need to commit
1. Stage, commit, and push


---

## Acknowledgments 

Materials adapted from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/reproducible-workflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/reproducible-workflow/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Reproducible workflow&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Reproducible workflow
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# A holistic workflow

---

## Workspace

When you are running a session of R, the workspace contains all the objects you created in that session: 
* Libraries with `library()`
* User-created objects (variables, functions, etc.)

Our goal: not to preserve the workspace, but the code that produces that workspace

---

## Pets VS Cattle?

&amp;lt;img src="../../../../../../../../../../../img/individual-cows-vs-cattle.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

&amp;lt;!-- https://blog.octo.com/en/pet-vs-cattle-from-server-craftsman-to-software-craftsman/ --&amp;gt;

--

**Think of your R workspaces as livestock, not pets. Your R code is your pet!**

---

## Save code, not workspace

**Advantages of saving code, not workspace:**
* Enforces reproducibility: if everything is in the code, other people can reproduce your work
* Easy to regenerate on-demand: re-run the code and the workspace will be recreated

--

**How to make this happen:**
* Always save code in your script

* Always start R with an empty and new workspace, do not restore the previous section. Change the default settings:
 * "Do you want to save your workspace?" No, thanks
 * Tools &amp;gt; Global Options &amp;gt; General 
 * uncheck “Restore .Rdata into workspace at startup”
 * set to Never "Save workspace to .RData on exit"

* Restart R often: Session &amp;gt; Restart R

---

## Inefficient approach to clear workspace

```r
rm(list = ls())
```

* Good intent, but poor execution
* Only deletes user-created objects
* Enforces hidden dependencies on things you ran before `rm(list = ls())`

Instead: restart your R session to make sure you are clearing everything from your workspace

--

**Why do all of this?**...

---

class: middle, center

&amp;lt;iframe width="800" height="500" src="https://www.youtube.com/embed/GiPe1OiKQuk?start=07" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&amp;gt;&amp;lt;/iframe&amp;gt;

---

## Avoid unknown unknowns

**We want to restart our R session to avoid the "unknown unknowns"**: e.g., we loaded something in the workspace that we did not even remember, or we have run previous scripts for which results are held, etc.

Solution: write every script like its running in a fresh process

--

**Exception:** There are some instances where running everything in a new session of R might be challenging, such as storing computationally demanding output [see more on data in R here](https://bookdown.org/f_lennert/introduction-to-r/workingwithdata.html):
* In Rmd: `cache = TRUE`
* In regular R script: use `write_rds()` to save &amp;amp; `read_rds()` to import back

---

class: inverse, middle

# Project-based workflows

---

## Project-based workflow

In this class, we have been using a project-based workflow **by splitting work into project** (e.g., every homework assignment has been stored in a different R project, and every in-class practice exercise that you downloaded from the website has been stored as a R project)

The **value of this approach**:
* keeps materials organized
* helps managing working directories

---

## Working directory

The working directory is the folder that R takes as **default directory** every time you try to access files, scripts, etc.

**To check your current working directory**: start a new session of R and type `getwd()`. In R workbench it should be `"/home/your_cnetid"`

--

Working directory with `setwd()` vs Project-based workflow:
* You can manually set your directory to an absolute path, for example using `setwd()` 
* **OR** you can use relative file paths (relative to the project folder where this project is stored)

---

## Working directory with `setwd()`

This example uses `setwd()`to manually set your working dir to a specific folder:

```r
library(tidyverse)

# modify workng directory
setwd("/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/examples/")
getwd()

# reference directly data to import
data_ex_tea &amp;lt;- read_csv("data_ex_tea.csv")

#relevel months
data_ex_tea &amp;lt;- data_ex_tea %&amp;gt;% mutate(Months = factor(Months, levels = month.abb))

# plot
p &amp;lt;- ggplot(data_ex_tea, aes(Months, Cups_tea)) + geom_point()

# save p in figures folder, use .. notation to go up one level 
ggsave("../figures/tea_scatterplot.png")
```
--

Is this code reproducible?

---

## Project-based workflow: RStudio Projects

The previous code is not reproducible because I hard coded my own absolute path in the code. If you try to run the same code, you will get an error. This hinders reproducibility! 

Our goal should be to **avoid specifying the working directory, and have it detected automatically.** 

---

## Project-based workflow: RStudio Projects

R studio has something called "RStudio Projects" (**`.Rproj`**) to help us implement this workflow. R will automatically detect the working directory based on your project. Advantages: ensures portability and a reliable behavior.

It needs: 

* File system discipline: one project = one folder with all material you need for that project
* File path discipline: do not use long file paths for working directories

For example, every homework and in-class exercise folder that we have been using in this course has a `.Rproj` file. This file helps R to automatically detect the working directory. If you switch between projects, the working directory changes automatically. 

---

## Working dir with `setwd()` vs Project-based workflow

Review the previous example using `.Rproj`:
* Go to File &amp;gt; New Project &amp;gt; Existing Directory
* If I set the Existing Directory to my project `"/Users/jeanclipperton/Desktop/something_something"`, 
the previous code can be modified as follows:

```r
library(tidyverse)

# get current working directory 
getwd()

# reference data directly to import
data_ex_tea &amp;lt;- read_csv("data_ex_tea.csv")

#relevel months
data_ex_tea &amp;lt;- data_ex_tea %&amp;gt;%
 mutate(Months = factor(Months, levels = month.abb))
 
# plot
p &amp;lt;- ggplot(data_ex_tea, aes(Months, Cups_tea)) +
 geom_point()


# save p in figures folder, use .. notation to go up one level 
ggsave("../figures/tea_scatterplot.png")

# save p in figures folder
ggsave("foofy/figures/foofy_scatterplot.png")
```

---


class: inverse, middle

# Practice using reproducible workflow within R

---

### Instructions:

1) In your [R Workbench](https://macs30500.netlify.app/setup/r/r-server/), create a new R Project (File &amp;gt; New Project &amp;gt; New Directory); no need to make it a Version control project for this exercise. Give the name "test" to the new directory and place it in a sub-folder (e.g., your lecture sub-folder, etc.)

2) Inside your newly created "test" folder, create a "data" sub-folder (Go under "Files" (lower right menu) and click on the yellow folder icon)

3) In your R Workbench, you should have your HW3 with a folder called "data" and two `.csv` files. You want to take the `scdb-case.csv` and make a copy of it in your newly created "test" folder (if you do not have this data, you can pick any other csv file from another folder). To do so:
* navigate to the HW3 data folder, find the csv file and check the box next to it
* click on the blue wheel icon under "Files" and select "Copy to"
* navigate to the "test" folder, then to its "data" sub-folder, and move the csv to that sub-folder

---

### Instructions (cont.):

4) Create a new R script inside your "test" folder (File &amp;gt; New File &amp;gt; R Script) 

5) Use `getwd()` to check your working directory.
It should be your new project's working directory

6) In your script, load the tidyverse library, then import the `scdb-case.csv` data using a **full path**

7) Import the same data using a **relative path** (relative to your `.Rproj`)

---


## Use safe filepaths

Using R projects to encapsulate our project is great and prevents a number of problems. 

So far we have learned to:
* Avoid `setwd()` at all costs
* Split work into R projects
* Declare each folder as a project

In addition:
* We can use `here()` to locate a file location independently from where the current working directory is. So, even if the working directory accidentally gets changed, we still are able to retrieve the file.

---

&amp;lt;!-- class: small --&amp;gt;

## How to use the `here()` function from the `here` package


```r
library(here)
here()
```

```
## [1] "/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site"
```

This prints out what it identifies as current project folder (relative to where these slides have been created) 

--

If I want to build a file path, based on this directory, I can use the `here()` function to build that path. For example, if I want to access a file `awesome.txt` located in a specific folder and sub-folder of `course-site`, I pass each folder and the name of the file as a different argument to the `here()` function:


```r
# use here to build the path
here("static", "extras", "awesome.txt")
## [1] "/Users/jeanclipperton/Library/CloudStorage/Box-Box/Teaching/CFSS/course-site/static/extras/awesome.txt"

# test to see if it works
cat(readLines(here("static", "extras", "awesome.txt")))
## OMG this is so awesome!
```
 
---

## How to use the `here()` function from the `here` package

What happens if we change the working directory?


```r
# change the working directory
setwd("/Users/jeanclipperton/Library")
getwd()
## [1] "/Users/jeanclipperton/Library"

# test to see if this still works
cat(readLines(here("static", "extras", "awesome.txt")))
## OMG this is so awesome!
```

Since I changed the working directory, there is no "static" folder anymore, but the `here()` function still works!

This because the output of the code `here("static", "extras", "awesome.txt")` remains the same regardless on how we change the working dir: **`here()` identifies the location of the current `.Rproj`** and builds the path from there

---

class: inverse, middle

# Practice using reproducible workflow within R

---

### Instructions:

8) Load the `here` library (already installed on R Workbench). Type `here()` to print out what it identifies as current project folder. Then import the same `scdb-case.csv` file building a path with `here()`
9) 

---

## Filepaths and R Markdown

**Every time you knit an `.Rmd` file, R always assumes that its location is the working directory**, regardless of whatever you are doing in R. This is important to remember, and sometimes leads to complications.

Let's see an example with the supreme courts data you worked with for homework 3... 

---

## Filepaths and R Markdown

Imagine we have a `"court-project"` folder, structured as follows:

```
data/
 scdb-case.csv
analysis/
 exploratory-analysis.Rmd
final-report.Rmd
scotus.Rproj
```

--

Imagine that in both of the R Markdown files `exploratory-analysis.Rmd` and `final-report.Rmd`, we have this piece of code: `read_csv("data/scdb-case.csv")`

* In `final-report.Rmd`, will this code work?
* In `exploratory-analysis.Rmd`, will this code work?
* If we replace the `read_csv("data/scdb-case.csv")` with `read_csv(here("data", "scdb-case.csv"))`, will this code work in both .Rmd files? **Hint: here can override the particular location of the file while the relational path cannot.**

---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/shiny/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/shiny/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Building Shiny Apps&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACS 20400 University of Chicago" />
 &lt;script src="libs/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="libs/remark-css/default.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/metropolis.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Building Shiny Apps
]
.author[
### MACS 20400 &lt;br /> University of Chicago
]

---




# What is Shiny?

* R package from RStudio
* Web application framework for R
* R code `\(\rightarrow\)` interactive web page
* No HTML/CSS/Javascript knowledge required
* Great for sharing R analysis with someone scared of R

---

# Dating age rule

* [Half your age plus seven](https://www.netflix.com/watch/70152033?t=420)
* [My Shiny app](https://bensoltoff.shinyapps.io/cfss-age-rule/)

---

# What is a Shiny app?

* Computer running R
* Web page
* Computer performs calculations, sends contents to web page
* User interacts with web page, sends updates back to computer
* Rinse and repeat

---

# City of Chicago wage employees

* [Dataset](https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w)
* [Final Shiny app](https://bensoltoff.shinyapps.io/chicago-employees/)

---

# Shiny app template

```r
library(shiny)
ui &amp;lt;- fluidPage()
server &amp;lt;- function(input, output) {}
shinyApp(ui = ui, server = server)
```

**Important**: Do not place any code after `shinyApp()`

---

# Run Shiny app in RStudio, method 1

Save file as **app.R** `\(\rightarrow\)` "Run" button turns to "Run App"

![](/img/shiny-runapp.png)

Good for creating Shiny apps quickly, all code in one file

---

# Run Shiny app in RStudio, method 2

Save UI as **ui.R** and server as **server.R** in **same directory**

![](/img/Shiny-run-app-screenshot.png)

Good for complex Shiny apps, separates view vs logic

If using this method, **do not** include a call to `shinyApp(...)`

---

# Run Shiny app in RStudio, method 3

*File &amp;gt; New File &amp;gt; Shiny Web App...*

![](/img/shiny-add-template.png)

Generates the template for you

---

# Stop Shiny app in RStudio

Press "Esc" or click the *Stop* icon

![](/img/shiny-stopapp.png)

---

# Exercise: create the basic app

* `usethis::use_course("cis-ds/shiny-demo")`
* Create a basic Shiny app
* Import the City of Chicago wage employee data file

---

# Add elements to app inside `fluidPage()`

```r
library(shiny)
ui &amp;lt;- fluidPage("Hello CFSS")
server &amp;lt;- function(input, output) {}
shinyApp(ui = ui, server = server)
```

![](/img/shiny-basic.png)

---

# Add elements to app inside `fluidPage()`

```r
fluidPage(
	h1("My Shiny app"),
	"Hello CFSS"
)
```

![](/img/shiny-add-h1.png)

---

# Add HTML to `fluidPage()`

* Remember the UI simply creates HTML
* [Can use any HTML tags](http://shiny.rstudio.com/articles/tag-glossary.html)
 * `h1()` = header1
 * `br()` = line break
 * `strong()` = bold text
* Any HTML tag can be accessed using `tags` object
 * `h1` = `tags$h1()`, `br` = `tags$br()`
* Common tags can be accesed without `tags`

---

# Add HTML to `fluidPage()`

```r
fluidPage(
 h1("My Shiny app"),
 h3("Subtitle"),
 "Hello",
 "CFSS",
 br(),
 strong("bold text")
)
```

![](/img/shiny-tags.png)

---

# Use a layout

* By default, all elements stack up one after the other
* [Can use different layouts](http://shiny.rstudio.com/articles/layout-guide.html)
* We’ll use `sidebarLayout()`

---

# `sidebarLayout()`

```r
fluidPage(
 titlePanel("My Shiny app"),
 sidebarLayout(
 sidebarPanel(
 "This is a side panel"
 ),
 mainPanel(
 "And this is the main stuff"
 )
 )
)
```

---

# `sidebarLayout()`

![](/img/shiny-sidebarlayout.png)

---

# Exercise: add a layout

* Define the layout for the application
* Add an app title
* Identify where inputs and outputs will go

---

# Inputs and outputs

* For interactivity, app needs inputs and outputs
* **Inputs** - things user can toggle/adjust
* **Output** - R objects user can see, often depend on inputs

---

# Inputs

```r
library(shiny)

ui &amp;lt;- fluidPage(
 sliderInput(
 "num", "Choose a number",
 min = 0, max = 100,
 value = 20)
)

server &amp;lt;- function(input, output) {}

shinyApp(ui = ui, server = server)
```

![](/img/shiny-input.png)

---

# Inputs

```r
sliderInput("num", "Choose a number",
 min = 0, max = 100, value = 20)
```


```
## &amp;lt;div class="form-group shiny-input-container"&amp;gt;
## &amp;lt;label class="control-label" id="num-label" for="num"&amp;gt;Choose a number&amp;lt;/label&amp;gt;
## &amp;lt;input class="js-range-slider" id="num" data-skin="shiny" data-min="0" data-max="100" data-from="20" data-step="1" data-grid="true" data-grid-num="10" data-grid-snap="false" data-prettify-separator="," data-prettify-enabled="true" data-keyboard="true" data-data-type="number"/&amp;gt;
## &amp;lt;/div&amp;gt;
```

---

# Inputs

![](/img/shiny-inputs.png)

---

# Inputs

.pull-left[

```r
sliderInput("num",
 "Choose a number",
 min = 0,
 max = 100,
 value = 20)
```

]

.pull-right[

* Input name
* Label to display
* Input-specific arguments

]

---

# Exercise: add inputs

* Add inputs for
 * Wage
 * Full/part-time
 * Department

---

# Outputs

Function | Outputs
---------|---------
`plotOutput()` | plot
`tableOutput()` | table
`uiOutput()` | Shiny UI element
`textOutput()` | text

* Plots, tables, text - anything that R creates and users see
* Initialize as empty placeholder space until object is created

---

# Outputs

```r
library(shiny)

ui &amp;lt;- fluidPage(
 sliderInput("num", "Choose a number",
 0, 100, 20),
 plotOutput("myplot")
)

server &amp;lt;- function(input, output) {}

shinyApp(ui = ui, server = server)
```

![](/img/shiny-addplot-placeholder.png)

---

# Exercise: add placeholders for output

* Add placeholders for a
 * Histogram
 * Table

---

# Server: assemble input into outputs

```r
server &amp;lt;- function(input, output) {
 output$myplot &amp;lt;- renderPlot({
 plot(rnorm(input$num))
 })
}
```

1. Save objects into `output$`
1. Build objects with `render*()`

---

# `Output()` `\(\rightarrow\)` `render*()`

Output function | Render function
-------|----------
`plotOutput()` | `renderPlot({})`
`tableOutput()` | `renderTable({})`
`uiOutput()` | `renderUI({})`
`textOutput()` | `renderText({})`

---

# `render*()` functions

```r
renderPlot({
 plot(rnorm(100))
})
```

---

# Server: assemble input into outputs

```r
server &amp;lt;- function(input, output) {
 output$myplot &amp;lt;- renderPlot({
 plot(rnorm(input$num))
 
 # in UI:sliderInput("num", ...)
 })
}
```

1. Save objects into `output$`
1. Build objects with `render*()`
1. Access input values with `input$`

---

# Exercise: add output

* Create a histogram of hourly wages for selected employees
* Add a table showing the count of selected employees per department

---

# Reactivity

* Shiny uses **reactive programming**
* Reactive variables
 * When value of variable `x` changes, anything that relies on `x` is re-evaluated
 * Contrast with regular R:
 ```r
 x &amp;lt;- 5
 y &amp;lt;- x + 1
 x &amp;lt;- 10
 ```

---

# Reactivity

* `input$num` is a **reactive** value
 ```r
 output$myplot &amp;lt;- renderPlot({
 plot(rnorm(input$num))
 })
 ```
* `output$myplot` depends on `input$num`
 * `input$num` changes `\(\rightarrow\)` `output$myplot` **reacts**
* All inputs are automatically reactive, so if you use any input inside a `render*` function, the output will re-render any time input changes

---

# Reactive contexts

* You can define your own reactive variables
* Reactive values can only be used inside **reactive contexts**
* Any `render*` function is a reactive context
* Use `reactive({...})` to assign a reactive variable
* Use `observe({...})` to access a reactive variable
* Remember: reactive variable means anything that depends on it gets re-executed automatically

---

# Reactive contexts

.pull-left[

## Assign variable

```r
server &amp;lt;- function(input, output) {
	x &amp;lt;- input$num + 1
}
# error
```

```r
server &amp;lt;- function(input, output) {
 x &amp;lt;- reactive({
 input$num + 1
 })
}
# OK
```

]

.pull-right[

## Access variable

```r
server &amp;lt;- function(input, output) {
	print(input$num)
}
# error
```

```r
server &amp;lt;- function(input, output) {
 observe({
 print(input$num)
 })
}
# OK
```

]

---

# Simple Shiny app using basic reactivity

```r
library(shiny)
ui &amp;lt;- fluidPage(
 sliderInput("num", "Choose a number",
 0, 100, 20),
 plotOutput("myplot")
)

server &amp;lt;- function(input, output) {
 output$myplot &amp;lt;- renderPlot({
 plot(seq(input$num))
 })
 x &amp;lt;- reactive({
 input$num + 1
 })
 observe({
 print(x())
 })
}

shinyApp(ui = ui, server = server)
```

---

# Exercise: make your code more efficient

* Create a reactive data frame `employ_filter` that creates the filtered data frame
* Use `employ_filter` to create the histogram and table

---

# Create UI elements dynamically

* `uiOutput()`
* Changing input values based on other inputs

---

# Basic example of uiOutput()

```r
library(shiny)
ui &amp;lt;- fluidPage(
 numericInput("num", "Maximum slider value", 5),
 uiOutput("slider")
)

server &amp;lt;- function(input, output) {
 output$slider &amp;lt;- renderUI({
 sliderInput("slider", "Slider", min = 0,
 max = input$num, value = 0)
 })
}

shinyApp(ui = ui, server = server)
```

---

# Exercise: Populate the job titles

* Use `uiOutput()` in our app to populate the job titles input

---

# Share your app: shinyapps.io

* Go to http://www.shinyapps.io/ and make an account
* Make sure all your app files are in an isolated folder
* Click "Publish Application" in RStudio
 ![](/img/shiny-publish.png)
 * You might be asked to install a couple packages
 * Follow instructions from RStudio


 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script src="https://cfss.uchicago.edu/slides/macros.js">&lt;/script>
&lt;script src="https://platform.twitter.com/widgets.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/statistical-learning-classification-and-cross-validation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/statistical-learning-classification-and-cross-validation/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Statistical learning: classification and cross-validation&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACS 30500 University of Chicago" />
 &lt;script src="libs/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="libs/remark-css/default.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/metropolis.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Statistical learning: classification and cross-validation
]
.author[
### &lt;a href="https://info5940.infosci.cornell.edu">MACS 30500&lt;/a> &lt;br /> University of Chicago
]

---




.center[

![](https://eight2late.files.wordpress.com/2016/02/7214525854_733237dd83_z1.jpg?w=700)

]

---

.center[

![:scale 35%](https://s-media-cache-ak0.pinimg.com/564x/0b/87/df/0b87df1a54474716384f8ec94b52eab9.jpg)

]

---

.center[
![:scale 50%](http://data.iwastesomuchtime.com/November-26-2012-17-34-05-cookie.gif)

]

---

# Interpreting a decision tree



&amp;lt;img src="index_files/figure-html/titanic_tree-1.png" width="864" /&amp;gt;

---

# A more complex tree

&amp;lt;img src="index_files/figure-html/titanic_tree_full-1.png" width="864" /&amp;gt;

---

# A more complex-ier tree

&amp;lt;img src="index_files/figure-html/titanic_tree_complicated-1.png" width="864" /&amp;gt;

---

# Benefits/drawbacks to decision trees

+ Easy to explain
+ Easy to interpret/visualize
+ Good for qualitative predictors

- Lower accuracy rates
- Non-robust

---

# Random forests

![](https://c402277.ssl.cf1.rackcdn.com/photos/946/images/story_full_width/forests-why-matter_63516847.jpg?1345534028)

---

# Sampling 


```
## [1] 1 2 3 4 5 6 7 8 9 10
```

--

.pull-left[

##### Sampling without replacement


```
## [[1]]
## [1] 6 4 10 3 7 1 5 8 9 2
## 
## [[2]]
## [1] 1 6 9 2 10 8 4 5 7 3
## 
## [[3]]
## [1] 5 9 7 8 1 2 3 4 10 6
## 
## [[4]]
## [1] 1 7 6 5 3 8 2 4 10 9
## 
## [[5]]
## [1] 1 8 6 2 3 7 10 4 5 9
```

]

--

.pull-right[

##### Sampling with replacement


```
## [[1]]
## [1] 3 4 1 10 7 5 1 2 5 9
## 
## [[2]]
## [1] 8 1 10 5 3 7 3 1 10 3
## 
## [[3]]
## [1] 9 10 3 1 10 1 7 3 6 3
## 
## [[4]]
## [1] 8 3 6 3 5 10 10 3 6 5
## 
## [[5]]
## [1] 10 6 6 6 1 10 3 1 5 9
```

]

---

# Random forests

* Bootstrapping
* Reduces variance
* Bagging
* Random forest
 * Reliability

---

# Estimating statistical models using `caret`

* Not part of `tidyverse` (yet)
* Aggregator of hundreds of statistical learning algorithms
* Provides a single unified interface to disparate range of functions
 * Similar to `scikit-learn` for Python

---

# `train()`


```r
library(caret)

titanic_clean &amp;lt;- titanic %&amp;gt;%
 drop_na(Survived, Age)

caret_glm &amp;lt;- train(Survived ~ Age, data = titanic_clean,
 method = "glm",
 family = binomial,
 trControl = trainControl(method = "none"))
summary(caret_glm)
```

```
## 
## Call:
## NULL
## 
## Deviance Residuals: 
## Min 1Q Median 3Q Max 
## -1.1488 -1.0361 -0.9544 1.3159 1.5908 
## 
## Coefficients:
## Estimate Std. Error z value Pr(&amp;gt;|z|) 
## (Intercept) -0.05672 0.17358 -0.327 0.7438 
## Age -0.01096 0.00533 -2.057 0.0397 *
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
## Null deviance: 964.52 on 713 degrees of freedom
## Residual deviance: 960.23 on 712 degrees of freedom
## AIC: 964.23
## 
## Number of Fisher Scoring iterations: 4
```

---

# Estimating a random forest




```r
titanic_rf &amp;lt;- train(Survived ~ ., data = titanic_rf_data,
 method = "rf",
 ntree = 200,
 trControl = trainControl(method = "oob"))
titanic_rf
```

```
## Random Forest 
## 
## 714 samples
## 7 predictor
## 2 classes: 'Died', 'Survived' 
## 
## No pre-processing
## Resampling results across tuning parameters:
## 
## mtry Accuracy Kappa 
## 2 0.8151261 0.6038002
## 5 0.8039216 0.5885946
## 9 0.7885154 0.5589455
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.
```

---

# Structure of `train()` object


```
## List of 25
## $ method : chr "rf"
## $ modelInfo :List of 15
## $ modelType : chr "Classification"
## $ results :'data.frame':	3 obs. of 3 variables:
## $ pred : NULL
## $ bestTune :'data.frame':	1 obs. of 1 variable:
## $ call : language train.formula(form = Survived ~ ., data = titanic_rf_data, method = "rf", ntree = 200, trControl = trainCont| __truncated__
## $ dots :List of 1
## $ metric : chr "Accuracy"
## $ control :List of 26
## $ finalModel :List of 23
## ..- attr(*, "class")= chr "randomForest"
## $ preProcess : NULL
## $ trainingData: tibble [714 × 8] (S3: tbl_df/tbl/data.frame)
## $ ptype : tibble [0 × 7] (S3: tbl_df/tbl/data.frame)
## $ resample : NULL
## $ resampledCM : NULL
## $ perfNames : chr [1:2] "Accuracy" "Kappa"
## $ maximize : logi TRUE
## $ yLimits : NULL
## $ times :List of 3
## $ levels : chr [1:2] "Died" "Survived"
## ..- attr(*, "ordered")= logi FALSE
## $ terms :Classes 'terms', 'formula' language Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked
## .. ..- attr(*, "variables")= language list(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked)
## .. ..- attr(*, "factors")= int [1:8, 1:7] 0 1 0 0 0 0 0 0 0 0 ...
## .. .. ..- attr(*, "dimnames")=List of 2
## .. ..- attr(*, "term.labels")= chr [1:7] "Pclass" "Sex" "Age" "SibSp" ...
## .. ..- attr(*, "order")= int [1:7] 1 1 1 1 1 1 1
## .. ..- attr(*, "intercept")= int 1
## .. ..- attr(*, "response")= int 1
## .. ..- attr(*, ".Environment")=&amp;lt;environment: R_GlobalEnv&amp;gt; 
## .. ..- attr(*, "predvars")= language list(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked)
## .. ..- attr(*, "dataClasses")= Named chr [1:8] "factor" "numeric" "factor" "numeric" ...
## .. .. ..- attr(*, "names")= chr [1:8] "Survived" "Pclass" "Sex" "Age" ...
## $ coefnames : chr [1:9] "Pclass" "Sexmale" "Age" "SibSp" ...
## $ contrasts :List of 2
## $ xlevels :List of 2
## - attr(*, "class")= chr [1:2] "train" "train.formula"
```

---

# Model statistics


```r
titanic_rf$finalModel
```

```
## 
## Call:
## randomForest(x = x, y = y, ntree = 200, mtry = min(param$mtry, ncol(x))) 
## Type of random forest: classification
## Number of trees: 200
## No. of variables tried at each split: 2
## 
## OOB estimate of error rate: 18.49%
## Confusion matrix:
## Died Survived class.error
## Died 390 34 0.08018868
## Survived 98 192 0.33793103
```

---

# Results of a single tree


```r
randomForest::getTree(titanic_rf$finalModel, labelVar = TRUE)
```

```
## left daughter right daughter split var split point status prediction
## 1 2 3 Parch 0.50000 1 &amp;lt;NA&amp;gt;
## 2 4 5 Sexmale 0.50000 1 &amp;lt;NA&amp;gt;
## 3 6 7 SibSp 2.50000 1 &amp;lt;NA&amp;gt;
## 4 8 9 EmbarkedS 0.50000 1 &amp;lt;NA&amp;gt;
## 5 10 11 EmbarkedQ 0.50000 1 &amp;lt;NA&amp;gt;
## 6 12 13 Sexmale 0.50000 1 &amp;lt;NA&amp;gt;
## 7 14 15 SibSp 4.50000 1 &amp;lt;NA&amp;gt;
## 8 16 17 Age 22.50000 1 &amp;lt;NA&amp;gt;
## 9 18 19 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 10 20 21 Pclass 1.50000 1 &amp;lt;NA&amp;gt;
## 11 22 23 Age 30.00000 1 &amp;lt;NA&amp;gt;
## 12 24 25 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 13 26 27 Fare 23.41250 1 &amp;lt;NA&amp;gt;
## 14 28 29 Parch 1.50000 1 &amp;lt;NA&amp;gt;
## 15 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 16 30 31 EmbarkedQ 0.50000 1 &amp;lt;NA&amp;gt;
## 17 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 18 32 33 Age 37.00000 1 &amp;lt;NA&amp;gt;
## 19 34 35 Fare 7.70000 1 &amp;lt;NA&amp;gt;
## 20 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 21 36 37 Age 32.25000 1 &amp;lt;NA&amp;gt;
## 22 38 39 Fare 7.74585 1 &amp;lt;NA&amp;gt;
## 23 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 24 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 25 40 41 Fare 20.66250 1 &amp;lt;NA&amp;gt;
## 26 42 43 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 27 44 45 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 28 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 29 46 47 Sexmale 0.50000 1 &amp;lt;NA&amp;gt;
## 30 48 49 Age 17.50000 1 &amp;lt;NA&amp;gt;
## 31 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 32 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 33 50 51 SibSp 1.50000 1 &amp;lt;NA&amp;gt;
## 34 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 35 52 53 Age 25.50000 1 &amp;lt;NA&amp;gt;
## 36 54 55 EmbarkedC 0.50000 1 &amp;lt;NA&amp;gt;
## 37 56 57 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 38 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 39 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 40 58 59 SibSp 1.50000 1 &amp;lt;NA&amp;gt;
## 41 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 42 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 43 60 61 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 44 62 63 SibSp 1.50000 1 &amp;lt;NA&amp;gt;
## 45 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 46 64 65 Fare 31.33125 1 &amp;lt;NA&amp;gt;
## 47 66 67 Fare 31.33125 1 &amp;lt;NA&amp;gt;
## 48 68 69 Age 15.50000 1 &amp;lt;NA&amp;gt;
## 49 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 50 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 51 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 52 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 53 70 71 Age 38.00000 1 &amp;lt;NA&amp;gt;
## 54 72 73 SibSp 1.50000 1 &amp;lt;NA&amp;gt;
## 55 74 75 Age 29.50000 1 &amp;lt;NA&amp;gt;
## 56 76 77 EmbarkedC 0.50000 1 &amp;lt;NA&amp;gt;
## 57 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 58 78 79 EmbarkedS 0.50000 1 &amp;lt;NA&amp;gt;
## 59 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 60 80 81 Age 24.75000 1 &amp;lt;NA&amp;gt;
## 61 82 83 EmbarkedC 0.50000 1 &amp;lt;NA&amp;gt;
## 62 84 85 Parch 1.50000 1 &amp;lt;NA&amp;gt;
## 63 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 64 86 87 Age 14.00000 1 &amp;lt;NA&amp;gt;
## 65 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 66 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 67 88 89 Age 6.00000 1 &amp;lt;NA&amp;gt;
## 68 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 69 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 70 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 71 90 91 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 72 92 93 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 73 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 74 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 75 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 76 94 95 Pclass 2.50000 1 &amp;lt;NA&amp;gt;
## 77 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 78 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 79 96 97 Parch 1.50000 1 &amp;lt;NA&amp;gt;
## 80 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 81 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 82 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 83 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 84 98 99 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 85 100 101 EmbarkedS 0.50000 1 &amp;lt;NA&amp;gt;
## 86 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 87 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 88 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 89 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 90 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 91 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 92 102 103 Age 30.50000 1 &amp;lt;NA&amp;gt;
## 93 104 105 Age 30.75000 1 &amp;lt;NA&amp;gt;
## 94 106 107 Age 57.00000 1 &amp;lt;NA&amp;gt;
## 95 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 96 108 109 Age 27.50000 1 &amp;lt;NA&amp;gt;
## 97 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 98 110 111 EmbarkedC 0.50000 1 &amp;lt;NA&amp;gt;
## 99 112 113 Pclass 1.50000 1 &amp;lt;NA&amp;gt;
## 100 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 101 114 115 Pclass 1.50000 1 &amp;lt;NA&amp;gt;
## 102 116 117 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 103 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 104 118 119 SibSp 0.50000 1 &amp;lt;NA&amp;gt;
## 105 120 121 Fare 7.91040 1 &amp;lt;NA&amp;gt;
## 106 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 107 122 123 Age 64.00000 1 &amp;lt;NA&amp;gt;
## 108 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 109 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 110 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 111 124 125 Age 23.50000 1 &amp;lt;NA&amp;gt;
## 112 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 113 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 114 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 115 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 116 126 127 Age 21.00000 1 &amp;lt;NA&amp;gt;
## 117 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 118 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 119 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 120 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 121 128 129 Age 31.50000 1 &amp;lt;NA&amp;gt;
## 122 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 123 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 124 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 125 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 126 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 127 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
## 128 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Survived
## 129 0 0 &amp;lt;NA&amp;gt; 0.00000 -1 Died
```

---

# Variable importance

&amp;lt;img src="index_files/figure-html/rf_import-1.png" width="864" /&amp;gt;

---

# Exercise: depression and voting

.center[

![:scale 45%](https://i.pinimg.com/564x/24/81/96/24819625c9636fcfab5000a47811d93b--favorite-quotes-offices.jpg)

]

---

# Resampling methods

* Evaluating model fit/predictive power
* How to avoid overfitting the data

---

# Validation set

* Randomly split data into two distinct sets
 * Training set
 * Validation set
* Train model on training set
* Evaluate fit on validation set

---

# Regression



&amp;lt;img src="index_files/figure-html/auto_plot_lm-1.png" width="864" /&amp;gt;

---

# Mean squared error

`$$MSE = \frac{1}{n} \sum_{i = 1}^{n}{(y_i - \hat{f}(x_i))^2}$$`

* `\(y_i =\)` the observed response value for the `\(i\)`th observation
* `\(\hat{f}(x_i) =\)` the predicted response value for the `\(i\)`th observation given by `\(\hat{f}\)`
* `\(n =\)` the total number of observations

---

# Split data


```r
set.seed(1234)

auto_split &amp;lt;- initial_split(data = Auto, prop = 0.5)
auto_train &amp;lt;- training(auto_split)
auto_test &amp;lt;- testing(auto_split)

dim(Auto)
```

```
## [1] 392 9
```

```r
dim(auto_train)
```

```
## [1] 196 9
```

```r
dim(auto_test)
```

```
## [1] 196 9
```

---

# Train model


```r
auto_lm &amp;lt;- glm(mpg ~ horsepower, data = auto_train)
tidy(auto_lm)
```

```
## # A tibble: 2 × 5
## term estimate std.error statistic p.value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 39.2 1.00 39.2 3.49e-94
## 2 horsepower -0.150 0.00876 -17.2 9.57e-41
```


```r
(train_mse &amp;lt;- augment(auto_lm, newdata = auto_train) %&amp;gt;%
 mutate(.resid = mpg - .fitted,
 .resid2 = .resid ^ 2) %$%
 mean(.resid2))
```

```
## [1] 24.13599
```

---

# Validate model


```r
(test_mse &amp;lt;- augment(auto_lm, newdata = auto_test) %&amp;gt;%
 mutate(.resid = mpg - .fitted,
 .resid2 = .resid ^ 2) %$%
 mean(.resid2))
```

```
## [1] 23.93601
```

---

# Compare models



&amp;lt;img src="index_files/figure-html/mse-poly-1.png" width="864" /&amp;gt;

---

# Classification


```r
survive_age_woman_x &amp;lt;- glm(Survived ~ Age * Sex, data = titanic,
 family = binomial)
tidy(survive_age_woman_x)
```

```
## # A tibble: 4 × 5
## term estimate std.error statistic p.value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 0.594 0.310 1.91 0.0557 
## 2 Age 0.0197 0.0106 1.86 0.0624 
## 3 Sexmale -1.32 0.408 -3.23 0.00125
## 4 Age:Sexmale -0.0411 0.0136 -3.03 0.00241
```

---

# Test error rate


```r
# split the data into training and validation sets
titanic_split &amp;lt;- initial_split(data = titanic, prop = 0.5)

# fit model to training data
train_model &amp;lt;- glm(Survived ~ Age * Sex,
 data = training(titanic_split),
 family = binomial)

# calculate predictions using validation set
x_test_accuracy &amp;lt;- augment(train_model,
 newdata = testing(titanic_split),
 type.predict = "response") %&amp;gt;% 
 mutate(pred = as.numeric(.fitted &amp;gt; .5))

# calculate test error rate
mean(x_test_accuracy$Survived != x_test_accuracy$pred, na.rm = TRUE)
## [1] 0.2241379
```

---

# Drawbacks to validation sets

&amp;lt;img src="index_files/figure-html/auto_variable_mse-1.png" width="864" /&amp;gt;

---

# Leave-one-out cross-validation

`$$CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n}{MSE_i}$$`

* Extension of validation set to repeatedly split data and average results
* Minimizes bias of estimated error rate
* Low variance
* Highly computationally intensive

---

# `rsample::loo_cv()`


```r
loocv_data &amp;lt;- loo_cv(Auto)
loocv_data
```

```
## # Leave-one-out cross-validation 
## # A tibble: 392 × 2
## splits id 
## &amp;lt;list&amp;gt; &amp;lt;chr&amp;gt; 
## 1 &amp;lt;split [391/1]&amp;gt; Resample1 
## 2 &amp;lt;split [391/1]&amp;gt; Resample2 
## 3 &amp;lt;split [391/1]&amp;gt; Resample3 
## 4 &amp;lt;split [391/1]&amp;gt; Resample4 
## 5 &amp;lt;split [391/1]&amp;gt; Resample5 
## 6 &amp;lt;split [391/1]&amp;gt; Resample6 
## 7 &amp;lt;split [391/1]&amp;gt; Resample7 
## 8 &amp;lt;split [391/1]&amp;gt; Resample8 
## 9 &amp;lt;split [391/1]&amp;gt; Resample9 
## 10 &amp;lt;split [391/1]&amp;gt; Resample10
## # … with 382 more rows
```

---

# Splits


```r
first_resample &amp;lt;- loocv_data$splits[[1]]
first_resample
```

```
## &amp;lt;Analysis/Assess/Total&amp;gt;
## &amp;lt;391/1/392&amp;gt;
```

---

# Splits


```r
training(first_resample) %&amp;gt;% glimpse()
## Rows: 391
## Columns: 9
## $ mpg &amp;lt;dbl&amp;gt; 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2…
## $ cylinders &amp;lt;dbl&amp;gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, …
## $ displacement &amp;lt;dbl&amp;gt; 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…
## $ horsepower &amp;lt;dbl&amp;gt; 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…
## $ weight &amp;lt;dbl&amp;gt; 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385…
## $ acceleration &amp;lt;dbl&amp;gt; 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, …
## $ year &amp;lt;dbl&amp;gt; 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7…
## $ origin &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …
## $ name &amp;lt;fct&amp;gt; chevrolet chevelle malibu, buick skylark 320, plymouth sa…
assessment(first_resample) %&amp;gt;% glimpse()
## Rows: 1
## Columns: 9
## $ mpg &amp;lt;dbl&amp;gt; 35
## $ cylinders &amp;lt;dbl&amp;gt; 4
## $ displacement &amp;lt;dbl&amp;gt; 122
## $ horsepower &amp;lt;dbl&amp;gt; 88
## $ weight &amp;lt;dbl&amp;gt; 2500
## $ acceleration &amp;lt;dbl&amp;gt; 15.1
## $ year &amp;lt;dbl&amp;gt; 80
## $ origin &amp;lt;dbl&amp;gt; 2
## $ name &amp;lt;fct&amp;gt; triumph tr7 coupe
```

---

# Holdout results

1. Obtain the analysis data set (i.e. the `\(n-1\)` training set)
1. Fit a linear regression model
1. Predict the assessment data set using the `broom` package
1. Determine the MSE for each sample

--


```r
holdout_results &amp;lt;- function(splits) {
 # Fit the model to the n-1
 mod &amp;lt;- glm(mpg ~ horsepower, data = analysis(splits))
 
 # Save the heldout observation
 holdout &amp;lt;- assessment(splits)
 
 # `augment` will save the predictions with the holdout data set
 res &amp;lt;- augment(mod, newdata = holdout) %&amp;gt;%
 # calculate residuals for future use
 mutate(.resid = mpg - .fitted)
 
 # Return the assessment data set with the additional columns
 res
}
```

---

# Holdout results


```r
holdout_results(loocv_data$splits[[1]])
```

```
## # A tibble: 1 × 11
## mpg cylinders displacement horsepower weight acceleration year origin name 
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;
## 1 35 4 122 88 2500 15.1 80 2 triu…
## # … with 2 more variables: .fitted &amp;lt;dbl&amp;gt;, .resid &amp;lt;dbl&amp;gt;
```

---

# Holdout results


```r
loocv_data$results &amp;lt;- map(loocv_data$splits, holdout_results)
loocv_data$mse &amp;lt;- map_dbl(loocv_data$results, ~ mean(.x$.resid ^ 2))
loocv_data
```

```
## # Leave-one-out cross-validation 
## # A tibble: 392 × 4
## splits id results mse
## &amp;lt;list&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt; &amp;lt;dbl&amp;gt;
## 1 &amp;lt;split [391/1]&amp;gt; Resample1 &amp;lt;tibble [1 × 11]&amp;gt; 80.7 
## 2 &amp;lt;split [391/1]&amp;gt; Resample2 &amp;lt;tibble [1 × 11]&amp;gt; 2.53 
## 3 &amp;lt;split [391/1]&amp;gt; Resample3 &amp;lt;tibble [1 × 11]&amp;gt; 0.0275
## 4 &amp;lt;split [391/1]&amp;gt; Resample4 &amp;lt;tibble [1 × 11]&amp;gt; 4.56 
## 5 &amp;lt;split [391/1]&amp;gt; Resample5 &amp;lt;tibble [1 × 11]&amp;gt; 26.7 
## 6 &amp;lt;split [391/1]&amp;gt; Resample6 &amp;lt;tibble [1 × 11]&amp;gt; 63.0 
## 7 &amp;lt;split [391/1]&amp;gt; Resample7 &amp;lt;tibble [1 × 11]&amp;gt; 0.124 
## 8 &amp;lt;split [391/1]&amp;gt; Resample8 &amp;lt;tibble [1 × 11]&amp;gt; 19.8 
## 9 &amp;lt;split [391/1]&amp;gt; Resample9 &amp;lt;tibble [1 × 11]&amp;gt; 38.0 
## 10 &amp;lt;split [391/1]&amp;gt; Resample10 &amp;lt;tibble [1 × 11]&amp;gt; 67.1 
## # … with 382 more rows
```

---

# Holdout results


```r
loocv_data %&amp;gt;%
 summarize(mse = mean(mse))
```

```
## # A tibble: 1 × 1
## mse
## &amp;lt;dbl&amp;gt;
## 1 24.2
```

---

# Compare polynomial terms

&amp;lt;img src="index_files/figure-html/loocv_poly-1.png" width="864" /&amp;gt;

---

# LOOCV in classification


```r
# function to generate assessment statistics for titanic model
holdout_results &amp;lt;- function(splits) {
 # Fit the model to the n-1
 mod &amp;lt;- glm(Survived ~ Age * Sex, data = analysis(splits),
 family = binomial)
 
 # Save the heldout observation
 holdout &amp;lt;- assessment(splits)
 
 # `augment` will save the predictions with the holdout data set
 res &amp;lt;- augment(mod, newdata = assessment(splits),
 type.predict = "response") %&amp;gt;% 
 mutate(pred = as.numeric(.fitted &amp;gt; .5))

 # Return the assessment data set with the additional columns
 res
}
```

---

# LOOCV in classification


```r
titanic_loocv &amp;lt;- loo_cv(titanic) %&amp;gt;%
 mutate(results = map(splits, holdout_results),
 error_rate = map_dbl(results, ~ mean(.x$Survived != .x$pred,
 na.rm = TRUE)))
mean(titanic_loocv$error_rate, na.rm = TRUE)
```

```
## [1] 0.219888
```

---

# Exercise: LOOCV in linear regression

.center[

![](https://thealexcreed.files.wordpress.com/2014/05/liftbitch.jpg)

]

---

# `\(k\)`-fold cross-validation

`$$CV_{(k)} = \frac{1}{k} \sum_{i = 1}^{k}{MSE_i}$$`

* Split data into `\(k\)` folds
* Repeat training/test process for each fold
* LOOCV: `\(k=n\)`

---

# `\(K\)`-fold CV in linear regression



&amp;lt;img src="index_files/figure-html/10_fold_auto_loocv-1.png" width="864" /&amp;gt;

---

# Computational speed of LOOCV

&amp;lt;img src="index_files/figure-html/loocv-kfold-time-1.png" width="864" /&amp;gt;

---

# `\(K\)`-fold CV in logistic regression


```r
# function to generate assessment statistics for titanic model
holdout_results &amp;lt;- function(splits) {
 # Fit the model to the training set
 mod &amp;lt;- glm(Survived ~ Age * Sex, data = analysis(splits),
 family = binomial)
 
 # Save the heldout observations
 holdout &amp;lt;- assessment(splits)
 
 # `augment` will save the predictions with the holdout data set
 res &amp;lt;- augment(mod, newdata = assessment(splits),
 type.predict = "response") %&amp;gt;% 
 mutate(pred = as.numeric(.fitted &amp;gt; .5))

 # Return the assessment data set with the additional columns
 res
}
```

---

# `\(K\)`-fold CV in logistic regression


```r
titanic_cv10 &amp;lt;- vfold_cv(data = titanic, v = 10) %&amp;gt;%
 mutate(results = map(splits, holdout_results),
 error_rate = map_dbl(results, ~ mean(.x$Survived != .x$pred,
 na.rm = TRUE)))
mean(titanic_cv10$error_rate, na.rm = TRUE)
```

```
## [1] 0.2196609
```

---

# Exercise: `\(K\)`-fold CV

.center[

![](https://crossfitaggieland.com/wp-content/uploads/2015/01/pet4.jpeg)

]

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script src="https://cfss.uchicago.edu/slides/macros.js">&lt;/script>
&lt;script src="https://platform.twitter.com/widgets.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/text-analysis-classification-and-topic-modeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/text-analysis-classification-and-topic-modeling/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Text analysis: topic modeling and sentiment analysis&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Text analysis: &lt;br /> topic modeling and sentiment analysis
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






# Agenda
* Topic Modeling
 * LDA
* Sentiment Analysis
 * Positive / negative sentiment
* Application: TS!
* Future applications: 
 * Author prediction

---
class: inverse, middle

# Topic Modeling

---

# Topic Modeling

Method to organize and understand large collections of textual information (without reading them).

How? 
--
By **finding groups of words ("topics") that go together.** Words that co-occur more frequently that chance alone would predict are assigned to the same topic.

Example: organizing 1.2M books into 2000 topics see David Mimno [slides here](https://mimno.infosci.cornell.edu/slides/details.pdf) and [video here](https://vimeo.com/53080123). 

---

# Topic Modeling

**Word Frequency** looks at the exact recurrence of each word in a corpus (using a simple count or a weighted count).

Instead: 

**Topic Modeling** looks at how groups of words co-occur together (using probability).

--

Intuition: 

The meaning of words is dependent upon the broader context in which they are used. 

---

# Topic Modeling

A topic is a set of words that are associated with one another, showing an underlying common theme that is semantically interpretable by humans. 

A topic is similar to what a human would call a theme or a discourse: whenever a specific discourse is made, some words tend to come up more frequently than others. The goal of TM is to identify the discourses that characterize a collection of documents. 

---

# Topic Modeling

One way to think about how TM…

Imagine working through an article with a set of highlighters. As you read through the article:
 * you use a different color for the key words of themes within the article as you encounter them
 * when you were done, you could take all words of the same color and create separate lists (one per each topic)


---

# Topic Modeling

&amp;lt;img src="tm.png" width="90%" style="display: block; margin: auto;" /&amp;gt;

---

# Topic Modeling: LDA

TM is the name of a family of algorithms. The most common is **LDA or Latent Dirichlet Allocation**. This model assumes that:

1. every document in a corpus contains a mixture of topics that are found throughout the entire corpus

1. each topic is made of a (limited) mixture of characteristic words, which tend to occur together whenever the topic is displayed

The topic structure is hidden ("latent"): we can only observe the documents and words, not the topics themselves; the goal is to infer such topics by the words and documents (more formally: topic modeling computes the conditional posterior distribution of latent variables, e.g. topics, given the observed variables, e.g. words in documents).

---

# Topic Modeling: LDA

**LDA works as follows:**

1. The researcher begins by setting an arbitrary number of topics (`k`) for the whole collection of documents.

1. The algorithm (Gibbs sampling) creates, simultaneously:
 * a first randomly chosen word-topic probability: distribution of topics over all observed words in the collection
 * a first randomly chosen document-topic probability: distribution of topics by document 

1. Through reiterative attempts, the algorithm adjusts these initial distributions to provide a set of probabilities for every word-topic pair and for every document-topic pair. 

---

# Topic Modeling: LDA

**LDA produces two types of output:**

1. words most frequently associated with each of the `k` topics specified by the researcher 

1. documents most frequently associated with each of the `k` topics (the researcher defines a probability threshold)

---

# Topic Modeling: LDA simple example

We start with a simple example, then move to a real example in R. Imagine we have a corpus with the following five documents (each document is one sentence):

**Document 1** I ate a banana and spinach smoothie for breakfast.

**Document 2** I like to eat broccoli and bananas.

**Document 3** Puppies and kittens are cute.

**Document 4** My sister adopted a kitten yesterday.

**Document 5** This cute hamster is eating a piece of broccoli.

---

# Topic Modeling: LDA simple example

**First, we need to transform these textual data in the appropriate form needed for LDA:**
* input:
 * raw data
* output:
 * create a vocabulary (remove stop words, lowercase, tokenize, etc.)
 * create a document-term matrix

**Then, we run LDA:**
* input:
 * the document-term matrix as input
 * the number of topics we want to generate (we decide them)
* output:
 * the word-topic and document-topic probabilities

---

# Topic Modeling: LDA simple example

If we give to LDA the document-term matrix from these 5 documents, and we ask for 2 topics, LDA might produce something like: 

**Topic A:** 30% eat, 20% broccoli, 15% bananas, 10% breakfast, …

**Topic B:** 20% dog, 20% kitten, 20% cute, 15% hamster, …

--

**Document 1 and 2** 100% Topic A (we can label it "food")

**Document 3 and 4**: 100% Topic B (we can label it "cute animals")

**Document 5:** 60% Topic A, 40% Topic B

---

# Topic Modeling: LDA example in R

Download today's class materials to access the code. (`usethis::use_course("CFSS-MACSS/text-analysis-fundamentals-and-sentiment-analysis-and-tm")`) We have additional resources you can practice with as well!

**Examples from the book**: Chapter 6, and the three case-study chapters + Chapter 2 to reshape the data into the appropriate format for LDA


---
class: inverse, middle, center

![](https://media.giphy.com/media/tNTq5fw9apN2OzZID9/giphy.gif) 

---
# A thorough examination of Taylor Swift Lyrics 
--
Recall the following graphic: 
![visualization of textual analysis process](https://www.tidytextmining.com/images/tmwr_0101.png) 
--

We will move through this process using [this dataset of Taylor Swift albums and lyrics from Kaggle](https://www.kaggle.com/datasets/ishikajohari/taylor-swift-all-lyrics-30-albums?resource=download)

---
## Basic workflow for text analysis

We can think at the basic workflow as a 4-step process:

1. Obtain your textual data: **Kaggle, check!**

1. Data cleaning and pre-processing **OOF THIS WAS A PAIN** *see end of slides for more detail*

1. Data transformation **building on last class's materials**

1. Perform analysis **the fun part**


---
# Steps: Data cleaning and pre-processing 
(see: data/swift_data_raw) 
To find the data, I googled things like, 'taylor swift lyrics dataset' before finding the dataset on kaggle. I then spot-checked some of the albums and songs to be sure that things looked generally OK. (remember, once you use someone else's data, it becomes your problem!) 

I pulled all this in and tried to use specific code and packages that we've used in class as much as possible so you could see where the pieces came from. 

Without belaboring this too much, you can see in today's files where I have the raw data I imported and cleaned, and how I timmed out unwanted characteristics / elements, e.g. [Chorus]. 

---
# Steps: Data cleaning and pre-processing 
(see: data/swift_data_raw) 
Here is a snippet of what the raw structure was: `data &amp;gt; albums &amp;gt; 1989 &amp;gt; song.txt` 

--
Here is what the raw txt file looked like: 

```r
strwrap(read_lines(here("..", "text-analysis-fundamentals-and-sentiment-analysis-and-tm", "data", "swift_data_raw", "Albums", "1989", "BlankSpace.txt")), 80)
## [1] "237 ContributorsTranslationsTürkçeEspañolPortuguêsPolskiΕλληνικάFrançaisBlank"
## [2] "Space Lyrics[Verse 1]" 
## [3] "Nice to meet you, where you been?" 
## [4] "I could show you incredible things" 
## [5] "Magic, madness, heaven, sin" 
## [6] "Saw you there and I thought" 
## [7] "\"Oh, my God, look at that face" 
## [8] "You look like my next mistake" 
## [9] "Love's a game, wanna play?\" Ayy" 
## [10] "New money, suit and tie" 
## [11] "I can read you like a magazine" 
## [12] "Ain't it funny? Rumors fly" 
## [13] "And I know you heard about me" 
## [14] "So, hey, let's be friends" 
## [15] "I'm dying to see how this one ends" 
## [16] "Grab your passport and my hand" 
## [17] "I can make the bad guys good for a weekend" 
## [18] "[Chorus]" 
## [19] "So, it's gonna be forever" 
## [20] "Or it's gonna go down in flames?" 
## [21] "You can tell me when it's over, mm" 
## [22] "If the high was worth the pain" 
## [23] "Got a long list of ex-lovers" 
## [24] "They'll tell you I'm insane" 
## [25] "'Cause you know I love the players" 
## [26] "And you love the game" 
## [27] "'Cause we're young and we're reckless" 
## [28] "We'll take this way too far" 
## [29] "It'll leave you breathless, mm" 
## [30] "Or with a nasty scar" 
## [31] "Got a long list of ex-lovers" 
## [32] "They'll tell you I'm insane" 
## [33] "But I've got a blank space, baby" 
## [34] "And I'll write your name" 
## [35] "" 
## [36] "[Verse 2]" 
## [37] "Cherry lips, crystal skies" 
## [38] "I could show you incredible things" 
## [39] "Stolen kisses, pretty lies" 
## [40] "You're the king, baby, I'm your queen" 
## [41] "Find out what you want" 
## [42] "Be that girl for a month" 
## [43] "Wait, the worst is yet to come, oh, no" 
## [44] "Screaming, crying, perfect storms" 
## [45] "I can make all the tables turn" 
## [46] "Rose garden filled with thorns" 
## [47] "Keep you second guessing, like" 
## [48] "\"Oh, my God, who is she?\"" 
## [49] "I get drunk on jealousy" 
## [50] "But you'll come back each time you leave" 
## [51] "'Cause, darling, I'm a nightmare dressed like a daydream" 
## [52] "You might also like[Chorus]" 
## [53] "So, it's gonna be forever" 
## [54] "Or it's gonna go down in flames?" 
## [55] "You can tell me when it's over, mm" 
## [56] "If the high was worth the pain" 
## [57] "Got a long list of ex-lovers" 
## [58] "They'll tell you I'm insane" 
## [59] "'Cause you know I love the players" 
## [60] "And you love the game" 
## [61] "'Cause we're young and we're reckless (Oh)" 
## [62] "We'll take this way too far" 
## [63] "It'll leave you breathless (Oh-oh), mm" 
## [64] "Or with a nasty scar" 
## [65] "Got a long list of ex-lovers" 
## [66] "They'll tell you I'm insane (Insane)" 
## [67] "But I've got a blank space, baby" 
## [68] "And I'll write your name" 
## [69] "" 
## [70] "[Bridge]" 
## [71] "Boys only want love if it's torture" 
## [72] "Don't say I didn't, say I didn't warn ya" 
## [73] "Boys only want love if it's torture" 
## [74] "Don't say I didn't, say I didn't warn ya" 
## [75] "" 
## [76] "[Chorus]" 
## [77] "So, it's gonna be forever" 
## [78] "Or it's gonna go down in flames?" 
## [79] "You can tell me when it's over (Over), mm" 
## [80] "If the high was worth the pain" 
## [81] "Got a long list of ex-lovers" 
## [82] "They'll tell you I'm insane (I'm insane)" 
## [83] "'Cause you know I love the players" 
## [84] "And you love the game (And you love the game)" 
## [85] "'Cause we're young and we're reckless (Yeah)" 
## [86] "We'll take this way too far (Ooh)" 
## [87] "It'll leave you breathless, mm" 
## [88] "Or with a nasty scar (With a nasty scar)" 
## [89] "Got a long list of ex-lovers" 
## [90] "They'll tell you I'm insane" 
## [91] "But I've got a blank space, baby" 
## [92] "And I'll write your name1KEmbed"
```
---
# Steps: Cleaning (see: data/swift_data_raw)
Obviously, there's a lot of work that was needed here. I did a rough clean -- for publication, I would probably do another pass or two and do some more spot checks. (I like to use a random number generator to select a row of my dataframe to verify that everything is good / looks OK). 

--

**Steps**:
1. Generate list of file paths (note I had to loop through albums to get songs). (HW05 was helpful for this)
1. Extract album title
 * Get title from path string
 * Add spaces back in where needed
1. Extract song title from file path
 * Get title from path string
 * Add spaces back in where needed
1. Read in data:
 * Read lines from path
 * Remove the top line
 * Get rid of any chunks about song structure
1. Merge data (Album, Song, Lyrics) and export as data frame



---
# Steps: Data transformation

* Remove stop words (sort of interesting, what do you do about songs like, 'the 1'?). 
* Perform analysis on entire corpus and by album: 
 * Frequency of words (histogram and wordcloud)
 * Sentiment of words (positive / negative)
 * Emotional score for text and albums
* Consider future steps: "eras" and "eras tour"??? 


---
# Steps: Perform analysis on entire corpus vs albums
For this, we want to explore the most common words used by Taylor Swift overall. We can then consider how we might want to break things out in future anlaysis. *(Note, this was a rough clean, so we have some words that don't fully make sense in here).*
--
.panelset[
.panel[.panel-name[Overall Analysis]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_frequent_words.png" alt="Histogram of most frequent words in Taylor Swift songs" width="30%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of most frequent words in Taylor Swift songs&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Wordcloud]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_wordcloud.png" alt="Wordcloud of most frequent tokens in Taylor Swift songs" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Wordcloud of most frequent tokens in Taylor Swift songs&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Wordcloud: Pos/Neg]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_wordcloud_pos_neg.png" alt="Most frequent Positive (dark gray) and Negative (light gray) tokens in Taylor Swift Lyrics" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Most frequent Positive (dark gray) and Negative (light gray) tokens in Taylor Swift Lyrics&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Analysis by Album]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_frequent_words_album.png" alt="Histogram of most frequent words in Taylor Swift songs by album" width="50%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of most frequent words in Taylor Swift songs by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
]

---
# Steps: Visualizations (Wordcloud)
Here, we can explore the word cloud generated from the text. THESE ARE NOT FOR ANALYSIS. YES THEY ARE COOL. NO THEY ARE NOT ANALYSIS!!!
--
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_wordcloud.png" alt="Word cloud of popular tokens" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Word cloud of popular tokens&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

---
## Trajectory: Thinking about word use

&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_frequent_words_album.png" alt="Histogram of most frequent words in Taylor Swift songs by album" width="70%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of most frequent words in Taylor Swift songs by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
Across each album, we can get a sense of a trajectory: time and love seem to feature in quite frequently, while we see a shift from 'girl' in her early albums to 'woman' in later ones. We can dig into this a bit more deeply as we look at the sentiment of the words. 



---
## Trajectory: Thinking about word use (tf-idf) 
When calculating tf-idf, we're looking for words that are more common relative to the rest of the corpus. We can think of this as an 'album signature' in our case. Here, we can see that we get a collection of different words than when we just look at the most frequent words. 

&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_idf_words.png" alt="Histogram of most frequent words in Taylor Swift songs by album" width="70%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of most frequent words in Taylor Swift songs by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
Across each album, we can get a sense of a trajectory: time and love seem to feature in quite frequently, while we see a shift from 'girl' in her early albums to 'woman' in later ones. We can dig into this a bit more deeply as we look at the sentiment of the words. 

---
# (reminder / review) LDA: TOPICS
LDA (Laten Dirichlet Allocation) is one method for fitting a topic model. It offers a means of *unsupervised* classification of a collection of documents. (I think of it as you dump a bunch of items into a pile and it sorts them for you based on patterns it finds...although the same item could appear in multiple piles). 

Small / simple example: suppose you have a list of a bunch of animals that you want grouped. You give it the following: dog, cat, parakeet, tiger, polar bear, lion, penguin. If you tell the model you want three topics, it might provide the following groups:

* Topic 1: Dog, cat, parakeet
* Topic 2: Parakeet, penguin, polar bear
* Topic 3: Cat, tiger, lion

--
It's up to you, the researcher, to determine what meaning or value lies within these topics / allocations. You may also determine how many topics you would like (more topics can mean a slower model). If you had said two topics, you might have gotten the following instead: 

* Topic 1: Dog, cat, parakeet
* Topic 2: Penguin, polar bear, tiger, lion

Notice that the 'sense' you make of the topics might be different in the two situations. 

---
# LDA: Two topic model
Let's start with a simple two-topic model (we'll get more complicated soon!)
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_frequent_words_topics.png" alt="Frequent words in a two-topic model" width="50%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Frequent words in a two-topic model&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

--
We can think about what we might 'call' these topics and how we might want to explore this further. (Again, note this is unsupervised!)

---
# LDA: understanding the right number of topics
Let's try that again, but now with different numbers of topics. I have a visualization that is a little different from the text because I felt like it helped visualize the results better. We could do boxplots, but those were a bit messy for this particular dataset. 

--

.panelset[
.panel[.panel-name[Two topics]

&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_2topics.png" alt="Text plot of songs, colored by albums (two topics)" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Text plot of songs, colored by albums (two topics)&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Three topics]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_3topics.png" alt="Text plot of songs, colored by albums (three topics)" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Text plot of songs, colored by albums (three topics)&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Ten topics!]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_10topics.png" alt="Text plot of songs, colored by albums (ten topics)" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Text plot of songs, colored by albums (ten topics)&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
]

---

# Reflection: 


I think two topics makes sense here, of our options. However, I would be interested in pooling albums and reassessing to see. Alternatively, we might want to think about other ways to explore the meaning / distinctions. 


---

# Topic modeling: pros/cons

* Topic models **account for "multiplexity":** a given document is unlikely to fall precisely and fully into a single topic 

* Topic models **do not care about the order of words** “dog eats food" is the same as "food eats dog" 

* To determine the "right" number of topics: no fixed rule, it is a try-error process, ultimately **the researcher decides** (there are some metrics, such as perplexity and coherence score but are beyond our goals)

* Topics are **unlabeled:** they are just a bunch of words, it is up to the researcher to read, interpret, and label them

* Topic models are **no substitute for human interpretation of a text:** they are a way of making educated guesses about how words cohere into different latent themes by identifying patterns in the way they co-occur within documents. Many people are somewhat disappointed when they discover their model produces uninformative results

---

# LDAvis

LDAvis is a an interactive visualization of LDA model results

https://github.com/cpsievert/LDAvis


1. What is the meaning of each topic?
1. How prevalent is each topic?
1. How do the topics relate to each other?

---

class: inverse, middle

# Sentiment Analysis

---

# Sentiment Analysis

Use of NLP and programming to **study emotional states and subjective information in a text**. 

In practice sentiment analysis is usually applied:
* to determine the polarity of a text: whether a text is positive, negative, or neutral
* to detect specific feelings and emotions: angry, sad, happy, etc.
* examples: analyzing costumer feedback, classify movies review

Different from Topic Modeling, Sentiment Analysis it is usually supervised (e.g., needs a labeled input to compare our text to)

---

# Sentiment Analysis: our approach

Our approach to sentiment analysis (consistent with the book, Chapter 2): 

* consider the text a combination of its individual words, and 
* consider the sentiment content of the text as the sum of the sentiment content of the individual words

Notice: "This isn’t the only way to approach sentiment analysis, but it is an often-used approach, and an approach that naturally takes advantage of the tidy tool ecosystem."

---

# The `sentiments` datasets 

The tidytext package provides access to several sentiment lexicons:

+ **AFINN** from Finn Årup Nielsen (words classified with on a scale from -5 to +5)
+ **bing** from Bing Liu and collaborators (words classified into binary categories: negative and positive)
+ **nrc** from Saif Mohammad and Peter Turney (words classified in multiple categories)

See: https://www.tidytextmining.com/sentiment.html#the-sentiments-datasets

---

# The `sentiments` datasets

These dictionaries constitute our gold standard (e.g., our labeled sentiments): we use them to classify our texts.

Dictionary-based methods like these find the total sentiment of a piece of text by adding up the individual sentiment scores for each word in the text.

---

# Sentiment Analysis: Examples

**Examples from the book**: Chapter 2, and the three case-study chapters

**Another example (in today's class-materials)**: sentiment analysis of Harry Potter textual data. 

**Another example (in today's class-materials)**: sentiment analysis of Taylor Swift albums

---
class: middle, inverse, center

# Back to TS
![](https://media.giphy.com/media/u23zXEvNsIbfO/giphy.gif)


---
# Steps: Analysis -- Sentiment
Here, we can look at the sentiment within her work: specifically, what are the positive and negative words used, both overall and by album? 

--
.panelset[
.panel[.panel-name[Overall Analysis]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_sentiment.png" alt="Histogram of positive and negative sentiment in Taylor Swift songs" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of positive and negative sentiment in Taylor Swift songs&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Analysis by Album: Positive]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_positive_words_album.png" alt="Histogram of positive sentiment in Taylor Swift songs by album" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of positive sentiment in Taylor Swift songs by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Analysis by Album: Negative]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_negative_words_album.png" alt="Histogram of negative sentiment in Taylor Swift songs by album" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of negative sentiment in Taylor Swift songs by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
]


---
# Steps: Analysis (Negative Sentiment)
Again, here some expertise / background on Taylor Swift can be helpful to make sense of our analysis. We can see that her early work has less 'intense' (generally) language and the negative sentiment features words like, 'crazy,' 'sad,' and 'bad'. With Reputation, we see a shift (this makes sense given the album and its role in her discography). Here, we see words like 'hate' come in and, as we move into more recent albums, words like 'death,' 'shit,' 'kill.' 

&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_negative_words_album.png" alt="Histogram of negative words by album" width="45%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of negative words by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

# Steps: Analysis (Negative Sentiment)
With positive words, we see a lot of consistency ('like') and while there are some more 'innocent' words appearing with more frequency in earlier albums, we don't see as much change / evolution as we did with the negative words. If anything, the language has gotten more direct in the later work (which, particularly thinking about 1989 and Midnights, makes sense). 

--
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_positive_words_album.png" alt="Histogram of postive words used by album" width="45%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of postive words used by album&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;


---
# Steps: Visualizations

--
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ts_sentiment_album.png" alt="Emotional arc of TS albums" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Emotional arc of TS albums&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

---
class: inverse, middle, center

![](https://media.giphy.com/media/ej1WNA2G75DfUai7NR/giphy.gif)

---
# Recap: 

* There are methods for analyzing text and getting a sense of the common ideas and topics that emerge
* Unsupervised (easier), supervised (need training data of some kind) can provide techniques to offer deeper insights
* Sentiment analysis looks at overall valence of words
* Lots of room for researcher to interpret: can be difficult to do well and needs some expertise to evaluate. 

---
# Acknowledgements

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. I developed the Taylor Swift example using data from [Kaggle](https://www.kaggle.com/datasets/ishikajohari/taylor-swift-all-lyrics-30-albums/versions/12?resource=download) and building on code from [Text Mining in R](https://www.tidytextmining.com/). Any errors or oversights are mine alone.


---
class: middle, center, inverse

# THANK YOU ALL FOR A GREAT CLASS! I have genuinely enjoyed getting to know you and your work and hope you keep in touch regarding how you use R in the future!

We have one assignment remaining. Have a great rest of your summer!

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/text-analysis-fundamentals-and-sentiment-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/text-analysis-fundamentals-and-sentiment-analysis/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Text analysis: fundamentals&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Text analysis: fundamentals
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






# Agenda

* Regular Expressions
 * basic understanding of how it workds
 * intro to stringr package 
* Workflow for text analysis 
 * Three examples:
 * Emily Dickinson (basic process with small example)
 * Jane Austen (more complex example with some analysis)
 * Billboard hot 100: merging data, answering quesitons, building workflow

---
class: inverse, middle

# Regular Expressions


---

### What are regular expressions? Why are they for?

We use them to manipulate character data, aka strings. 

Regular Expressions or regexes (singular regex): **language for pattern matching**. They are strings containing normal characters and special meta-characters that describe a particular pattern that we want to match in a given text.

Regular Expressions are used:

* in **many programming languages**
* for **any task that deals with text:** NLP or data-cleaning tasks (e.g., find words that include a given set of letters, how often do past tenses occur in a text, find emails or phone numbers, find and replace left over HTML tags from scraping, etc.).

&amp;lt;!--
Given our ability to manipulate strings and our ability to test for equivalence (==) or test whether some string contains another (in), we don't technically need special functions for pattern matching (e.g. regular expressions). That said, it becomes very tedious very quickly if we have to write all our pattern-matching code ourselves
--&amp;gt;


---
# Regex: how we match

* **Anchors**: match a position before or after other characters
* **Types**: matching types of characters
* **Classes**: ranges or sets of characters
* **Quantifiers**: specify how it matches
 * **Repetition**: matching more than a single instance
 * **Patterns and backreferences**: can name and extract specific chunks
* **Lookahead**: specify that certain elements must appear before your chunk (regardless of whether it appears within it)
* **Literal matches and modifiers**: you can specify particular matches (e.g. case)
* **Unicode**: particularly useful if you're working with other languages

---
# Regex: lazy vs greedy

Examples of Lazy or Non-Greedy quantifiers are `??`, `*?`, `+?`, and `{}?`:

* They match as few characters as possible, and stop at the first recurrence of a character (e.g., the regex moves forward through the string one character at a time, and stops at the first match)
* Example: the regex `a+?` will match as few "a" as possible in the string "aaaa". Thus, it matches the first character "a" and is done with it

---

### Regex examples

Examples: download today's in-class materials from the website: `usethis::use_course("CFSS-MACSS/text-analysis-fundamentals")`

Resources:
* [stringr cheat sheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf) for a complete overview of all `stringr` functions
* [Chapter 14 "Strings" of R for Data Science](https://r4ds.had.co.nz/strings.html#strings), especially section 14.4 "Tools" for examples of each of these functions
* [Regular expressions cheat sheet](https://www.datacamp.com/cheat-sheet/regular-expresso)
* [Excellent (but a bit complex) tutorial](https://github.com/ziishaned/learn-regex/blob/master/README.md)

---

### The `stringr()` package in R

When you use regular expressions for your analysis, most likely you will need to use your regular expression together with one of the functions from the `stringr()` package. 

This package includes several functions that let you: detect matches in a string, count the number of matches, extract them. replace them with other values, or split a string based on a match. 

---

### The `stringr()` package in R

Fundamental `stringr()` functions:

`str_detect()`: detect matches in a string
`str_count()`: count the number of matches
`str_extract()` and `str_extract_all()`: extract matches
`str_replace()` and `str_replace_all()`: replace matches
`str_split()`: split a string based on a match

Key resources:
* [Chapter 14 "Strings" of R for Data Science](https://r4ds.had.co.nz/strings.html#strings), especially section 14 for examples of each of these functions
* [Cheat sheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)

---

class: inverse, middle

# Basic workflow for text analysis

---

## Basic workflow for text analysis

We can think at the basic workflow as a 4-step process:

1. Obtain your textual data

1. Data cleaning and pre-processing 

1. Data transformation

1. Perform analysis

Let's review each step...

---
class: inverse, middle

![visualization of textual analysis process](https://www.tidytextmining.com/images/tmwr_0101.png)

*Source: [Text Mining with R](https://www.tidytextmining.com/tidytext.html#the-unnest_tokens-function)*
---

## 1. Obtain your textual data

**Common data sources for text analysis:**

* Online (Scraping and/or APIs)
* Databases
* PDF documents
* Digital scans of printed materials

---

## 1. Obtain your textual data

**Corpus and document:**

* Textual data are usually referred to as **corpus**: general term to refer to a collection of texts, stored as raw strings (e.g., a set of articles from the NYT, novels by an author, one or multiple books, etc.)

* Each corpus might have separate articles, chapters, pages, or even paragraphs. Each individual unit is called a **document**. You decide what constitutes a document in your corpus. 

---

## 2. Data cleaning and pre-processing

**Standard cleaning and pre-processing tasks:**

* Tokenize the text (to n-grams)
* Convert to lower case
* Remove punctuation and numbers
* Remove stopwords (standard and custom/domain-specific)
* Remove or replace other unwanted tokens
* Stemming or Lemmatization 

---

## 2. Data cleaning and pre-processing

**Tokenize the text (to n-grams) mean splitting your text into single tokens**. 

**Token:** word, alphanumeric character, !, ?, number, emoticon etc.

Most tokenizers split on white spaces, but they need also consider exceptions such as contractions (I'll, dog's), hyphens in or between words (e-mail, co-operate, take-it-or-leave, 30-year-old).

**N-gram:** a contiguous sequence of n items from a given text (items can be syllables, letters, words, etc.). We usually keep unigrams (the single word), but there instances in which bigrams are helpful: for example "Joe Biden" is a bi-gram. 
---

## 2. Data cleaning and pre-processing

**Remove stopwords** (standard and custom/domain-specific) 
* Examples: the, is, are, a, an, in, etc.
* Why we want to remove them? 
* Example: if you are working on a corpus that talks about "President Biden" you might want to add "Biden" among your stop words

---

## 2. Data cleaning and pre-processing

**Stemming** and **lemmatization** are similar in that both aim at simplifying words (aka tokens) to their base form but they do it differently. Why do we want to do it?

--

**Stemming:** reducing a token to its **root stem** by brutally removing parts from them 
* Examples: dogs become dog, walked becomes walk
* Faster, but not always accurate. Example: caring becomes car, changing becomes chang, better becomes bett

**Lemmatization:** reducing a token to its **root lemma** by using their meaning, so the token is converted to the concept that it represents
* Examples: dogs become dog, walked becomes walk, 
* Slower, but more accurate. Example: caring becomes care, changing becomes change, better becomes good

---

## 2. Data cleaning and pre-processing

More advanced pre-processing tasks (only applied to specific analyses):

* POS or Part-Of-Speech tagging (nouns, verbs, adjectives, etc.) 
* NER or Named Entity Recognition tagging (person, place, company, etc.)
* Parsing

---

## 3. Data transformation

Transformation means *converting the text into numbers*, e.g. some sort of quantifiable measure that a computer can process.

Usually you want to transform your raw textual data (your document) into a vector of countable units:

* Bag-of-words model: creates a document-term matrix (one row for each document, and one column for each term)
* Word embedding models

---

## 4. Perform analysis

We will learn the following:

* Basic exploratory analysis
 * Word frequency
 * TF-IDF (weighted version of word frequency)
 * Correlations
 
* More Advanced
 * Sentiment analysis
 * Topic modeling

---
# Motivating example 1: Emily Dickinson

We can think at the basic workflow as a 4-step process:

1. Obtain your textual data: *Emily Dickinson's could not stop for Death*

1. Data cleaning and pre-processing *(simple)*

1. Data transformation *transform one token per row* [see next slides!]

1. Perform analysis *basic histogram*

---
class: inverse, middle

# WARNING: GRAPHICS ARE NOT NICELY FORMATTED!!
*do as I say, not as I do!*

---
## Analysis: what does this mean?

&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/ex_plums.png" alt="Histogram of text from exercise 1" width="60%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of text from exercise 1&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

---

class: inverse, middle

# Text analysis with R tidyverse 


---

### The tidy text format

There are different ways to complete all steps in R, and different packages have their own approach. We learn how to perform these operations within the tidyverse. 

For the data cleaning and pre-processing step: we start by converting text into a tidy format, which follows the same principle of tidy analysis we have learned so far.


---

### The tidy text format

A tidy text format is defined as **a table with one-token-per-row** (this is different from the document-term matrix, which has one-document-per-row and one-term-per-column).

Steps:

* take your text
* put into a tibble
* convert into the tidy text format using `unnest_tokens()` 
 * punctuation is automatically removed
 * lower case is automatically applied

See [`tidytext`](https://github.com/juliasilge/tidytext) for more info

---
## Example 2: Jane Austen example (more complex)

We're going to move onto our next example, using Jane Austen's novels. Now that we have a lot more text to work with, we need to do a bit more cleaning. 
--
Recall the following graphic:
![visualization of textual analysis process](https://www.tidytextmining.com/images/tmwr_0101.png)


---
## Example 2: Jane Austen example (more complex)

Now, if we were to follow and replicate what we did in example one, we'd end up with this:

--
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/austen_no_stop.png" alt="Histogram of text containing stop words" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of text containing stop words&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;

---
## Tidy text: Stop words

Whoops! Without further cleaning, the elimination of "stop words," we aren't going to have much insightful to say. 

## **HOW TO ELIMINATE STOP WORDS?** 
--
We have a dataset of stop words we can use, but how?!


```r
library(tidytext)
data(stop_words)
head(stop_words)
```

```
## # A tibble: 6 × 2
## word lexicon
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 a SMART 
## 2 a's SMART 
## 3 able SMART 
## 4 about SMART 
## 5 above SMART 
## 6 according SMART
```

--
ANTI JOIN!!!


---
### Removing stop words with an anti join

```r
# remove stop words with anti_join()
data(stop_words)
tidy_books &amp;lt;- tidy_books %&amp;gt;%
 anti_join(stop_words)
```

--
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/austen.png" alt="Histogram of text containing stop wordws" width="40%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;Histogram of text containing stop wordws&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
---
# COOL!! NOW WHAT?!!!

Once you have your data, you can start looking at the text to get a sense of what's there, what isn't there, and then can move into multiple future directions:

* What words are and are not there (ex: authorship of Federalist documents)
* What words are connected to one another and are not (ex: Garkov) 
--
* What ideas / themes ... **TOPICS** come up
* The overall feelings (**SENTIMENT**) in the text

---
## Example: building on this (next steps)

.panelset[
.panel[.panel-name[Plot of books]
&amp;lt;div class="figure" style="text-align: center"&amp;gt;
&amp;lt;img src="../../img/austen_bybook.png" alt="By book analysis from Austen" width="60%" /&amp;gt;
&amp;lt;p class="caption"&amp;gt;By book analysis from Austen&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
]
.panel[.panel-name[Table of Books]

|book |word | n| tf| idf| tf_idf|
|:-------------------|:---------|---:|---------:|--------:|---------:|
|Sense &amp;amp; Sensibility |elinor | 623| 0.0051935| 1.791759| 0.0093056|
|Sense &amp;amp; Sensibility |marianne | 492| 0.0041015| 1.791759| 0.0073488|
|Mansfield Park |crawford | 493| 0.0030724| 1.791759| 0.0055050|
|Pride &amp;amp; Prejudice |darcy | 373| 0.0030523| 1.791759| 0.0054689|
|Persuasion |elliot | 254| 0.0030362| 1.791759| 0.0054401|
|Emma |emma | 786| 0.0048821| 1.098612| 0.0053635|
|Northanger Abbey |tilney | 196| 0.0025199| 1.791759| 0.0045151|
|Emma |weston | 389| 0.0024162| 1.791759| 0.0043293|
|Pride &amp;amp; Prejudice |bennet | 294| 0.0024058| 1.791759| 0.0043106|
|Persuasion |wentworth | 191| 0.0022831| 1.791759| 0.0040908|
]
]

---
# TIME TO FLY FREE! Example 3
In groups: work through the example below and see what you learn. 

**Example 3:** How often is each U.S. state mentioned in a popular song? We’ll define popular songs as those in Billboard’s Year-End Hot 100 from 1958 to the present. Data from Billboard Year-End Hot 100 (1958-present) and the Census Bureau ACS

---
### Recap: The tidy text format

Examples of basic exploratory text analysis using R tidyverse.
These examples all in your in-class materials for today and might be useful for your HW08.

**Example 1:** from book "1.2 Emily Dickinson example"

**Example 2:** from the book "1.3 Jane Austen example"

**Example 3:** How often is each U.S. state mentioned in a popular song? We’ll define popular songs as those in Billboard’s Year-End Hot 100 from 1958 to the present. Data from Billboard Year-End Hot 100 (1958-present) and the Census Bureau ACS

**More examples available** in the assigned readings and suggested resources 

---
# Recap

* Regex: how we can deal with text. Need this to find particular terms, have a basic understanding of text. 

* Workflow: multiple steps -- need to start thinking about the process and the complexity of your text can be crucial for your success. 

---
## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/vectors-and-iteration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/vectors-and-iteration/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Control Structures&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Control Structures
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Overview of control structures in R 

&amp;lt;!-- dropped from here vectors and lists, moved them to the data structure lecture 
added here conditional statements and more on iteration --&amp;gt;

---

## Control Structures in R

All programs we have written so far can be seen as a finite and fixed sequence of commands.

**Control structures** allow us to vary our commands by controlling their flow of execution. How? by adding some “logic” into our R code, rather than executing the same R code every time.

---

## Control Structures in R

The main control structures are:

* **`if... else` statements**: test one or more condition(s) and act on it/them
* **`for` loop**: execute a loop a fixed number of times
* **`while` loop**: execute a loop while a condition is true

See Chapter 13 “Control Structures” in *R programming for Data Science* and Chapter 21 “Iteration” in *R for Data Science* for more in-depth info.

---

class: inverse, middle

# Conditional Statements: if... else

---

### If-else 

If-else tests a condition and act on it depending on whether the condition is TRUE or FALSE.

.small[
Syntax:
```
if (condition to be evaluated) {
 action performed when condition is TRUE
} 
else {
 action performed when condition is FALSE
}
```

Example:

```r
age &amp;lt;- 14
if (age &amp;gt; 16) {
 print("You are elegible to get a driving license")
} else {
 print("You cannot drive")
}
```

```
## [1] "You cannot drive"
```
]

&amp;lt;!-- available options for size in descending order are:
Huge &amp;gt; huge &amp;gt; LARGE &amp;gt; Large &amp;gt; large &amp;gt; normalsize &amp;gt; small &amp;gt; footnotesize &amp;gt; scriptsize &amp;gt; tiny --&amp;gt;

---

### If-else 

Example: What is the output of this code?

```r
y &amp;lt;- 10
if (y &amp;lt; 20) {
 x &amp;lt;- "Too low" 
} else {
 x &amp;lt;- "Too high"
}
```

--


```
## [1] "Too low"
```

---

### If-else 

Example: What is the output of this code?

```r
my_numbers &amp;lt;- c(3,4,5,"6",7)

if (!is.numeric(my_numbers)) {
 print("At least one argument is not numeric. Only provide numbers.")
} else {
 print("All numeric elements")
}
```

--


```
## [1] "At least one argument is not numeric. Only provide numbers."
```


---

### If, else if, else

We can expand the basic if-else structure to incorporate multiple tests using **`else if`**


Syntax:
```
if (condition 1) {
 action 1 performed when condition 1 is TRUE
} 
else if (condition 2) { 
 action 2 performed when condition 2 is TRUE
}
else {
 action performed when condition 2 is FALSE
}
```

---

### If, else if, else

Example:

```r
x &amp;lt;- 0

# check if x is positive, negative, or zero
if (x &amp;gt; 0) {
 print("x is a positive number")
} else if (x &amp;lt; 0) {
 print("x is a negative number")
} else {
 print("x is zero")
}
```

```
## [1] "x is zero"
```

---

### Nested if-else

We can also write nested if-else statement to specify **conditions inside conditions**

.small[

```r
x &amp;lt;- 15

# check if x is positive
if (x &amp;gt; 0) {
 if (x %% 2 == 0) { # execute only if x is positive: check if x is even or odd with %%
 print("x is a positive even number")
 } else {
 print("x is a positive odd number")
 }
 
# execute only if x is not positive
} else {
 if (x %% 2 == 0) {
 print("x is a negative even number")
 } else {
 print("x is a negative odd number")
 }
}
```

```
## [1] "x is a positive odd number"
```
]

&amp;lt;!-- modulo is the reminder after dividing one number by another. Here 15 : 2 = 7, but 1 is the reminder, thus the number is odd --&amp;gt;

---

### ifelse()

R accepts `if()` and `else()` statements, but also statements using the built-in **`ifelse()`** 

.small[
Syntax:
```
ifelse (condition to be evaluated,
 action performed when condition is TRUE,
 action performed when condition is FALSE)
}
```

Example:

```r
y &amp;lt;- 3
ifelse(sqrt(16) &amp;gt; y, 
 sqrt(16),
 0)
```

```
## [1] 4
```
] 

Notice, there is also a `dplyr` version of `ifelse()`, called `if_else()`: [see documentation here](https://dplyr.tidyverse.org/reference/if_else.html)

---

### ifelse()

Example: What is the output of this code?

```r
numbers &amp;lt;- c(10, 6, 7)
ifelse(numbers %% 2 == 1, 
 "odd",
 "even")
```

--

```
## [1] "even" "even" "odd"
```

Our input is a vector, not a single number, thus the code will evaluate each element of the vector. 

Notice the `%%` operator outputs the remainder from a division (e.g., 7 : 2 = 3 with remainder 1, thus the number is odd).

---

### ifelse()

Example: What is the output of this code?

```r
qualify &amp;lt;- data.frame("Athlet" = c("Noah", "Julio", "Nick", "Maria"), 
 "Scores" = c(32, 37, 28, 30))

ifelse(qualify$"Scores" &amp;gt; 30, "Admitted", "Rejected")
```

--
Example: What is the output of this code?

```
## [1] "Admitted" "Admitted" "Rejected" "Rejected"
```



&amp;lt;!--
More on this:
https://docs.ycrc.yale.edu/r-novice-gapminder/07-control-flow/
Comparing ifelse() and for loop:
https://www.r-bloggers.com/2020/02/if-else-and-ifelse/
--&amp;gt;

---

class: inverse, middle

# Practice writing if... else statements

---
Practice Qs:


```r
ifelse(sqrt(9)&amp;lt;2,sqrt(9),0)
```


```r
x=12
if(is.numeric(x)) y=x*2
```


```r
x=letters[20]
if (is.numeric(x)){ 
 print('is numeric') 
} else { 
 (is.character(x)) 
 print('is character')
}
```

**Task** flip the results from above
---

class: inverse, middle

# Iteration: For loops

---

### For loops

For loops are the most common looping construct. Used to **iterate over the elements of an object** (list, vector, etc.) and apply some statement(s) to each of them (e.g., we do something with that element)

Syntax:
```
for (item in sequence of items) {
 statement(s) 
}
```

Example:

```r
for (item in 1:3){
 print(item)
}
```

```
## [1] 1
## [1] 2
## [1] 3
```

---

### For loops 

Example:

```r
for (item in 1:3){
 print(item)
}
```

```
## [1] 1
## [1] 2
## [1] 3
```

Let's unpack this example:
* the statement we are executing here is simple: we print `item` using the `print()` function
* `item` is a placeholder: at each iteration of the loop, the element `item` varies 
* the number of repetitions of the statement block depends on the number of items in the sequence of numbers that we provide, in this example 3
* `item` can be labeled anything else, R does not care as long as you are consistent

---

### For loops

Another example:

```r
for (i in 1:3){
 print(i)
 print("Hello")
 sum &amp;lt;- i + 100
 print(sum)
}
```

```
## [1] 1
## [1] "Hello"
## [1] 101
## [1] 2
## [1] "Hello"
## [1] 102
## [1] 3
## [1] "Hello"
## [1] 103
```

&amp;lt;!-- What is this loop doing? Have someone describing it 
what happens if I add a print(i) at the end outside the loop: prints last i--&amp;gt;


---

### Nested for loops

- The **outer loop** takes control of the number of complete repetitions of the inner loop
- The **inner loop** is executed N-times for every execution of the outer loop


```r
for (i in 1:3) {
 print(i)
 for (j in c("a", "b")) {
 print(j)
 }
}
```

```
## [1] 1
## [1] "a"
## [1] "b"
## [1] 2
## [1] "a"
## [1] "b"
## [1] 3
## [1] "a"
## [1] "b"
```

&amp;lt;!--
for (i in 1:3) {
 print(i)
 for (j in c('a', 'b')) {
 print(i)
 print(paste(i, "outer"))
 print(j)
 print(paste(i,j))
 }
}
--&amp;gt;

---

### Same operation without and with a for loop on a data frame

Get the data:

```r
library(tidyverse)
library(palmerpenguins)
data(penguins)

head(penguins)
```

```
## # A tibble: 6 × 8
## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 Adelie Torgersen 39.1 18.7 181 3750
## 2 Adelie Torgersen 39.5 17.4 186 3800
## 3 Adelie Torgersen 40.3 18 195 3250
## 4 Adelie Torgersen NA NA NA NA
## 5 Adelie Torgersen 36.7 19.3 193 3450
## 6 Adelie Torgersen 39.3 20.6 190 3650
## # ℹ 2 more variables: sex &amp;lt;fct&amp;gt;, year &amp;lt;int&amp;gt;
```

---

### Same operation without and with a for loop on a data frame

Perform some basic cleaning:

```r
penguins_clean &amp;lt;- 
 select(penguins, 3:6) %&amp;gt;%
 drop_na()
head(penguins_clean)
```

```
## # A tibble: 6 × 4
## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1 39.1 18.7 181 3750
## 2 39.5 17.4 186 3800
## 3 40.3 18 195 3250
## 4 36.7 19.3 193 3450
## 5 39.3 20.6 190 3650
## 6 38.9 17.8 181 3625
```


---

### Same operation without and with a for loop on a data frame

Calculate the mean value per each column **without a loop**:

```r
mean(penguins_clean$bill_length_mm)
## [1] 43.92193
mean(penguins_clean$bill_depth_mm)
## [1] 17.15117
mean(penguins_clean$flipper_length_mm)
## [1] 200.9152
mean(penguins_clean$body_mass_g)
## [1] 4201.754
```

Use the mean function, and apply it to each column of the data frame. Notice we can use the `$` sign to access columns within a data frame. This works but is a lot of copying/pasting...

--

How can we do the same using a iterative operation, e.g. **with a for loop**? 

In-class demo (the code is included in the shared in-class practice folder for today)

---

### Same operation without and with a for loop on a data frame

Calculate the mean value per each column **with a for loop**:

```r
# initialize empty vector to store results
output &amp;lt;- vector(mode = "double", length = ncol(penguins_clean))

# loop 
for (i in seq_along(penguins_clean)) {
 output[[i]] &amp;lt;- mean(penguins_clean[[i]])
}
output
```

```
## [1] 43.92193 17.15117 200.91520 4201.75439
```

--

For loops include three components: 
* output (to store results; pre-allocating the output with a given length makes the loop much faster)
* sequence (what goes in the for loop)
* body (the statements to be executed every time through the loop) 

---

### Preallocation

&amp;lt;!-- This explains why we are pre-allocating in the first place, why we do so with a vector, and it also might answer Diana question last time about storing results in a tibble or data frame
having an object that is already of the same length of the output, where we are just plugging in 
individual values (this increases speed) rather the more naive approach in which we store with an 
empty vector or an empty other object (e.g. a dataframe) of length zero, and then append or add on
each of the values as we calculate them

For example, let's take this mpg data (built in dataframe in R about auto, we do not really care about the content of the data here); here what we are doing is creating duplicates of that dataframe 100 times and we are then putting them together into a single data frame. 

Without preallocation: we can create an empty dataframe (here with the tibble function), iterate over 100 times, take this empty dataframe and combine the rows of it with the rows of the original dataframe, and replace the original object with the new copy and save in output (so we are appending 100 rows every time we iterate!) 

If we do proper preallocation: we create a list of 100 empty elements, every time we store the results in the list, then we use the bind_rows() functions at the end

The first approach does not preallocate by creating an empty space to store the output, the second does. See the difference in time of execution. From 80 milliseconds to less than 3. So you can see how inefficient is not to allocate since most of our data will have more than 100 rows!

--&amp;gt;

.panelset[
.panel[.panel-name[Code]
```r
# no preallocation
mpg_no_preall &amp;lt;- tibble()
for(i in 1:100){
 mpg_no_preall &amp;lt;- bind_rows(mpg_no_preall, mpg)
}

# with preallocation using a list
mpg_preall &amp;lt;- vector(mode = "list", length = 100)
for(i in 1:100){
 mpg_preall[[i]] &amp;lt;- mpg
}
mpg_preall &amp;lt;- bind_rows(mpg_preall)
```
]

.panel[.panel-name[Plot]
&amp;lt;img src="index_files/figure-html/unnamed-chunk-24-1.png" width="70%" style="display: block; margin: auto;" /&amp;gt;
]
]


---

class: inverse, middle

# Practice writing for loops

---

class: inverse, middle

# Iteration: While loops

---

### While loops

* A while loop begins by evaluating a condition 
* If the condition is TRUE, R executes the loop body
* Once the loop body is executed, R starts over: the condition is evaluated again, and so forth, until the condition is FALSE 
* At that point, the while loop exits

---

### While loops

Syntax:
```
while (condition to be evaluated) {
statement(s)
}
```

Example:

```r
counter &amp;lt;- 1

while(counter &amp;lt;= 4) {
 print(counter)
 counter &amp;lt;- counter + 1
}
```

```
## [1] 1
## [1] 2
## [1] 3
## [1] 4
```

&amp;lt;!-- 
set the counter outside the loop, usually to 1
set a condition to be evaluated: here the condition says the counter has to be smaller or equal to 4
if the condition is TRUE, the loop is executed, here all we ask is to print(counter)
thus the first time it prints 1
but if we leave it as it is (without the last line of code), the while loops will keep going infinitely: we need a way to break the loop
thus we increment our counter inside the loop by redefining it as counter + 1
--&amp;gt;
---


### While loops

Let's take the same example, but print `counter` also at the end: Why are the results different?

```r
counter &amp;lt;- 1

while(counter &amp;lt;= 3) {
 print(counter)
 counter &amp;lt;- counter + 1
 print(counter)
}
```

```
## [1] 1
## [1] 2
## [1] 2
## [1] 3
## [1] 3
## [1] 4
```

---

### While loops

Let's take the same example, but do not increment our `counter` variable: What do you predict it will happen?

```
counter &amp;lt;- 1
while(counter &amp;lt; 3){
 print(counter)
}
```
--

Infinite loop!
&amp;lt;!-- show this in class --&amp;gt;

---

### While loops

Example: What is the output of this code?

```r
counter &amp;lt;- 1
while(counter &amp;lt; 4){
 print(counter)
 multiply &amp;lt;- counter * 100
 print(multiply)
 counter &amp;lt;- counter + 1
 print(counter)
}
```

```
## [1] 1
## [1] 100
## [1] 2
## [1] 2
## [1] 200
## [1] 3
## [1] 3
## [1] 300
## [1] 4
```

---

### While loops

While loops are best used **when you do not know how long the input sequence should run for**. For example, you might want to loop until you get three heads in a row in a random sequence of numbers. You can’t do that with a for loop.


While loops usually require a **"count variable"** to be set outside the loop.

While are **less common than for loops**, that's why we do not go in-depth.

---

class: inverse, middle

# Iteration: For loops alternatives in R 

### Iteration with `map_*()` functions
### Iteration with `across()`

---

## Map functions

&amp;lt;!-- As we have seen in the slides and practice, we kind of have to write a lot of code for a for loop, for example to calculate a straightforward operation like the mean or median etc. so R gives us a shortcut: map functions which come from the purrr package in R and are much more compact (go to the documentation page)
--&amp;gt;

R provides alternatives to for loops: **`for` loops are good, but `map()` functions may be even better!** 

They come from the `purr` package in R https://purrr.tidyverse.org/

There are **different `map()` functions** depending on the type of output you want to create -- notice this is the same thing in the for loop when we specify the mode of our output vector:

- `map()` makes a list
- `map_lgl()` makes a logical vector
- `map_int()` makes an integer vector
- `map_dbl()` makes a double vector
- `map_chr()` makes a character vector

---

## Map functions

Let's see an example using the built-in [`mtcars` data frame](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars):

```r
data(mtcars)
head(mtcars)
```

```
## mpg cyl disp hp drat wt qsec vs am gear carb
## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4
## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4
## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1
## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1
## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2
## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1
```

---

## Map functions

Pick the `map()` function you need and specify two main arguments (for more see documentation): 
* what you are iterating over
* what you are calculating


```r
map_dbl(mtcars, median)
```

```
## mpg cyl disp hp drat wt qsec vs am gear 
## 19.200 6.000 196.300 123.000 3.695 3.325 17.710 0.000 0.000 4.000 
## carb 
## 2.000
```

```r
map_dbl(mtcars, mean, na.rm = TRUE)
```

```
## mpg cyl disp hp drat wt qsec 
## 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 17.848750 
## vs am gear carb 
## 0.437500 0.406250 3.687500 2.812500
```

---

## Map functions

We can use `map()` functions also with the `%&amp;gt;%` operator:


```r
mtcars %&amp;gt;%
 map_dbl(mean, na.rm = TRUE)
```

```
## mpg cyl disp hp drat wt qsec 
## 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 17.848750 
## vs am gear carb 
## 0.437500 0.406250 3.687500 2.812500
```

---

## Across function

We’ve seen how to use loops and `map()` functions to solve the same task. **Let's review one final method: the `across()` function**.

Notice:
* `across()` comes from the `dplyr` package
* `map()` functions come from the `purr` package

Advantages:
* `across()` makes it easy to apply the same transformation to multiple columns in a data frame
* since it comes from `dplyr()`, it is well integrated with `dplyr` verbs!

---

### Single column

Using the `dplyr` verb `summarize()`, we can easily calculate the mean of one column without the help of `map()` or `across()`. Here we calculate the mean of `mpg` using the built-in `mtcars` data:

```r
mtcars %&amp;gt;%
 summarize(miles_gallon = mean(mpg))
```

```
## miles_gallon
## 1 20.09062
```

---

### Multiple columns

We can extend the same operation to multiple columns, as follows:

```r
mtcars %&amp;gt;%
 summarize(
 miles_gallon = mean(mpg),
 cylinders = mean(cyl),
 displacement = mean(disp),
 horsepower = mean(hp),
 rear_axle_ratio = mean(drat),
 weight = mean(wt)
 )
```

```
## miles_gallon cylinders displacement horsepower rear_axle_ratio weight
## 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725
```
This works... but we can do this same operator more efficiently using `across()`

---

## `dplyr::across()`

`across()` has two main arguments:

* `.cols`: columns you want to operate on; can select columns by position, name, and type
* `.fns`: is a function or list of functions to apply to each column

We now review some examples of `across()` in conjunction with its favorite verb, `summarize()` 

Check the documentation for more examples and applications: https://dplyr.tidyverse.org/reference/across.html

---

### `summarize()`, `across()`, and `everything()`

.panelset[
.panel[.panel-name[Single function]

```r
# calculate the mean on all columns of mtcars, use everything() to select all variables
mtcars %&amp;gt;%
 summarize(across(.cols = everything(), 
 .fns = mean, na.rm = TRUE))
```

```
## mpg cyl disp hp drat wt qsec vs am
## 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625
## gear carb
## 1 3.6875 2.8125
```
]

.panel[.panel-name[Multiple functions]

```r
# to apply multiple summaries, store the functions in a list
mtcars %&amp;gt;%
 summarize(across(everything(),
 .fns = list(min, max)))
```

```
## mpg_1 mpg_2 cyl_1 cyl_2 disp_1 disp_2 hp_1 hp_2 drat_1 drat_2 wt_1 wt_2
## 1 10.4 33.9 4 8 71.1 472 52 335 2.76 4.93 1.513 5.424
## qsec_1 qsec_2 vs_1 vs_2 am_1 am_2 gear_1 gear_2 carb_1 carb_2
## 1 14.5 22.9 0 1 0 1 3 5 1 8
```
]

.panel[.panel-name[Multiple named functions]

```r
# provide names to variables, to clearly distinguish each summarized variable
mtcars %&amp;gt;%
 summarize(across(everything(), 
 .fns = list(min = min, max = max)))
```

```
## mpg_min mpg_max cyl_min cyl_max disp_min disp_max hp_min hp_max drat_min
## 1 10.4 33.9 4 8 71.1 472 52 335 2.76
## drat_max wt_min wt_max qsec_min qsec_max vs_min vs_max am_min am_max gear_min
## 1 4.93 1.513 5.424 14.5 22.9 0 1 0 1 3
## gear_max carb_min carb_max
## 1 5 1 8
```
]

.panel[.panel-name[Grouped by]

```r
# use with group_by() to calculate the mean of all columns for each group
mtcars %&amp;gt;%
 group_by(cyl) %&amp;gt;%
 summarize(across(everything(), 
 .fns = mean, na.rm = TRUE))
```

```
## # A tibble: 3 × 11
## cyl mpg disp hp drat wt qsec vs am gear carb
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 4 26.7 105. 82.6 4.07 2.29 19.1 0.909 0.727 4.09 1.55
## 2 6 19.7 183. 122. 3.59 3.12 18.0 0.571 0.429 3.86 3.43
## 3 8 15.1 353. 209. 3.23 4.00 16.8 0 0.143 3.29 3.5
```
]
]

&amp;lt;!-- https://willhipson.netlify.app/post/dplyr_across/dplyr_across/ --&amp;gt;

---

## More examples using the [`worldbank` data](https://data.worldbank.org/)


```r
data("worldbank", package = "rcis")
worldbank
```

```
## # A tibble: 78 × 14
## iso3c date iso2c country perc_energy_fosfuel rnd_gdpshare
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 ARG 2005 AR Argentina 89.1 0.379
## 2 ARG 2006 AR Argentina 88.7 0.400
## 3 ARG 2007 AR Argentina 89.2 0.402
## 4 ARG 2008 AR Argentina 90.7 0.421
## 5 ARG 2009 AR Argentina 89.6 0.519
## 6 ARG 2010 AR Argentina 89.5 0.518
## 7 ARG 2011 AR Argentina 88.9 0.537
## 8 ARG 2012 AR Argentina 89.0 0.609
## 9 ARG 2013 AR Argentina 89.0 0.612
## 10 ARG 2014 AR Argentina 87.7 0.613
## # ℹ 68 more rows
## # ℹ 8 more variables: percgni_adj_gross_savings &amp;lt;dbl&amp;gt;,
## # real_netinc_percap &amp;lt;dbl&amp;gt;, gdp_capita &amp;lt;dbl&amp;gt;, top10perc_incshare &amp;lt;dbl&amp;gt;,
## # employment_ratio &amp;lt;dbl&amp;gt;, life_exp &amp;lt;dbl&amp;gt;, pop_growth &amp;lt;dbl&amp;gt;, pop &amp;lt;dbl&amp;gt;
```

---

### `summarize()`, `across()`, and `where()`

.panelset[
.panel[.panel-name[Single condition]

```r
# use across() with where() to pick variables based on type (e.g. is.numeric(), etc.)
worldbank %&amp;gt;% 
 group_by(country) %&amp;gt;%
 summarize(across(.cols = where(is.numeric), .fns = mean, na.rm = TRUE))
```

```
## # A tibble: 6 × 11
## country perc_energy_fosfuel rnd_gdpshare percgni_adj_gross_savings
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Argentina 89.1 0.501 17.5
## 2 China 87.6 1.67 48.3
## 3 Indonesia 65.3 0.0841 30.5
## 4 Norway 58.9 1.60 37.2
## 5 United Kingdom 86.3 1.68 13.5
## 6 United States 84.2 2.69 17.6
## # ℹ 7 more variables: real_netinc_percap &amp;lt;dbl&amp;gt;, gdp_capita &amp;lt;dbl&amp;gt;,
## # top10perc_incshare &amp;lt;dbl&amp;gt;, employment_ratio &amp;lt;dbl&amp;gt;, life_exp &amp;lt;dbl&amp;gt;,
## # pop_growth &amp;lt;dbl&amp;gt;, pop &amp;lt;dbl&amp;gt;
```
]

.panel[.panel-name[Compound condition]

```r
# or pick variables based on type and whose name begins with "perc"
worldbank %&amp;gt;%
 group_by(country) %&amp;gt;%
 summarize(across(
 .cols = where(is.numeric) &amp;amp; starts_with("perc"),
 .fn = mean, na.rm = TRUE
 ))
```

```
## # A tibble: 6 × 3
## country perc_energy_fosfuel percgni_adj_gross_savings
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Argentina 89.1 17.5
## 2 China 87.6 48.3
## 3 Indonesia 65.3 30.5
## 4 Norway 58.9 37.2
## 5 United Kingdom 86.3 13.5
## 6 United States 84.2 17.6
```
]

]

---

### `across()` and `filter()`

To use `across()` with `filter()`, we need an extra step: `if_any()` or `if_all()`


```r
# if_any() keeps rows where the predicate is true for at least one column
worldbank %&amp;gt;%
 filter(if_any(everything(), ~ !is.na(.x)))
```


```r
# if_all() keeps rows where the predicate is true for all selected columns
worldbank %&amp;gt;%
 filter(if_all(everything(), ~ !is.na(.x)))
```


---

class: inverse, middle

# Practice writing `map_*()` functions and `across()` iteration


---

## Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/visualizations-and-the-grammar-of-graphics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/visualizations-and-the-grammar-of-graphics/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Visualizations and the Grammar of Graphics&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACSS 30500 University of Chicago" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Visualizations and the Grammar of Graphics
]
.author[
### MACSS 30500 &lt;br /> University of Chicago
]

---






class: inverse, middle

# Why visualize data?

---

class: center, middle

Consider the following 13 datasets:


| ID| `\(N\)`| `\(\bar{X}\)`| `\(\bar{Y}\)`| `\(\sigma_{X}\)`| `\(\sigma_{Y}\)`| `\(R\)`|
|--:|---:|---------:|---------:|------------:|------------:|----------:|
| 1| 142| 54.26610| 47.83472| 16.76983| 26.93974| -0.0641284|
| 2| 142| 54.26873| 47.83082| 16.76924| 26.93573| -0.0685864|
| 3| 142| 54.26732| 47.83772| 16.76001| 26.93004| -0.0683434|
| 4| 142| 54.26327| 47.83225| 16.76514| 26.93540| -0.0644719|
| 5| 142| 54.26030| 47.83983| 16.76774| 26.93019| -0.0603414|
| 6| 142| 54.26144| 47.83025| 16.76590| 26.93988| -0.0617148|
| 7| 142| 54.26881| 47.83545| 16.76670| 26.94000| -0.0685042|
| 8| 142| 54.26785| 47.83590| 16.76676| 26.93610| -0.0689797|
| 9| 142| 54.26588| 47.83150| 16.76885| 26.93861| -0.0686092|
| 10| 142| 54.26734| 47.83955| 16.76896| 26.93027| -0.0629611|
| 11| 142| 54.26993| 47.83699| 16.76996| 26.93768| -0.0694456|
| 12| 142| 54.26692| 47.83160| 16.77000| 26.93790| -0.0665752|
| 13| 142| 54.26015| 47.83972| 16.76996| 26.93000| -0.0655833|

---

class: center, middle

If we estimate linear regression models for each dataset, we obtain virtually identical coefficients, again suggesting the relationships are identical

&amp;lt;img src="index_files/figure-html/datasaurus-lm-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: center, middle

But what happens if we draw a picture?

&amp;lt;img src="index_files/figure-html/datasaurus-graph-1.gif" width="90%" style="display: block; margin: auto;" /&amp;gt;

---

class: center, middle

These 13 datasets have the same summary statistics, yet they are drastically different in appearance!

&amp;lt;img src="index_files/figure-html/datasaurus-graph-static-1.png" width="90%" style="display: block; margin: auto;" /&amp;gt;

---

class: inverse, middle

# The Grammar of Graphics

---

## Grammar and Grammar of Graphics

&amp;gt; A **Grammar** can be broadly defined as the whole system and structure of a language or of languages in general, usually taken as consisting of syntax and morphology (including inflections) and sometimes also phonology and semantics. It what makes communication possible


&amp;gt; Applied to visualizations, a **Grammar of Graphics** is a grammar that makes it possibile to create a wide range of statistical graphics!

---

### Grammar of Graphics

* A grammar used to create a wide range of statistical graphics

* Grammar of graphics approach: implemented in **[`ggplot2`](https://cran.r-project.org/web/packages/ggplot2/index.html)**, a widely used graphics library for R

* ggplot2 is part of the **[`tidyverse`](https://www.tidyverse.org/)** a collection of R packages designed for data science that share the same grammar and data structures. We will learn how to use multiple packages from tidyverse in this course.

---

class: inverse, middle

# Main components of the Grammar of Graphics

&amp;gt; Go to "The Grammar of Graphics" notes in our website to follow along


---

# Grammar of Graphics: the layer cake approach 
.footnote[*Thanks to Jennifer Lin for this metaphor*]
* graph layer +
* data layer + 
* label layer + 
* theme layer + 
* other layer + 



---

# Data: Gapminder and other data
Gapminder data cover multiple countries over multiple years and include information on life expectancy and population. This is one of multiple 'sample' datasets available for R (others including iris and mtcars). It's neat because to use it, you can just call `install.packages("gapminder")` and then `data(gapminder)`. 

---

# Basic graph: preloaded data

Let's start with mtcars (you will see MANY EXAMPLES using this on stackoverflow). In a fresh Rmd file, create a code chunk that calls `data(mtcars)`


```r
data(mtcars)
head(mtcars)
```

```
## mpg cyl disp hp drat wt qsec vs am gear carb
## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4
## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4
## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1
## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1
## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2
## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1
```

---

# Where we're going: graph somewhat prettiness

&amp;lt;img src="index_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---
 
# ggplot layer
 This layer sets up the graph itself. Note that if you just set the data, as I do here, you basically get a blank slate. 
 
--
 I have told it what I want for the data and my respective axes but I haven't actually plotted anything yet!

```r
ggplot(mtcars, aes(x = mpg, y = wt))
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-3-1.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

---
# graph layer
 Then, we just add each element with a `+` after. Here, we have a few options for how we want the "things" on the graph to appear. Option 1: points. (note, there are multiple ways we could choose to set this up).
 

```r
ggplot(mtcars, aes(x = mpg, y = wt)) +
 geom_point()
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

---
# graph layer
 Then, we just add each element with a `+` after. Here, we have a few options for how we want the "things" on the graph to appear. Option 2: text (note, there are multiple ways we could choose to set this up).
 

```r
ggplot(mtcars, aes(x = mpg, y = wt)) +
 geom_text(label = rownames(mtcars), check_overlap = TRUE) 
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-5-1.png" width="50%" style="display: block; margin: auto;" /&amp;gt;


---

# points (intermediate / advanced) layer (back to points!)
Here, we can see our points colored by different criteria. 


```r
ggplot(mtcars)+ 
 geom_point(aes(x = mpg, y = wt, 
 color = factor(cyl),
 shape = factor(cyl),
 size = hp)) 
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-6-1.png" width="50%" style="display: block; margin: auto;" /&amp;gt;


---

# label layer 


```r
ggplot(mtcars)+ 
 geom_point(aes(x = mpg, y = wt, 
 color = factor(cyl),
 shape = factor(cyl),
 size = hp))+ 
 labs(title = "Car MPG vs weight", 
 x = 'Miles per gallon',
 y = 'Car weight',
 shape="Cylinders", size="Horsepower", color = "Cylinders",
 caption = "Source: mtcars")
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-7-1.png" width="50%" style="display: block; margin: auto;" /&amp;gt;

---
 
# theme layer


```r
ggplot(mtcars)+ 
 geom_point(aes(x = mpg, y = wt, 
 color = factor(cyl),
 shape = factor(cyl),
 size = hp))+ 
 labs(title = "Car MPG vs weight", 
 x = 'Miles per gallon',
 y = 'Car weight',
 shape="Cylinders", size="Horsepower", color = "Cylinders",
 caption = "Source: mtcars") +
 theme_bw()
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-8-1.png" width="40%" style="display: block; margin: auto;" /&amp;gt;

---
 
# others


```r
ggplot(mtcars)+ 
 geom_point(aes(x = mpg, y = wt, 
 color = factor(cyl),
 shape = factor(cyl),
 size = hp))+ 
 labs(title = "Car MPG vs weight", 
 x = 'Miles per gallon',
 y = 'Car weight',
 shape="Cylinders", size="Horsepower", color = "Cylinders",
 caption = "Source: mtcars") +
 theme_bw() +
 scale_color_manual(values = c("black", "gray", "blue") ) 
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-9-1.png" width="40%" style="display: block; margin: auto;" /&amp;gt;

---
 
# Final version!

.pull-left[


```r
ggplot(mtcars)+ 
 geom_point(aes(x = mpg, y = wt, 
 color = factor(cyl),
 shape = factor(cyl),
 size = hp))+ 
 labs(title = "Car MPG vs weight", 
 x = 'Miles per gallon',
 y = 'Car weight',
 shape="Cylinders", size="Horsepower", color = "Cylinders",
 caption = "Source: mtcars") +
 theme_bw() +
 scale_color_manual(values = c("black", "gray", "blue") ) 
```

]


.pull-right[
&amp;lt;img src="index_files/figure-html/unnamed-chunk-11-1.png" width="90%" style="display: block; margin: auto;" /&amp;gt;
]
---
 
# Basic graph: gapminder 
 

&amp;gt; Which is the best name for our dataset? 
 a) df or dat 
 b) gapminder 
 c) gapminder_2007 
 d) (something else) 
 

---
 
# Basic graph: gapminder 

(NOTE: BAD CODE (why?)) 

```r
data(gapminder) # note: not necessary but this will have it show up in your environment like with 'regular' data
```

--

### Why is this code better? 

```r
data(gapminder) # note: not necessary but this will 
 # have it show up in your environment 
 # like with 'regular' data
```

--

Now, use yesterday's skills to explore the dataset. What might make a good `x' or 'y'? 

--- 

---

# Exercise: Gapminder

&amp;lt;img src="index_files/figure-html/gapminder-over-time-1.gif" width="60%" style="display: block; margin: auto;" /&amp;gt;

---

# Acknowledgments 

The content of these slides is derived in part from Sabrina Nardin's and Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.

 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/visualize-spatial-i/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/visualize-spatial-i/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Visualizing spatial data I&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="INFO 5940 Cornell University" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Visualizing spatial data I
]
.author[
### INFO 5940 &lt;br /> Cornell University
]

---






## Geospatial visualizations

* Earliest form of information visualizations
* Geospatial data visualizations
* [Google Maps](https://www.google.com/maps)

---

## Not that Jon Snow

&amp;lt;img src="https://media.giphy.com/media/3ohzdUi5U8LBb4GD4s/giphy.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Dr. John Snow

&amp;lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Snow-cholera-map-1.jpg/2183px-Snow-cholera-map-1.jpg" width="50%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [Wikipedia](https://en.wikipedia.org/wiki/John_Snow)]

---

## Designing modern maps

* Depict spatial features
* Incorporate additional attributes and information
* Major features
 * Scale
 * Projection
 * Symbols

---

## Scale

* Proportion between distances and sizes on a map and their actual distances and sizes on Earth
* Small-scale map
* Large-scale map

---

## Large-scale map

&amp;lt;img src="index_files/figure-html/large-scale-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Small-scale map

&amp;lt;img src="index_files/figure-html/small-scale-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

.pull-left[

## Asgard


&amp;lt;img src="../../../../../../../../img/asgard.jpeg" width="95%" style="display: block; margin: auto;" /&amp;gt;

]

--

.pull-right[

## Midgard

&amp;lt;img src="../../../../../../../../img/midgard.png" width="95%" style="display: block; margin: auto;" /&amp;gt;

]

---

## Not flat

&amp;lt;img src="https://images.theconversation.com/files/218823/original/file-20180514-100722-1yxg7ip.jpg" width="50%" style="display: block; margin: auto;" /&amp;gt;

---

## Projection

* Process of taking a three-dimensional object and visualizing it on a two-dimensional surface
* No 100% perfect method for this
* Always introduces distortions

--


* Properties of projection methods
 1. Shape
 1. Area
 1. Angles
 1. Distance
 1. Direction

---



&amp;lt;img src="index_files/figure-html/projections-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Symbols

&amp;lt;img src="index_files/figure-html/bb-hydepark-stamen-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

class: inverse, middle

# `ggmap` for raster maps

---

## `ggmap`

- Package for drawing maps using `ggplot2` and **raster** map tiles
- Static image files generated by mapping services
- Focus on incorporating data into existing maps
- Severely limits ability to change the appearance of the geographic map
- Don't have to worry about the maps, just the data to go on top

---

## Bounding box



.panelset[
.panel[.panel-name[Code]

```r
nyc_bb &amp;lt;- c(
* left = -74.263045,
* bottom = 40.487652,
* right = -73.675963,
* top = 40.934743
)

nyc_stamen &amp;lt;- get_stamenmap(
 bbox = nyc_bb,
 zoom = 11
)
ggmap(nyc_stamen)
```



]

.panel[.panel-name[Plot]

&amp;lt;img src="index_files/figure-html/unnamed-chunk-7-1.png" width="70%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## Level of detail

&amp;lt;img src="index_files/figure-html/bb-nyc-stamen-zoom-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Identifying bounding box

&amp;gt; Use [bboxfinder.com](http://bboxfinder.com/#0.000000,0.000000,0.000000,0.000000) to determine the exact longitude/latitude coordinates for the bounding box you wish to obtain.

---

## Types of map tiles

&amp;lt;img src="index_files/figure-html/stamen-maptype-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="https://media.giphy.com/media/oOK9AZGnf9b0c/giphy.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Import crime data

* New York City open data portal
* [Crime data from 2022](https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243)




```r
crimes &amp;lt;- here("data", "nyc-crimes.csv") %&amp;gt;%
 read_csv()
```


```r
glimpse(crimes)
```

```
## Rows: 256,797
## Columns: 7
## $ cmplnt_num &amp;lt;chr&amp;gt; "247350382", "243724728", "246348713", "240025455", "2461…
## $ boro_nm &amp;lt;chr&amp;gt; "BROOKLYN", "QUEENS", "QUEENS", "BROOKLYN", "BRONX", "BRO…
## $ cmplnt_fr_dt &amp;lt;dttm&amp;gt; 1011-05-18 04:56:02, 1022-04-11 04:56:02, 1022-06-08 04:…
## $ law_cat_cd &amp;lt;chr&amp;gt; "MISDEMEANOR", "MISDEMEANOR", "MISDEMEANOR", "FELONY", "F…
## $ ofns_desc &amp;lt;chr&amp;gt; "CRIMINAL MISCHIEF &amp;amp; RELATED OF", "PETIT LARCENY", "PETIT…
## $ latitude &amp;lt;dbl&amp;gt; 40.66904, 40.77080, 40.68766, 40.65421, 40.83448, 40.6973…
## $ longitude &amp;lt;dbl&amp;gt; -73.90619, -73.81115, -73.83406, -73.95957, -73.85637, -7…
```

---

## Plot high-level map of crime

.panelset.sideways[

```r
nyc &amp;lt;- nyc_stamen
*ggmap(nyc)
```

&amp;lt;img src="index_files/figure-html/import-nyc-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Using `geom_point()`

.panelset.sideways[

```r
ggmap(nyc) +
* geom_point(
* data = crimes,
* mapping = aes(
* x = longitude,
* y = latitude
* )
* )
```

&amp;lt;img src="index_files/figure-html/plot-crime-point-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Using `geom_point()`

.panelset.sideways[

```r
ggmap(nyc) +
 geom_point(
 data = crimes,
 mapping = aes(
 x = longitude,
 y = latitude
 ),
* size = .25,
* alpha = .01
 )
```

&amp;lt;img src="index_files/figure-html/plot-crime-point-alpha-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Using `geom_density_2d()`

.panelset.sideways[

```r
ggmap(nyc) +
* geom_density_2d(
 data = crimes,
 mapping = aes(
 x = longitude,
 y = latitude
 )
 )
```

&amp;lt;img src="index_files/figure-html/kde-contour-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Using `stat_density_2d()`

.panelset.sideways[

```r
ggmap(nyc) +
* stat_density_2d(
 data = crimes,
 mapping = aes(
 x = longitude,
 y = latitude,
* fill = stat(level)
 ),
* geom = "polygon"
 )
```

&amp;lt;img src="index_files/figure-html/kde-fill-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Using `stat_density_2d()`

.panelset.sideways[

```r
ggmap(nyc) +
 stat_density_2d(
 data = crimes,
 mapping = aes(
 x = longitude,
 y = latitude,
 fill = stat(level)
 ),
* alpha = .2,
* bins = 25,
 geom = "polygon"
 )
```

&amp;lt;img src="index_files/figure-html/plot-crime-density-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Looking for variation

.panelset.sideways[

```r
ggmap(nyc) +
 stat_density_2d(
 data = crimes %&amp;gt;%
 filter(ofns_desc %in% c(
 "DANGEROUS DRUGS",
 "GRAND LARCENY OF MOTOR VEHICLE",
 "ROBBERY",
 "VEHICLE AND TRAFFIC LAWS"
 )),
 aes(
 x = longitude,
 y = latitude,
 fill = stat(level)
 ),
 alpha = .4,
 bins = 10,
 geom = "polygon"
 ) +
* facet_wrap(facets = vars(ofns_desc))
```

&amp;lt;img src="index_files/figure-html/plot-crime-wday-1.png" width="100%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Exercise using `ggmap`

&amp;lt;img src="https://c.tenor.com/GopcJIF_Y98AAAAC/lost-kermit.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

&lt;div class="countdown" id="timer_6319fdf0" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">15&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---

class: middle, inverse

# Geofaceting

---



&amp;lt;img src="index_files/figure-html/geofacet-state-1.png" width="90%" style="display: block; margin: auto;" /&amp;gt;

---

## Daily US vaccine data by state



.small[

```r
us_state_vaccinations &amp;lt;- read_csv(here::here("data", "us_state_vaccinations.csv"))
```


```r
glimpse(us_state_vaccinations)
```

```
## Rows: 38,052
## Columns: 16
## $ date &amp;lt;date&amp;gt; 2021-01-12, 2021-01-13, 2021-01-1…
## $ location &amp;lt;chr&amp;gt; "Alabama", "Alabama", "Alabama", "…
## $ total_vaccinations &amp;lt;dbl&amp;gt; 78134, 84040, 92300, 100567, NA, N…
## $ total_distributed &amp;lt;dbl&amp;gt; 377025, 378975, 435350, 444650, NA…
## $ people_vaccinated &amp;lt;dbl&amp;gt; 70861, 74792, 80480, 86956, NA, NA…
## $ people_fully_vaccinated_per_hundred &amp;lt;dbl&amp;gt; 0.15, 0.19, NA, 0.28, NA, NA, NA, …
## $ total_vaccinations_per_hundred &amp;lt;dbl&amp;gt; 1.59, 1.71, 1.88, 2.05, NA, NA, NA…
## $ people_fully_vaccinated &amp;lt;dbl&amp;gt; 7270, 9245, NA, 13488, NA, NA, NA,…
## $ people_vaccinated_per_hundred &amp;lt;dbl&amp;gt; 1.45, 1.53, 1.64, 1.77, NA, NA, NA…
## $ distributed_per_hundred &amp;lt;dbl&amp;gt; 7.69, 7.73, 8.88, 9.07, NA, NA, NA…
## $ daily_vaccinations_raw &amp;lt;dbl&amp;gt; NA, 5906, 8260, 8267, NA, NA, NA, …
## $ daily_vaccinations &amp;lt;dbl&amp;gt; NA, 5906, 7083, 7478, 7498, 7509, …
## $ daily_vaccinations_per_million &amp;lt;dbl&amp;gt; NA, 1205, 1445, 1525, 1529, 1531, …
## $ share_doses_used &amp;lt;dbl&amp;gt; 0.207, 0.222, 0.212, 0.226, NA, NA…
## $ total_boosters &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ total_boosters_per_hundred &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA…
```

]

.footnote[
Source: https://ourworldindata.org/us-states-vaccinations
]

---

## Facet by location

.panelset.sideways[
.panel[.panel-name[Code]

```r
ggplot(
 data = us_state_vaccinations,
 mapping = aes(x = date, y = people_fully_vaccinated_per_hundred)
) +
 geom_area() +
* facet_wrap(facets = vars(location))
```



]

.panel[.panel-name[Plot]

&amp;lt;img src="index_files/figure-html/unnamed-chunk-15-1.png" width="95%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## Data cleaning


```r
us_state_vaccinations &amp;lt;- us_state_vaccinations %&amp;gt;%
 mutate(location = if_else(location == "New York State", "New York", location)) %&amp;gt;%
 filter(location %in% c(state.name, "District of Columbia"))
```

---

## Geofacet by state

Using `geofacet::facet_geo()`:

.panelset.sideways[
.panel[.panel-name[Code]

```r
ggplot( 
 data = us_state_vaccinations,
 mapping = aes(x = date, y = people_fully_vaccinated_per_hundred)
) +
 geom_area() +
* facet_geo(facets = vars(location)) +
 labs(
 x = NULL, y = NULL,
 title = "Covid-19 vaccination rate in the US",
 subtitle = "Daily number of people fully vaccinated, per hundred",
 caption = "Source: Our World in Data"
 )
```



]

.panel[.panel-name[Plot]

&amp;lt;img src="index_files/figure-html/unnamed-chunk-17-1.png" width="95%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## Geofacet by state, with improvements

.panelset.sideways[
.panel[.panel-name[Plot]
&amp;lt;img src="index_files/figure-html/unnamed-chunk-18-1.png" width="95%" style="display: block; margin: auto;" /&amp;gt;
]
.panel[.panel-name[Code]
.small[

```r
ggplot(us_state_vaccinations, aes(x = date, y = people_fully_vaccinated_per_hundred, group = location)) +
 geom_area() +
 facet_geo(facets = vars(location)) +
* scale_y_continuous(
* limits = c(0, 100),
* breaks = c(0, 50, 100),
* minor_breaks = c(25, 75)
* ) +
* scale_x_date(breaks = c(ymd("2021-01-01", "2021-07-01", "2022-01-01")), date_labels = "%b-%y") +
 labs(
 x = NULL, y = NULL,
 title = "Covid-19 vaccination rate in the US",
 subtitle = "Daily number of people fully vaccinated, per hundred",
 caption = "Source: Our World in Data"
 ) +
 theme(
* strip.text.x = element_text(size = 7),
* axis.text = element_text(size = 8),
 plot.title.position = "plot"
 )
```
]
]
]

---

## Bring in 2020 Presidential election results




```r
election_2020 &amp;lt;- read_csv(here::here("data", "us-election-2020.csv"))
```


```r
election_2020
```

```
## # A tibble: 51 × 5
## state electoal_votes biden trump win 
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Alabama 9 0 9 Republican
## 2 Alaska 3 0 3 Republican
## 3 Arizona 11 11 0 Democrat 
## 4 Arkansas 6 0 6 Republican
## 5 California 55 55 0 Democrat 
## 6 Colorado 9 9 0 Democrat 
## 7 Connecticut 7 7 0 Democrat 
## 8 Delaware 3 3 0 Democrat 
## 9 District of Columbia 3 3 0 Democrat 
## 10 Florida 29 0 29 Republican
## # … with 41 more rows
## # ℹ Use `print(n = ...)` to see more rows
```

---

## Geofacet by state, color by presidential election result

.tiny[
.panelset.sideways[
.panel[.panel-name[Code]

```r
us_state_vaccinations %&amp;gt;%
 left_join(election_2020, by = c("location" = "state")) %&amp;gt;%
 ggplot(mapping = aes(x = date, y = people_fully_vaccinated_per_hundred)) +
* geom_area(aes(fill = win)) +
 facet_geo(facets = vars(location)) +
* scale_y_continuous(limits = c(0, 100), breaks = c(0, 50, 100), minor_breaks = c(25, 75)) +
 scale_x_date(breaks = c(ymd("2021-01-01", "2021-07-01", "2022-01-01")), date_labels = "%b") +
* scale_fill_manual(values = c("#2D69A1", "#BD3028")) +
 labs(
 x = NULL, y = NULL,
 title = "Covid-19 vaccination rate in the US",
 subtitle = "Daily number of people fully vaccinated, per hundred",
 caption = "Source: Our World in Data",
 fill = "2020 Presidential\nElection"
 ) +
 theme(
 strip.text.x = element_text(size = 7),
 axis.text = element_text(size = 8),
 plot.title.position = "plot",
* legend.position = c(0.93, 0.15),
* legend.text = element_text(size = 9),
* legend.title = element_text(size = 11),
* legend.background = element_rect(color = "gray", size = 0.5)
 )
```



]

.panel[.panel-name[Plot]

&amp;lt;img src="index_files/figure-html/unnamed-chunk-23-1.png" width="100%" style="display: block; margin: auto;" /&amp;gt;

]
]
]
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/visualize-spatial-ii/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/visualize-spatial-ii/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Visualizing spatial data II&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="INFO 5940 Cornell University" />
 &lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="index_files/panelset/panelset.css" rel="stylesheet" />
 &lt;script src="index_files/panelset/panelset.js">&lt;/script>
 &lt;link href="index_files/countdown/countdown.css" rel="stylesheet" />
 &lt;script src="index_files/countdown/countdown.js">&lt;/script>
 &lt;link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Visualizing spatial data II
]
.author[
### INFO 5940 &lt;br /> Cornell University
]

---






## Map data file formats

* Vector files
 * Raster images
 * Numeric data
* Popular formats
 * Shapefile
 * GeoJSON
 
---

## Shapefile

* Encodes points, lines, and polygons
* Collection of files
 * `.shp` - geographic coordinates
 * `.dbf` - data associated with the geographic features
 * `.prj` - projection of the coordinates in the shapefile

--




```
## -- geo_export_6fd95df5-1136-4829-8f2d-9cb5d1cc2222.dbf
## -- geo_export_6fd95df5-1136-4829-8f2d-9cb5d1cc2222.prj
## -- geo_export_6fd95df5-1136-4829-8f2d-9cb5d1cc2222.shp
## -- geo_export_6fd95df5-1136-4829-8f2d-9cb5d1cc2222.shx
```

---

## GeoJSON

* Uses **J**ava**S**cript **O**bject **N**otation (JSON) file format
 
 ```json
 {
 "type": "Feature",
 "geometry": {
 "type": "Point",
 "coordinates": [125.6, 10.1]
 },
 "properties": {
 "name": "Dinagat Islands"
 }
 }
 ```
* Plain text files

---

## Simple Features for R

&amp;lt;img src="../../../../../../../../img/sf.png" title="Three cute fuzzy monsters adding spatial geometries to an existing table of attributes using glue and tape, while one cuts out the spatial polygons. Title text reads 'sf: spatial data...simplified.' and a caption at the bottom reads 'sticky geometries: for people who love their maps and sanity.'" alt="Three cute fuzzy monsters adding spatial geometries to an existing table of attributes using glue and tape, while one cuts out the spatial polygons. Title text reads 'sf: spatial data...simplified.' and a caption at the bottom reads 'sticky geometries: for people who love their maps and sanity.'" width="60%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [Allison Horst](https://github.com/allisonhorst/stats-illustrations)]

---

## What is a feature?

* Thing or an object in the real world
* Sets of features
* Geometry
* Attributes

---

## Simple features

&amp;lt;img src="../../../../../../../../img/simple-features.png" title="Simple features" alt="Simple features" width="70%" style="display: block; margin: auto;" /&amp;gt;

.footnote[
Source: [Simple Features for R](https://r-spatial.github.io/sf/articles/sf1.html#sf-objects-with-simple-features-1)
]

---

## Simple features in R

* Uses basic R data structures
* Data frame with one row per feature
* Lots of list columns

---

## Importing shapefiles




```r
nyc_shape &amp;lt;- st_read(dsn = here("data", "borough-boundaries"))
```


```r
nyc_shape
```

```
## Simple feature collection with 5 features and 4 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS84(DD)
## boro_code boro_name shape_area shape_leng geometry
## 1 5 Staten Island 1623631283 325924.0 MULTIPOLYGON (((-74.05051 4...
## 2 2 Bronx 1187189499 463277.2 MULTIPOLYGON (((-73.89681 4...
## 3 1 Manhattan 636605816 359103.2 MULTIPOLYGON (((-74.01093 4...
## 4 3 Brooklyn 1934169229 728478.1 MULTIPOLYGON (((-73.86327 4...
## 5 4 Queens 3041397430 888238.6 MULTIPOLYGON (((-73.82645 4...
```

---

## Importing GeoJSON files




```r
nyc_json &amp;lt;- st_read(dsn = here("data", "borough-boundaries.geojson"))
```


```r
nyc_json
```

```
## Simple feature collection with 5 features and 4 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## boro_code boro_name shape_area shape_leng geometry
## 1 5 Staten Island 1623631283.36 325924.002076 MULTIPOLYGON (((-74.05051 4...
## 2 2 Bronx 1187189499.3 463277.240478 MULTIPOLYGON (((-73.89681 4...
## 3 1 Manhattan 636605816.437 359103.151368 MULTIPOLYGON (((-74.01093 4...
## 4 3 Brooklyn 1934169228.83 728478.125489 MULTIPOLYGON (((-73.86327 4...
## 5 4 Queens 3041397430.33 888238.562635 MULTIPOLYGON (((-73.82645 4...
```

---

## Drawing maps with `sf` objects




```r
usa &amp;lt;- st_read(dsn = here("data", "cb_2020_us_state_5m", "cb_2020_us_state_5m.shp"))
```

.tiny[

```r
usa
```

```
## Simple feature collection with 56 features and 9 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -179.1473 ymin: -14.55255 xmax: 179.7785 ymax: 71.35256
## Geodetic CRS: NAD83
## First 10 features:
## STATEFP STATENS AFFGEOID GEOID STUSPS NAME LSAD ALAND AWATER geometry
## 1 55 01779806 0400000US55 55 WI Wisconsin 00 140292246684 29343721650 MULTIPOLYGON (((-86.9562 45...
## 2 54 01779805 0400000US54 54 WV West Virginia 00 62266296765 489206049 MULTIPOLYGON (((-82.643 38....
## 3 16 01779783 0400000US16 16 ID Idaho 00 214049923496 2391577745 MULTIPOLYGON (((-117.2427 4...
## 4 27 00662849 0400000US27 27 MN Minnesota 00 206232157570 18949864226 MULTIPOLYGON (((-97.23921 4...
## 5 19 01779785 0400000US19 19 IA Iowa 00 144659688848 1085996889 MULTIPOLYGON (((-96.6397 42...
## 6 10 01779781 0400000US10 10 DE Delaware 00 5046731558 1399179670 MULTIPOLYGON (((-75.5708 39...
## 7 72 01779808 0400000US72 72 PR Puerto Rico 00 8868948653 4922329963 MULTIPOLYGON (((-65.3375 18...
## 8 29 01779791 0400000US29 29 MO Missouri 00 178052563675 2487215790 MULTIPOLYGON (((-95.77355 4...
## 9 50 01779802 0400000US50 50 VT Vermont 00 23873081385 1030243281 MULTIPOLYGON (((-73.43774 4...
## 10 24 01714934 0400000US24 24 MD Maryland 00 25151895765 6979171386 MULTIPOLYGON (((-76.0494 37...
```
]
---

## USA boundaries

.panelset.sideways[

```r
ggplot(data = usa) +
* geom_sf()
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Plot a subset of a map

.panelset.sideways[

```r
usa_48 &amp;lt;- usa %&amp;gt;%
* filter(NAME %in% state.name) %&amp;gt;%
* filter(NAME != "Alaska", NAME != "Hawaii")

ggplot(data = usa_48) +
 geom_sf()
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Just another `ggplot()`

.panelset.sideways[

```r
ggplot(data = usa_48) +
 geom_sf(
* fill = "palegreen",
* color = "black"
 )
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

&amp;lt;img src="https://imgs.xkcd.com/comics/contiguous_41_states.png" width="60%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [xkcd](https://xkcd.com/2394/)]

---

## `urbnmapr`

.panelset.sideways[

```r
library(urbnmapr)

*states_sf &amp;lt;- get_urbn_map("states", sf = TRUE)

ggplot(data = states_sf) +
 geom_sf()
```

&amp;lt;img src="index_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /&amp;gt;
]

---

class: inverse, middle

# Identifying points on a map

---

## Points




```r
crimes &amp;lt;- here("data", "nyc-crimes.csv") %&amp;gt;%
 read_csv()
```


```r
crimes_homicide &amp;lt;- filter(.data = crimes, ofns_desc == "MURDER &amp;amp; NON-NEGL. MANSLAUGHTER")
crimes_homicide
```

```
## # A tibble: 269 × 7
## cmplnt_num boro_nm cmplnt_fr_dt law_cat…¹ ofns_…² latit…³ longi…⁴
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dttm&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 240954923H1 BROOKLYN 1977-12-20 05:00:00 FELONY MURDER… 40.7 -74.0
## 2 245958045H1 BROOKLYN 2001-08-13 04:00:00 FELONY MURDER… 40.7 -73.9
## 3 8101169H6113 MANHATTAN 2005-03-06 05:00:00 FELONY MURDER… 40.8 -73.9
## 4 8101169H6113 MANHATTAN 2005-03-06 05:00:00 FELONY MURDER… 40.8 -73.9
## 5 16631466H8909 BROOKLYN 2006-05-24 04:00:00 FELONY MURDER… 40.7 -73.9
## 6 246056367H1 QUEENS 2015-05-13 04:00:00 FELONY MURDER… 40.6 -73.7
## 7 243507594H1 MANHATTAN 2020-06-19 04:00:00 FELONY MURDER… 40.8 -74.0
## 8 243688124H1 BROOKLYN 2021-01-31 05:00:00 FELONY MURDER… 40.7 -73.9
## 9 240767513H1 BROOKLYN 2021-02-17 05:00:00 FELONY MURDER… 40.6 -74.0
## 10 240767512H1 BROOKLYN 2021-05-24 04:00:00 FELONY MURDER… 40.6 -74.0
## # … with 259 more rows, and abbreviated variable names ¹​law_cat_cd, ²​ofns_desc,
## # ³​latitude, ⁴​longitude
## # ℹ Use `print(n = ...)` to see more rows
```

---

## Points

.panelset.sideways[

```r
ggplot(
 data = crimes_homicide,
 mapping = aes(
 x = longitude,
 y = latitude
 )
) +
* geom_point()
```

&amp;lt;img src="index_files/figure-html/scatter-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Points

.panelset.sideways[

```r
ggplot(data = nyc_json) +
* geom_sf() +
 geom_point(
 data = crimes_homicide,
 mapping = aes(
 x = longitude,
 y = latitude
 ),
 shape = 1
 )
```

&amp;lt;img src="index_files/figure-html/nyc-crime-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

## Converting to `sf` data frame


```r
crimes_homicide_sf &amp;lt;- st_as_sf(x = crimes_homicide, coords = c("longitude", "latitude"))
st_crs(crimes_homicide_sf) &amp;lt;- 4326 # set the coordinate reference system
crimes_homicide_sf
```

```
## Simple feature collection with 269 features and 5 fields
## Geometry type: POINT
## Dimension: XY
## Bounding box: xmin: -74.08578 ymin: 40.59087 xmax: -73.73331 ymax: 40.90316
## Geodetic CRS: WGS 84
## # A tibble: 269 × 6
## cmpln…¹ boro_nm cmplnt_fr_dt law_c…² ofns_…³ geometry
## * &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dttm&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;POINT [°]&amp;gt;
## 1 240954… BROOKL… 1977-12-20 05:00:00 FELONY MURDER… (-73.97448 40.68079)
## 2 245958… BROOKL… 2001-08-13 04:00:00 FELONY MURDER… (-73.92013 40.69862)
## 3 810116… MANHAT… 2005-03-06 05:00:00 FELONY MURDER… (-73.94295 40.81126)
## 4 810116… MANHAT… 2005-03-06 05:00:00 FELONY MURDER… (-73.94295 40.81126)
## 5 166314… BROOKL… 2006-05-24 04:00:00 FELONY MURDER… (-73.91796 40.6703)
## 6 246056… QUEENS 2015-05-13 04:00:00 FELONY MURDER… (-73.7491 40.60219)
## 7 243507… MANHAT… 2020-06-19 04:00:00 FELONY MURDER… (-73.95732 40.81194)
## 8 243688… BROOKL… 2021-01-31 05:00:00 FELONY MURDER… (-73.8627 40.67093)
## 9 240767… BROOKL… 2021-02-17 05:00:00 FELONY MURDER… (-73.97582 40.61046)
## 10 240767… BROOKL… 2021-05-24 04:00:00 FELONY MURDER… (-73.97582 40.61046)
## # … with 259 more rows, and abbreviated variable names ¹​cmplnt_num,
## # ²​law_cat_cd, ³​ofns_desc
## # ℹ Use `print(n = ...)` to see more rows
```

---

## Plotting with two sf data frames

.panelset.sideways[

```r
ggplot() +
 geom_sf(data = nyc_json) +
 geom_sf(
* data = crimes_homicide_sf,
* shape = 1
 )
```

&amp;lt;img src="index_files/figure-html/crimes-sf-plot-1.png" width="100%" style="display: block; margin: auto;" /&amp;gt;
]

---

class: inverse, middle

# Choropleths

---

&amp;lt;img src="https://media.giphy.com/media/If7M383oivlYY/giphy.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Fill (choropleths)




```r
fb_state &amp;lt;- read_csv(file = here("data", "foreign-born.csv"))
```


```r
fb_state
```

```
## # A tibble: 52 × 6
## GEOID NAME total native foreign pct_foreign
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 01 Alabama 4876250 4703303 172947 0.0355
## 2 02 Alaska 737068 679401 57667 0.0782
## 3 04 Arizona 7050299 6109648 940651 0.133 
## 4 05 Arkansas 2999370 2854323 145047 0.0484
## 5 06 California 39283497 28736287 10547210 0.268 
## 6 08 Colorado 5610349 5063836 546513 0.0974
## 7 10 Delaware 957248 865775 91473 0.0956
## 8 11 District of Columbia 692683 597618 95065 0.137 
## 9 09 Connecticut 3575074 3054123 520951 0.146 
## 10 12 Florida 20901636 16576836 4324800 0.207 
## # … with 42 more rows
## # ℹ Use `print(n = ...)` to see more rows
```

---

## Join the data


```r
usa_fb &amp;lt;- left_join(x = usa_48, y = fb_state, by = c("STATEFP" = "GEOID", "NAME"))
usa_fb
```

```
## Simple feature collection with 48 features and 13 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -124.7332 ymin: 24.51496 xmax: -66.9499 ymax: 49.38436
## Geodetic CRS: NAD83
## First 10 features:
## STATEFP STATENS AFFGEOID GEOID STUSPS NAME LSAD ALAND
## 1 55 01779806 0400000US55 55 WI Wisconsin 00 140292246684
## 2 54 01779805 0400000US54 54 WV West Virginia 00 62266296765
## 3 16 01779783 0400000US16 16 ID Idaho 00 214049923496
## 4 27 00662849 0400000US27 27 MN Minnesota 00 206232157570
## 5 19 01779785 0400000US19 19 IA Iowa 00 144659688848
## 6 10 01779781 0400000US10 10 DE Delaware 00 5046731558
## 7 29 01779791 0400000US29 29 MO Missouri 00 178052563675
## 8 50 01779802 0400000US50 50 VT Vermont 00 23873081385
## 9 24 01714934 0400000US24 24 MD Maryland 00 25151895765
## 10 33 01779794 0400000US33 33 NH New Hampshire 00 23190113978
## AWATER total native foreign pct_foreign
## 1 29343721650 5790716 5500994 289722 0.05003215
## 2 489206049 1817305 1787134 30171 0.01660206
## 3 2391577745 1717750 1615307 102443 0.05963790
## 4 18949864226 5563378 5090529 472849 0.08499315
## 5 1085996889 3139508 2973069 166439 0.05301436
## 6 1399179670 957248 865775 91473 0.09555831
## 7 2487215790 6104910 5849191 255719 0.04188743
## 8 1030243281 624313 594985 29328 0.04697644
## 9 6979171386 6018848 5105961 912887 0.15167138
## 10 1025973001 1348124 1265430 82694 0.06134005
## geometry
## 1 MULTIPOLYGON (((-86.9562 45...
## 2 MULTIPOLYGON (((-82.643 38....
## 3 MULTIPOLYGON (((-117.2427 4...
## 4 MULTIPOLYGON (((-97.23921 4...
## 5 MULTIPOLYGON (((-96.6397 42...
## 6 MULTIPOLYGON (((-75.5708 39...
## 7 MULTIPOLYGON (((-95.77355 4...
## 8 MULTIPOLYGON (((-73.43774 4...
## 9 MULTIPOLYGON (((-76.0494 37...
## 10 MULTIPOLYGON (((-72.55725 4...
```

---

## Draw the map

.panelset.sideways[

```r
ggplot(data = usa_fb) +
* geom_sf(mapping = aes(fill = pct_foreign))
```

&amp;lt;img src="index_files/figure-html/geom-map-state-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---

class: inverse, middle

# Use better colors

---

## `colorspace`

Scale name: `scale_&amp;lt;aesthetic&amp;gt;_&amp;lt;datatype&amp;gt;_&amp;lt;colorscale&amp;gt;()`

--

- `&amp;lt;aesthetic&amp;gt;`: name of the aesthetic (`fill`, `color`, `colour`)
- `&amp;lt;datatype&amp;gt;`: type of variable plotted (`discrete`, `continuous`, `binned`)
- `&amp;lt;colorscale&amp;gt;`: type of the color scale (`qualitative`, `sequential`, `diverging`)

--

Scale function | Aesthetic &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp; | Data type | Palette type &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;
:----------- | :-------- | :--------- | :------------
`scale_color_discrete_qualitative()` | `color` | discrete | qualitative
`scale_fill_continuous_sequential()` | `fill` | continuous | sequential
`scale_color_continuous_diverging()` | `color` | continuous | diverging

---

&amp;lt;img src="index_files/figure-html/colorspace-palettes-seq-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="index_files/figure-html/colorspace-palettes-div-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

&amp;lt;img src="index_files/figure-html/colorspace-palettes-qual-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Use better colors

.panelset.sideways[

```r
*library(colorspace)

ggplot(data = usa_fb) +
 geom_sf(mapping = aes(
 fill = pct_foreign
 )) +
* scale_fill_continuous_sequential(palette = "mako")
```

&amp;lt;img src="index_files/figure-html/geom-map-state-pal-1.png" width="100%" style="display: block; margin: auto;" /&amp;gt;
]

---

class: inverse, middle

# Spatial aggregation

---

## Spatial aggregation


```r
st_join(x = nyc_json, y = crimes_homicide_sf)
```

```
## Simple feature collection with 269 features and 9 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## First 10 features:
## boro_code boro_name shape_area shape_leng cmplnt_num
## 1 5 Staten Island 1623631283.36 325924.002076 239347883H1
## 1.1 5 Staten Island 1623631283.36 325924.002076 244818447H1
## 1.2 5 Staten Island 1623631283.36 325924.002076 246985876H1
## 2 2 Bronx 1187189499.3 463277.240478 242029394H1
## 2.1 2 Bronx 1187189499.3 463277.240478 242029394H1
## 2.2 2 Bronx 1187189499.3 463277.240478 243573864H1
## 2.3 2 Bronx 1187189499.3 463277.240478 244256173H1
## 2.4 2 Bronx 1187189499.3 463277.240478 240776535H1
## 2.5 2 Bronx 1187189499.3 463277.240478 240776535H1
## 2.6 2 Bronx 1187189499.3 463277.240478 240776535H1
## boro_nm cmplnt_fr_dt law_cat_cd
## 1 STATEN ISLAND 2022-01-18 05:00:00 FELONY
## 1.1 STATEN ISLAND 2022-05-09 04:00:00 FELONY
## 1.2 STATEN ISLAND 2022-06-21 04:00:00 FELONY
## 2 BRONX 2021-06-01 04:00:00 FELONY
## 2.1 BRONX 2021-06-01 04:00:00 FELONY
## 2.2 BRONX 2021-10-24 04:00:00 FELONY
## 2.3 BRONX 2021-12-17 05:00:00 FELONY
## 2.4 BRONX 2022-01-01 05:00:00 FELONY
## 2.5 BRONX 2022-01-01 05:00:00 FELONY
## 2.6 BRONX 2022-01-01 05:00:00 FELONY
## ofns_desc geometry
## 1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 1.1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 1.2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.3 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.4 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.5 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.6 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
```

---



count: false
 

.panel1-crimes-agg-map-auto[

```r
*nyc_json
```
]
 
.panel2-crimes-agg-map-auto[

```
## Simple feature collection with 5 features and 4 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## boro_code boro_name shape_area shape_leng
## 1 5 Staten Island 1623631283.36 325924.002076
## 2 2 Bronx 1187189499.3 463277.240478
## 3 1 Manhattan 636605816.437 359103.151368
## 4 3 Brooklyn 1934169228.83 728478.125489
## 5 4 Queens 3041397430.33 888238.562635
## geometry
## 1 MULTIPOLYGON (((-74.05051 4...
## 2 MULTIPOLYGON (((-73.89681 4...
## 3 MULTIPOLYGON (((-74.01093 4...
## 4 MULTIPOLYGON (((-73.86327 4...
## 5 MULTIPOLYGON (((-73.82645 4...
```
]

---
count: false
 

.panel1-crimes-agg-map-auto[

```r
nyc_json %&amp;gt;%
* st_join(y = crimes_homicide_sf)
```
]
 
.panel2-crimes-agg-map-auto[

```
## Simple feature collection with 269 features and 9 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## First 10 features:
## boro_code boro_name shape_area shape_leng cmplnt_num
## 1 5 Staten Island 1623631283.36 325924.002076 239347883H1
## 1.1 5 Staten Island 1623631283.36 325924.002076 244818447H1
## 1.2 5 Staten Island 1623631283.36 325924.002076 246985876H1
## 2 2 Bronx 1187189499.3 463277.240478 242029394H1
## 2.1 2 Bronx 1187189499.3 463277.240478 242029394H1
## 2.2 2 Bronx 1187189499.3 463277.240478 243573864H1
## 2.3 2 Bronx 1187189499.3 463277.240478 244256173H1
## 2.4 2 Bronx 1187189499.3 463277.240478 240776535H1
## 2.5 2 Bronx 1187189499.3 463277.240478 240776535H1
## 2.6 2 Bronx 1187189499.3 463277.240478 240776535H1
## boro_nm cmplnt_fr_dt law_cat_cd
## 1 STATEN ISLAND 2022-01-18 05:00:00 FELONY
## 1.1 STATEN ISLAND 2022-05-09 04:00:00 FELONY
## 1.2 STATEN ISLAND 2022-06-21 04:00:00 FELONY
## 2 BRONX 2021-06-01 04:00:00 FELONY
## 2.1 BRONX 2021-06-01 04:00:00 FELONY
## 2.2 BRONX 2021-10-24 04:00:00 FELONY
## 2.3 BRONX 2021-12-17 05:00:00 FELONY
## 2.4 BRONX 2022-01-01 05:00:00 FELONY
## 2.5 BRONX 2022-01-01 05:00:00 FELONY
## 2.6 BRONX 2022-01-01 05:00:00 FELONY
## ofns_desc geometry
## 1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 1.1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 1.2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-74.05051 4...
## 2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.1 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.2 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.3 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.4 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.5 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
## 2.6 MURDER &amp;amp; NON-NEGL. MANSLAUGHTER MULTIPOLYGON (((-73.89681 4...
```
]

---
count: false
 

.panel1-crimes-agg-map-auto[

```r
nyc_json %&amp;gt;%
 st_join(y = crimes_homicide_sf) %&amp;gt;%
* group_by(boro_name)
```
]
 
.panel2-crimes-agg-map-auto[

```
## Simple feature collection with 269 features and 9 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## # A tibble: 269 × 10
## # Groups: boro_name [5]
## boro_code boro_…¹ shape…² shape…³ cmpln…⁴ boro_nm cmplnt_fr_dt law_c…⁵
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dttm&amp;gt; &amp;lt;chr&amp;gt; 
## 1 5 Staten… 162363… 325924… 239347… STATEN… 2022-01-18 05:00:00 FELONY 
## 2 5 Staten… 162363… 325924… 244818… STATEN… 2022-05-09 04:00:00 FELONY 
## 3 5 Staten… 162363… 325924… 246985… STATEN… 2022-06-21 04:00:00 FELONY 
## 4 2 Bronx 118718… 463277… 242029… BRONX 2021-06-01 04:00:00 FELONY 
## 5 2 Bronx 118718… 463277… 242029… BRONX 2021-06-01 04:00:00 FELONY 
## 6 2 Bronx 118718… 463277… 243573… BRONX 2021-10-24 04:00:00 FELONY 
## 7 2 Bronx 118718… 463277… 244256… BRONX 2021-12-17 05:00:00 FELONY 
## 8 2 Bronx 118718… 463277… 240776… BRONX 2022-01-01 05:00:00 FELONY 
## 9 2 Bronx 118718… 463277… 240776… BRONX 2022-01-01 05:00:00 FELONY 
## 10 2 Bronx 118718… 463277… 240776… BRONX 2022-01-01 05:00:00 FELONY 
## # … with 259 more rows, 2 more variables: ofns_desc &amp;lt;chr&amp;gt;,
## # geometry &amp;lt;MULTIPOLYGON [°]&amp;gt;, and abbreviated variable names ¹​boro_name,
## # ²​shape_area, ³​shape_leng, ⁴​cmplnt_num, ⁵​law_cat_cd
## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names
```
]

---
count: false
 

.panel1-crimes-agg-map-auto[

```r
nyc_json %&amp;gt;%
 st_join(y = crimes_homicide_sf) %&amp;gt;%
 group_by(boro_name) %&amp;gt;%
* count()
```
]
 
.panel2-crimes-agg-map-auto[

```
## Simple feature collection with 5 features and 2 fields
## Geometry type: MULTIPOLYGON
## Dimension: XY
## Bounding box: xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553
## Geodetic CRS: WGS 84
## # A tibble: 5 × 3
## boro_name n geometry
## * &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;MULTIPOLYGON [°]&amp;gt;
## 1 Bronx 101 (((-73.89679 40.79633, -73.89713 40.7968, -73.89788 40.79…
## 2 Brooklyn 75 (((-73.86318 40.58406, -73.86283 40.58442, -73.8625 40.58…
## 3 Manhattan 46 (((-74.0086 40.68591, -74.00851 40.68596, -74.00843 40.68…
## 4 Queens 44 (((-73.82646 40.59059, -73.82647 40.59065, -73.82648 40.5…
## 5 Staten Island 3 (((-74.05054 40.56644, -74.05062 40.56651, -74.05067 40.5…
```
]

---
count: false
 

.panel1-crimes-agg-map-auto[

```r
nyc_json %&amp;gt;%
 st_join(y = crimes_homicide_sf) %&amp;gt;%
 group_by(boro_name) %&amp;gt;%
 count() %&amp;gt;%
* ggplot()
```
]
 
.panel2-crimes-agg-map-auto[
&amp;lt;img src="index_files/figure-html/crimes-agg-map_auto_05_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

---
count: false
 

.panel1-crimes-agg-map-auto[

```r
nyc_json %&amp;gt;%
 st_join(y = crimes_homicide_sf) %&amp;gt;%
 group_by(boro_name) %&amp;gt;%
 count() %&amp;gt;%
 ggplot() +
* geom_sf(mapping = aes(fill = n))
```
]
 
.panel2-crimes-agg-map-auto[
&amp;lt;img src="index_files/figure-html/crimes-agg-map_auto_06_output-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;
]

&amp;lt;style&amp;gt;
.panel1-crimes-agg-map-auto {
 color: black;
 width: 38.6060606060606%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel2-crimes-agg-map-auto {
 color: black;
 width: 59.3939393939394%;
 hight: 32%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
.panel3-crimes-agg-map-auto {
 color: black;
 width: NA%;
 hight: 33%;
 float: left;
 padding-left: 1%;
 font-size: 80%
}
&amp;lt;/style&amp;gt;



---

## Which is better for comparisons?

&amp;lt;img src="index_files/figure-html/crimes-agg-map-2-1.png" width="90%" style="display: block; margin: auto;" /&amp;gt;

---

## Exercise using household income

&amp;lt;img src="https://c.tenor.com/vvktIE0tx9kAAAAd/into-the-map-joe-tribbiani.gif" width="50%" style="display: block; margin: auto;" /&amp;gt;

&lt;div class="countdown" id="timer_631a0020" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">12&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

---

class: inverse, middle

# Bin continuous data to discrete intervals

---

## Bin data to discrete intervals

* Continuous vs. discrete variables for color
* Collapse to a discrete variable

---

## `cut_interval()`

.panelset.sideways[
.panel[.panel-name[Code]

```r
usa_fb %&amp;gt;%
* mutate(rate_cut = cut_interval(pct_foreign, n = 6)) %&amp;gt;%
 ggplot() +
 geom_sf(aes(fill = rate_cut)) +
 scale_fill_discrete_sequential(palette = "inferno")
```



]

.panel[.panel-name[Output]

&amp;lt;img src="index_files/figure-html/cut-int-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## `cut_number()`

.panelset.sideways[
.panel[.panel-name[Code]

```r
usa_fb %&amp;gt;%
* mutate(rate_cut = cut_number(pct_foreign, n = 6)) %&amp;gt;%
 ggplot() +
 geom_sf(aes(fill = rate_cut)) +
 scale_fill_discrete_sequential(palette = "inferno")
```



]

.panel[.panel-name[Output]

&amp;lt;img src="index_files/figure-html/cut-num-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## `ggplot2::binned_scale()`

.panelset.sideways[
.panel[.panel-name[Code]

```r
usa_fb %&amp;gt;%
 ggplot() +
 geom_sf(aes(fill = pct_foreign)) +
* scale_fill_binned_sequential(palette = "inferno")
```



]

.panel[.panel-name[Output]

&amp;lt;img src="index_files/figure-html/bin-scale-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## `ggplot2::binned_scale()` with quartiles

.panelset.sideways[
.panel[.panel-name[Code]

```r
usa_fb %&amp;gt;%
 ggplot() +
 geom_sf(aes(fill = pct_foreign)) +
 scale_fill_binned_sequential(
 palette = "inferno",
* n.breaks = 3
 )
```



]

.panel[.panel-name[Output]

&amp;lt;img src="index_files/figure-html/bin-quartile-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

## `ggplot2::binned_scale()` with quartiles

.panelset.sideways[
.panel[.panel-name[Code]

```r
usa_fb %&amp;gt;%
 ggplot() +
 geom_sf(aes(fill = pct_foreign)) +
 scale_fill_binned_sequential(
 palette = "inferno",
* n.breaks = 3,
* nice.breaks = FALSE
 )
```



]

.panel[.panel-name[Output]

&amp;lt;img src="index_files/figure-html/bin-quartile-not-nice-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

]
]

---

class: inverse, middle

# Map projection

---

## Map projection

.center[
&amp;lt;iframe width="560" height="315" src="https://www.youtube.com/embed/vVX-PrBRtTY?rel=0" frameborder="0" allowfullscreen&amp;gt;&amp;lt;/iframe&amp;gt;
]

---

## Map projection

&amp;lt;img src="https://imgs.xkcd.com/comics/mercator_projection.png" width="30%" style="display: block; margin: auto;" /&amp;gt;

.footnote[Source: [xkcd](https://xkcd.com/2082/)]

---

## Map projection

* Coordinate reference system
* proj4string
* **W**ell **K**nown **T**ext 2 (WKT2) string

&amp;gt; &amp;lt;https://spatialreference.org/ref/epsg/&amp;gt;

---

## US National Atlas Equal Area

.pull-left[
#### proj4string

```
+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs
```

]

.pull-right[

#### WKT2

```
PROJCS["US National Atlas Equal Area",
 GEOGCS["Unspecified datum based upon the Clarke 1866 Authalic Sphere",
 DATUM["Not_specified_based_on_Clarke_1866_Authalic_Sphere",
 SPHEROID["Clarke 1866 Authalic Sphere",6370997,0,
 AUTHORITY["EPSG","7052"]],
 AUTHORITY["EPSG","6052"]],
 PRIMEM["Greenwich",0,
 AUTHORITY["EPSG","8901"]],
 UNIT["degree",0.01745329251994328,
 AUTHORITY["EPSG","9122"]],
 AUTHORITY["EPSG","4052"]],
 UNIT["metre",1,
 AUTHORITY["EPSG","9001"]],
 PROJECTION["Lambert_Azimuthal_Equal_Area"],
 PARAMETER["latitude_of_center",45],
 PARAMETER["longitude_of_center",-100],
 PARAMETER["false_easting",0],
 PARAMETER["false_northing",0],
 AUTHORITY["EPSG","2163"],
 AXIS["X",EAST],
 AXIS["Y",NORTH]]
```

]

---

## EPSG

- Coordinated registry of CRSs
- [Spatial Reference](https://spatialreference.org/ref/epsg/)
- [epsg.io](https://epsg.io/)

---

## Mercator projection



&amp;lt;img src="index_files/figure-html/mercator-sf-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Projection using standard lines

&amp;lt;img src="index_files/figure-html/projection-rest-1.png" width="80%" style="display: block; margin: auto;" /&amp;gt;

---

## Adjusting color intervals and projections

&lt;div class="countdown" id="timer_631a020c" style="right:0;bottom:0;" data-warnwhen="0">
&lt;code class="countdown-time">&lt;span class="countdown-digits minutes">08&lt;/span>&lt;span class="countdown-digits colon">:&lt;/span>&lt;span class="countdown-digits seconds">00&lt;/span>&lt;/code>
&lt;/div>

&amp;lt;img src="https://c.tenor.com/pLC9Wr0DMWsAAAAC/lazy-sunday-google-maps.gif" width="80%" style="display: block; margin: auto;" /&amp;gt;
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item><item><title/><link>https://cfssmacss.netlify.app/slides/working-with-statistical-models/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cfssmacss.netlify.app/slides/working-with-statistical-models/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="" xml:lang="">
 &lt;head>
 &lt;title>Working with statistical models&lt;/title>
 &lt;meta charset="utf-8" />
 &lt;meta name="author" content="MACS 30500 University of Chicago" />
 &lt;script src="libs/header-attrs/header-attrs.js">&lt;/script>
 &lt;link href="libs/remark-css/default.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/metropolis.css" rel="stylesheet" />
 &lt;link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
 &lt;/head>
 &lt;body>
 &lt;textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Working with statistical models
]
.author[
### &lt;a href="https://info5940.infosci.cornell.edu">MACS 30500&lt;/a> &lt;br /> University of Chicago
]

---




# Working with models

* Visualizing raw data
* Visualizing summarized data
* `stat_*()` functions
* Default `geom_*()` functions

---

# Visualizing models separately

&amp;lt;img src="index_files/figure-html/viz-gapminder-combo-1.png" width="864" /&amp;gt;

---

# Combining `ggplot()`s

* How do we combine separate `ggplot()` objects into a single chart?
* `gridExtra`
* `cowplot`
* [`patchwork`](https://patchwork.data-imaginist.com/articles/patchwork.html)

---

# Showing several fits at once

* Mapping variables to the plot
* Instead of a column, use a character string
* [Example using SCOTUS](https://github.com/cfss-fa19/hw03/blob/master/demo/scotus_solution.md#with-two-data-frames)

---

# Showing several fits at once

&amp;lt;div style="width:100%;height:0;padding-bottom:56%;position:relative;"&amp;gt;&amp;lt;iframe src="https://giphy.com/embed/8AfVHQbGG8dxGCC7ES" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;

---

# Getting model-based graphics right

* Statistics is hard
* Communicating results is hard

--

## General guidelines

* Present your findings in substantive terms
* Show your degree of confidence
* Show your data (when you can)

---

# Coefficient plots

&amp;lt;table&amp;gt;
 &amp;lt;thead&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;th style="text-align:left;"&amp;gt; Term &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:right;"&amp;gt; Coefficient &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:right;"&amp;gt; Standard Error &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:right;"&amp;gt; t-statistic &amp;lt;/th&amp;gt;
 &amp;lt;th style="text-align:right;"&amp;gt; p-value &amp;lt;/th&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;/thead&amp;gt;
&amp;lt;tbody&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; (Intercept) &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 28.58 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.65 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 43.69 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Homicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -0.67 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.44 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -1.53 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.13 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Suicide &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 8.89 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.43 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 20.74 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Undetermined &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 1.27 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.73 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 1.73 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.08 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Police &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.25 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.47 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.54 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.59 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Male &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 1.24 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.15 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 8.02 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Black &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -1.65 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.49 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -3.37 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Hispanic &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -1.24 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.51 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -2.46 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.01 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Native American/Native Alaskan &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -0.89 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.73 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; -1.22 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.22 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; White &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 9.39 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.48 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 19.72 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; HS/GED &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 3.50 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.14 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 24.46 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; Some College &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 2.13 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.17 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 12.76 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
 &amp;lt;tr&amp;gt;
 &amp;lt;td style="text-align:left;"&amp;gt; BA+ &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 8.85 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.20 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 45.05 &amp;lt;/td&amp;gt;
 &amp;lt;td style="text-align:right;"&amp;gt; 0.00 &amp;lt;/td&amp;gt;
 &amp;lt;/tr&amp;gt;
&amp;lt;/tbody&amp;gt;
&amp;lt;/table&amp;gt;

---

# Coefficient plots

&amp;lt;img src="index_files/figure-html/complex-model-plot-1.png" width="864" /&amp;gt;

---

# Marginal effects plots

* Expected change in `\(Y\)` associated with a change in `\(X\)`
* Constant in OLS models
* Non-constant in logistic regression models

---

# Marginal effects plots



![](index_files/figure-html/titanic-marg-eff-1.gif)&amp;lt;!-- --&amp;gt;

---

# Average marginal effects


```
## # A tibble: 12 × 5
## term estimate std.error statistic p.value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 0.296 0.134 2.21 2.70e- 2
## 2 polviews_mExtremely Liberal 2.37 0.525 4.52 6.20e- 6
## 3 polviews_mLiberal 2.60 0.357 7.29 3.10e-13
## 4 polviews_mSlightly Liberal 1.29 0.248 5.21 1.94e- 7
## 5 polviews_mSlightly Conservative -1.36 0.181 -7.48 7.68e-14
## 6 polviews_mConservative -2.35 0.200 -11.7 1.07e-31
## 7 polviews_mExtremely Conservative -2.73 0.387 -7.04 1.87e-12
## 8 sexFemale 0.255 0.145 1.75 7.96e- 2
## 9 raceBlack 3.85 0.501 7.68 1.61e-14
## 10 raceOther -0.00214 0.436 -0.00492 9.96e- 1
## 11 sexFemale:raceBlack -0.198 0.660 -0.299 7.65e- 1
## 12 sexFemale:raceOther 1.57 0.588 2.68 7.37e- 3
```

---

# Average marginal effects

&amp;lt;img src="index_files/figure-html/obama-margins-1.png" width="864" /&amp;gt;

---

# Conditional effects



&amp;lt;img src="index_files/figure-html/obama-cond-plot-1.png" width="864" /&amp;gt;

---

# Marginal effects plots

&amp;lt;div style="width:100%;height:0;padding-bottom:41%;position:relative;"&amp;gt;&amp;lt;iframe src="https://giphy.com/embed/H7x1H0veAJlo4" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen&amp;gt;&amp;lt;/iframe&amp;gt;&amp;lt;/div&amp;gt;
 &lt;/textarea>
&lt;style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}&lt;/style>
&lt;script src="https://remarkjs.com/downloads/remark-latest.min.js">&lt;/script>
&lt;script src="https://cfss.uchicago.edu/slides/macros.js">&lt;/script>
&lt;script src="https://platform.twitter.com/widgets.js">&lt;/script>
&lt;script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
 window.dispatchEvent(new Event('resize'));
});
(function(d) {
 var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
 if (!r) return;
 s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
 d.head.appendChild(s);
})(document);

(function(d) {
 var el = d.getElementsByClassName("remark-slides-area");
 if (!el) return;
 var slide, slides = slideshow.getSlides(), els = el[0].children;
 for (var i = 1; i &lt; slides.length; i++) {
 slide = slides[i];
 if (slide.properties.continued === "true" || slide.properties.count === "false") {
 els[i - 1].className += ' has-continuation';
 }
 }
 var s = d.createElement("style");
 s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
 d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
 var deleted = false;
 slideshow.on('beforeShowSlide', function(slide) {
 if (deleted) return;
 var sheets = document.styleSheets, node;
 for (var i = 0; i &lt; sheets.length; i++) {
 node = sheets[i].ownerNode;
 if (node.dataset["target"] !== "print-only") continue;
 node.parentNode.removeChild(node);
 }
 deleted = true;
 });
})();
// add `data-at-shortcutkeys` attribute to &lt;body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
 let res = {};
 d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
 const t = tr.querySelector('td:nth-child(2)').innerText;
 tr.querySelectorAll('td:first-child .key').forEach(key => {
 const k = key.innerText;
 if (/^[a-z]$/.test(k)) res[k] = t; // must be a single letter (key)
 });
 });
 d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
 "use strict"
 // Replace &lt;script> tags in slides area to make them executable
 var scripts = document.querySelectorAll(
 '.remark-slides-area .remark-slide-container script'
 );
 if (!scripts.length) return;
 for (var i = 0; i &lt; scripts.length; i++) {
 var s = document.createElement('script');
 var code = document.createTextNode(scripts[i].textContent);
 s.appendChild(code);
 var scriptAttrs = scripts[i].attributes;
 for (var j = 0; j &lt; scriptAttrs.length; j++) {
 s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
 }
 scripts[i].parentElement.replaceChild(s, scripts[i]);
 }
})();
(function() {
 var links = document.getElementsByTagName('a');
 for (var i = 0; i &lt; links.length; i++) {
 if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
 links[i].target = '_blank';
 }
 }
})();
// adds .remark-code-has-line-highlighted class to &lt;pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
 const hlines = d.querySelectorAll('.remark-code-line-highlighted');
 const preParents = [];
 const findPreParent = function(line, p = 0) {
 if (p > 1) return null; // traverse up no further than grandparent
 const el = line.parentElement;
 return el.tagName === "PRE" ? el : findPreParent(el, ++p);
 };

 for (let line of hlines) {
 let pre = findPreParent(line);
 if (pre &amp;&amp; !preParents.includes(pre)) preParents.push(pre);
 }
 preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);&lt;/script>

&lt;script>
slideshow._releaseMath = function(el) {
 var i, text, code, codes = el.getElementsByTagName('code');
 for (i = 0; i &lt; codes.length;) {
 code = codes[i];
 if (code.parentNode.tagName !== 'PRE' &amp;&amp; code.childElementCount === 0) {
 text = code.textContent;
 if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
 /^\$\$(.|\s)+\$\$$/.test(text) ||
 /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
 code.outerHTML = code.innerHTML; // remove &lt;code>&lt;/code>
 continue;
 }
 }
 i++;
 }
};
slideshow._releaseMath(document);
&lt;/script>
&lt;!-- dynamically load mathjax for compatibility with self-contained -->
&lt;script>
(function () {
 var script = document.createElement('script');
 script.type = 'text/javascript';
 script.src = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
 if (location.protocol !== 'file:' &amp;&amp; /^https?:/.test(script.src))
 script.src = script.src.replace(/^https?:/, '');
 document.getElementsByTagName('head')[0].appendChild(script);
})();
&lt;/script>
 &lt;/body>
&lt;/html></description></item></channel></rss>